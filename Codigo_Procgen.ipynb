{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo_Procgen.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KLpmSgmeN6PX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matpg/RL-Agent-for-Unreal-Engine/blob/main/Codigo_Procgen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxXV_TQMVTV"
      },
      "source": [
        "### Descarga de Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3Jqzp-yr7r",
        "outputId": "652abf8a-c059-4e4d-e2fe-749b5c82c5c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install procgen\n",
        "!git clone https://github.com/openai/train-procgen.git\n",
        "!conda env update --name train-procgen --file train-procgen/environment.yml\n",
        "!conda activate train-procgen\n",
        "!pip install https://github.com/openai/baselines/archive/9ee399f5b20cd70ac0a871927a6cf043b478193f.zip\n",
        "!pip install -e train-procgen\n",
        "!pip install mpi4py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting procgen\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/34/0ae32b01ec623cd822752e567962cfa16ae9c6d6ba2208f3445c017a121b/procgen-0.10.4-cp36-cp36m-manylinux2010_x86_64.whl (39.9MB)\n",
            "\u001b[K     |████████████████████████████████| 39.9MB 76kB/s \n",
            "\u001b[?25hRequirement already satisfied: gym<1.0.0,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.18.5)\n",
            "Collecting gym3<1.0.0,>=0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/8c/83da801207f50acfd262041e7974f3b42a0e5edd410149d8a70fd4ad2e70/gym3-0.3.3-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.3.0)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.3)\n",
            "Collecting imageio<3.0.0,>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.4MB/s \n",
            "\u001b[?25hCollecting glfw<2.0.0,>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/1b/cc758368f1b2466b3701c0f692973aa8a0b51a192a40463c1d02d54d640c/glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 56.7MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/12/01126a2fb737b23461d7dadad3b8abd51ad6210f979ff05c6fa9812dfbbe/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.3MB/s \n",
            "\u001b[?25hCollecting moderngl<6.0.0,>=5.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/ab/5f72a1b7c5bdbb17160c85e8ba855d48925c74ff93c1e1027d5ad40bf33c/moderngl-5.6.2-cp36-cp36m-manylinux1_x86_64.whl (664kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.0.0)\n",
            "Collecting glcontext<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/8d/93915df9cd8d31c5f054bbacd1c7a76cd2f776b8212dcc768358bd2d4a37/glcontext-2.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio, glfw, imageio-ffmpeg, glcontext, moderngl, gym3, procgen\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed glcontext-2.2.0 glfw-1.12.0 gym3-0.3.3 imageio-2.9.0 imageio-ffmpeg-0.3.0 moderngl-5.6.2 procgen-0.10.4\n",
            "Cloning into 'train-procgen'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 387 (delta 2), reused 12 (delta 2), pack-reused 368\u001b[K\n",
            "Receiving objects: 100% (387/387), 71.37 MiB | 24.53 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "Checking out files: 100% (306/306), done.\n",
            "/bin/bash: conda: command not found\n",
            "/bin/bash: conda: command not found\n",
            "Collecting https://github.com/openai/baselines/archive/9ee399f5b20cd70ac0a871927a6cf043b478193f.zip\n",
            "\u001b[?25l  Downloading https://github.com/openai/baselines/archive/9ee399f5b20cd70ac0a871927a6cf043b478193f.zip\n",
            "\u001b[K     / 9.1MB 13.2MB/s\n",
            "\u001b[?25hCollecting gym<0.16.0,>=0.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/01/8771e8f914a627022296dab694092a11a7d417b6c8364f0a44a8debca734/gym-0.15.7.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.17.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.16.0)\n",
            "Building wheels for collected packages: baselines, gym\n",
            "  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baselines: filename=baselines-0.1.6-cp36-none-any.whl size=220649 sha256=545ec0ab6679b85178ddf7d7ef993964418b6b48ce3b390518107b13667d7829\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yamwmq_p/wheels/70/17/70/0c3c0d6795e1ad4315fce927be943aaf7f9a4fafb2d6e0d4cd\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.7-cp36-none-any.whl size=1648843 sha256=06d071168c12f6e812cf571392c0feaf5d9d0739a3a0236f63968547aff8a8dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/60/6a/f9c27ae133abaf5a5687ed2fa8ed19627d7fac5d843a27572b\n",
            "Successfully built baselines gym\n",
            "\u001b[31mERROR: gym 0.15.7 has requirement cloudpickle~=1.2.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gym, baselines\n",
            "  Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed baselines-0.1.6 gym-0.15.7\n",
            "Obtaining file:///content/train-procgen\n",
            "Installing collected packages: train-procgen\n",
            "  Running setup.py develop for train-procgen\n",
            "Successfully installed train-procgen\n",
            "Collecting mpi4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/8f/bbd8de5ba566dd77e408d8136e2bab7fdf2b97ce06cab830ba8b50a2f588/mpi4py-3.0.3.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.0.3-cp36-cp36m-linux_x86_64.whl size=2074492 sha256=d9261c2a00844cc8c5ddbcfce9081e61501c591a5a1a3c2667d5cadedc4c1583\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e0/86/2b713dd512199096012ceca61429e12b960888de59818871d6\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56usX4V4MgTq"
      },
      "source": [
        "### Comprobación de carga de librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "source": [
        "from procgen import ProcgenGym3Env"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_X-G5NnMr2i"
      },
      "source": [
        "### Entrenamiento en entorno Maze de Procgen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOi5OSNM4OA",
        "outputId": "36ae3ea0-a9d1-4d27-f8bf-a359919078ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!python -m train_procgen.train --env_name maze"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'train_procgen.train' found in sys.modules after import of package 'train_procgen', but prior to execution of 'train_procgen.train'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Logging to /tmp/procgen\n",
            "creating environment\n",
            "creating tf session\n",
            "WARNING:tensorflow:From /content/train-procgen/train_procgen/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/train-procgen/train_procgen/train.py:49: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-11-03 22:55:59.121261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-11-03 22:55:59.121502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3070680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-03 22:55:59.121535: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-03 22:55:59.123530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-03 22:55:59.235946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.236631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3070d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-03 22:55:59.236667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-11-03 22:55:59.236839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.237428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-11-03 22:55:59.237725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-03 22:55:59.239320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-03 22:55:59.240930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-03 22:55:59.241320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-03 22:55:59.242850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-03 22:55:59.243580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-03 22:55:59.246658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-03 22:55:59.246787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.247411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.247920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-11-03 22:55:59.247982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-03 22:55:59.249300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-03 22:55:59.249344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-11-03 22:55:59.249356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-11-03 22:55:59.249495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.250119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-03 22:55:59.250706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "training\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/mpi_adam_optimizer.py:11: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/ppo2/model.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/ppo2/model.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/input.py:31: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/models.py:43: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/models.py:57: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/models.py:67: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/models.py:69: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/a2c/utils.py:61: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/distributions.py:200: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/distributions.py:201: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/ppo2/model.py:95: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/tf_util.py:89: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/tf_util.py:90: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/ppo2/model.py:129: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/ppo2/model.py:129: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/baselines/common/mpi_util.py:26: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Stepping environment...\n",
            "2020-11-03 22:56:01.765560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-03 22:56:03.169635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "Done.\n",
            "---------------------------------------\n",
            "| eplenmean               | 75.1      |\n",
            "| eprewmean               | 10        |\n",
            "| fps                     | 843       |\n",
            "| loss/approxkl           | 0.000631  |\n",
            "| loss/clipfrac           | 0         |\n",
            "| loss/policy_entropy     | 2.71      |\n",
            "| loss/policy_loss        | -0.000741 |\n",
            "| loss/value_loss         | 0.683     |\n",
            "| misc/explained_variance | 0.0146    |\n",
            "| misc/nupdates           | 1         |\n",
            "| misc/serial_timesteps   | 256       |\n",
            "| misc/time_elapsed       | 19.4      |\n",
            "| misc/total_timesteps    | 1.64e+04  |\n",
            "---------------------------------------\n",
            "Stepping environment...\n",
            "Done.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/train-procgen/train_procgen/train.py\", line 109, in <module>\n",
            "    main()\n",
            "  File \"/content/train-procgen/train_procgen/train.py\", line 106, in main\n",
            "    comm=comm)\n",
            "  File \"/content/train-procgen/train_procgen/train.py\", line 75, in train_fn\n",
            "    max_grad_norm=0.5,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/baselines/ppo2/ppo2.py\", line 166, in learn\n",
            "    mblossvals.append(model.train(lrnow, cliprangenow, *slices))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/baselines/ppo2/ppo2.py\", line 165, in <genexpr>\n",
            "    slices = (arr[mbinds] for arr in (obs, returns, masks, actions, values, neglogpacs))\n",
            "KeyboardInterrupt\n",
            "[8086aef6d87d:00610] *** Process received signal ***\n",
            "[8086aef6d87d:00610] Signal: Segmentation fault (11)\n",
            "[8086aef6d87d:00610] Signal code: Address not mapped (1)\n",
            "[8086aef6d87d:00610] Failing at address: 0x7f5afd18220d\n",
            "[8086aef6d87d:00610] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f5affe2a8a0]\n",
            "[8086aef6d87d:00610] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f5affa69835]\n",
            "[8086aef6d87d:00610] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f5b002d4e44]\n",
            "[8086aef6d87d:00610] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f5affa6a6c5]\n",
            "[8086aef6d87d:00610] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f5b002d2cb3]\n",
            "[8086aef6d87d:00610] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmWxF7ygNBLf",
        "outputId": "6149bc6f-3b2b-4028-ec7f-5799792bd272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m train_procgen.train --help"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'train_procgen.train' found in sys.modules after import of package 'train_procgen', but prior to execution of 'train_procgen.train'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "usage: train.py [-h] [--env_name ENV_NAME] [--num_envs NUM_ENVS]\n",
            "                [--distribution_mode {easy,hard,exploration,memory,extreme}]\n",
            "                [--num_levels NUM_LEVELS] [--start_level START_LEVEL]\n",
            "                [--test_worker_interval TEST_WORKER_INTERVAL]\n",
            "                [--timesteps_per_proc TIMESTEPS_PER_PROC]\n",
            "\n",
            "Process procgen training arguments.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --env_name ENV_NAME\n",
            "  --num_envs NUM_ENVS\n",
            "  --distribution_mode {easy,hard,exploration,memory,extreme}\n",
            "  --num_levels NUM_LEVELS\n",
            "  --start_level START_LEVEL\n",
            "  --test_worker_interval TEST_WORKER_INTERVAL\n",
            "  --timesteps_per_proc TIMESTEPS_PER_PROC\n",
            "[3504aeb30f06:00669] *** Process received signal ***\n",
            "[3504aeb30f06:00669] Signal: Segmentation fault (11)\n",
            "[3504aeb30f06:00669] Signal code: Address not mapped (1)\n",
            "[3504aeb30f06:00669] Failing at address: 0x7f86bbd6520d\n",
            "[3504aeb30f06:00669] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7f86bea0d8a0]\n",
            "[3504aeb30f06:00669] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f86be64c835]\n",
            "[3504aeb30f06:00669] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f86beeb7e44]\n",
            "[3504aeb30f06:00669] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f86be64d6c5]\n",
            "[3504aeb30f06:00669] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f86beeb5cb3]\n",
            "[3504aeb30f06:00669] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWGZp3i9wyf",
        "outputId": "e41e0f99-3d7a-443d-f88c-47c4ba6ecf8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Eenvironement for learning\n",
        "# Use a separate environement for evaluation\n",
        "env = ProcgenGym3Env(num=8, env_name=\"maze\")\n",
        "print(env)\n",
        "train_env = env\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<CEnv lib_path=/usr/local/lib/python3.6/dist-packages/procgen/data/prebuilt/libenv.so options={'center_agent': True, 'use_generated_assets': False, 'use_monochrome_assets': False, 'restrict_themes': False, 'use_backgrounds': True, 'paint_vel_info': False, 'distribution_mode': 1, 'env_name': 'maze', 'num_levels': 0, 'start_level': 0, 'num_actions': 15, 'use_sequential_levels': False, 'debug_mode': 0, 'rand_seed': 1406393713, 'num_threads': 4, 'render_human': False, 'resource_root': '/usr/local/lib/python3.6/dist-packages/procgen/data/assets/'}>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggH5T4vIJLqM"
      },
      "source": [
        "def make_env(env_id, rank, seed=0):\n",
        "    \"\"\"\n",
        "    Utility function for multiprocessed env.\n",
        "    \n",
        "    :param env_id: (str) the environment ID\n",
        "    :param seed: (int) the inital seed for RNG\n",
        "    :param rank: (int) index of the subprocess\n",
        "    \"\"\"\n",
        "    def _init():\n",
        "        env = gym.make(env_id)\n",
        "        env = RGBImgObsWrapper(env) # Get pixel observations\n",
        "        env = ImgObsWrapper(env)\n",
        "        env = Monitor(env, './monitor_ppo2')\n",
        "        # Important: use a different seed for each environment\n",
        "        env.seed(seed + rank)\n",
        "        return env\n",
        "    set_global_seeds(seed)\n",
        "    return _init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAcx8k-JMtm"
      },
      "source": [
        "n_process = 8\n",
        "env = DummyVecEnv([make_env(env_id, i) for i in range(n_process)])\n",
        "train_env = VecNormalize(env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xz3YmHXN_Nw",
        "outputId": "4d18356f-6c6e-42bc-dfeb-cba00d465d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%cd /content/gym-minigrid/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gym-minigrid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHLMA6NFk95"
      },
      "source": [
        "# Use a separate environement for evaluation\n",
        "# eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "# Random Agent, before training\n",
        "# mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "# print(f\"mean_reward for random agent:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyygEePNZB5"
      },
      "source": [
        "### Definicion de Modelo del Agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCys-Vg-yYR"
      },
      "source": [
        "agent_model = PPO2(\n",
        "    'CnnPolicy',\n",
        "     train_env,\n",
        "      ent_coef=0.0,\n",
        "       nminibatches=32,\n",
        "        noptepochs=10,\n",
        "         verbose=1,\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k9PbbcWNn68"
      },
      "source": [
        "### Evaluar Agente Ingenuo/Aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqks9c0T-IDm"
      },
      "source": [
        "def evaluate(model, eval_env, num_episodes=100):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param model: (BaseRLModel object) the RL Agent\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    # This function will only work for a single Environment\n",
        "    # env = gnwrapper.LoopAnimation(model.get_env()) # Start Xvfb\n",
        "    env = eval_env\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset()\n",
        "        while not done:\n",
        "            # _states are only useful when using LSTM policies\n",
        "            action, _states = model.predict(obs)\n",
        "            # here, action, rewards and dones are arrays\n",
        "            # because we are using vectorized env\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            # env.render()\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "        \n",
        "\n",
        "    # env.display()\n",
        "    max_episode_reward = np.amax(all_episode_rewards)\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    min_episode_reward = np.amin(all_episode_rewards)\n",
        "    print(\n",
        "        \"Max reward:\", max_episode_reward,\n",
        "        \"Mean reward:\", mean_episode_reward,\n",
        "        \"Min reward:\", min_episode_reward,\n",
        "         \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return max_episode_reward, mean_episode_reward, min_episode_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQTdpYv9xJN",
        "outputId": "65fdcbc0-8a75-4160-8139-d72775dd3056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Random Agent, before training using property\n",
        "# from stable_baselines.common.evaluation import evaluate_policy\n",
        "max_r, mean_r, min_r = evaluate(agent_model, eval_env, num_episodes=100)\n",
        "\n",
        "# print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max reward: 0 Mean reward: 0.0 Min reward: 0 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjAP8NWNu_6"
      },
      "source": [
        "### Entrenar Agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHGB-VN-81O",
        "outputId": "8c3a6a2c-9b96-4080-f6e5-8d9ea4c358a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "agent_model.learn(total_timesteps=10000, log_interval=10)\n",
        "train_env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| approxkl           | 0.011721635   |\n",
            "| clipfrac           | 0.175         |\n",
            "| ep_len_mean        | 58.6          |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | 0.636         |\n",
            "| fps                | 258           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 1.9330553     |\n",
            "| policy_loss        | -0.022883493  |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.98e-05      |\n",
            "| total_timesteps    | 1024          |\n",
            "| value_loss         | 0.00035427717 |\n",
            "--------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcsEVysINz9j"
      },
      "source": [
        "### Evaluar Agente Entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5chx6sxfN76",
        "outputId": "ee2d11b3-c408-41ba-a662-a9b318ccc8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Trained Agent, after training using property\n",
        "# from stable_baselines.common.evaluation import evaluate_policy\n",
        "max_r, mean_r, min_r = evaluate(agent_model, eval_env, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max reward: 0.4666666666666667 Mean reward: 0.004666666666666667 Min reward: 0.0 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP9AbAmzqDYP"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create save dir\n",
        "save_dir = \"/tmp/gym/\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLpmSgmeN6PX"
      },
      "source": [
        "### Extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIe43E_dSBRy"
      },
      "source": [
        "import gym_minigrid\n",
        "\n",
        "env = gym.make('MiniGrid-SimpleCrossingEnvUmaze-v0')\n",
        "for i_episode in range(3):\n",
        "    obs = env.reset()\n",
        "    for t_steps in range(100):\n",
        "        # env.render()\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        print(obs)\n",
        "        if done:\n",
        "            print(\"Episode finished after {} timesteps\".format(t_steps+1))\n",
        "            break\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df08vXY_MtHg"
      },
      "source": [
        "!apt update && apt install xvfb\n",
        "!pip install gym-notebook-wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4A_IOZ_9fzW"
      },
      "source": [
        "# Random Agent, before training using function\n",
        "mean_reward_before_train = evaluate(agent_model, eval_env, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXOU1gvsHyT"
      },
      "source": [
        "!pip install tensorboard==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuCkk1M-kPGP"
      },
      "source": [
        "# Trained Agent\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(agent_model, train_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA5AjICfkVZl"
      },
      "source": [
        "!tensorboard --logdir ./ppo2_minigriddoorkey/ --host localhost "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}