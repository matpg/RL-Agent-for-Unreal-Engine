{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo zoo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matpg/RL-Agent-for-Unreal-Engine/blob/main/Codigo_zoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJy9QoDC7XA7"
      },
      "source": [
        "# RL Baselines Zoo: Training in Colab\n",
        "\n",
        "\n",
        "\n",
        "Github Repo: [https://github.com/araffin/rl-baselines-zoo](https://github.com/araffin/rl-baselines-zoo)\n",
        "\n",
        "Stable-Baselines Repo: [https://github.com/hill-a/stable-baselines](https://github.com/hill-a/stable-baselines)\n",
        "\n",
        "Medium article: [https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82](https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82)\n",
        "\n",
        "# Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXVDDlTn02M9",
        "outputId": "28ba35ec-b5da-4465-8b00-c54a59e58479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!apt-get update\n",
        "!apt-get install swig cmake libopenmpi-dev zlib1g-dev ffmpeg freeglut3-dev xvfb\n",
        "!pip install stable-baselines[mpi] --upgrade\n",
        "!pip install pybullet\n",
        "!pip install box2d box2d-kengz pyyaml pytablewriter optuna scikit-optimize\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [407 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,354 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,688 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,750 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [46.3 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [247 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,128 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,196 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.6 kB]\n",
            "Fetched 11.0 MB in 4s (2,610 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0 xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,884 kB of archives.\n",
            "After this operation, 8,089 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7 [783 kB]\n",
            "Fetched 1,884 kB in 1s (1,354 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 144786 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting stable-baselines[mpi]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/48/d428b79bd4360727925f9fe34afeea7a9da381da3dc8748df834a349ad1d/stable_baselines-2.10.1-py3-none-any.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.3)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.6)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Installing collected packages: stable-baselines\n",
            "  Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.1\n",
            "Collecting pybullet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/61/2fc2c19327966ca4e4133211be3f4dcc56c1ee6f392d71d0da8c6c1a4cba/pybullet-3.0.6-cp36-cp36m-manylinux1_x86_64.whl (102.2MB)\n",
            "\u001b[K     |████████████████████████████████| 102.2MB 41kB/s \n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.0.6\n",
            "Collecting box2d\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/0b/d48d42dd9e19ce83a3fb4eee074e785b6c6ea612a2244dc2ef69427d338b/Box2D-2.3.10-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 4.9MB/s \n",
            "\u001b[?25hCollecting box2d-kengz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/20/51d6c0c87f7642efb709c518fb0ca8e5eab068259588552c41da5926ae27/Box2D-kengz-2.3.3.tar.gz (425kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 22.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting pytablewriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/e2/62b208cdb8771dee1849bd2b4ed129284e1efff7669985697e4c124c1000/pytablewriter-0.58.0-py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.7MB/s \n",
            "\u001b[?25hCollecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 23.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.7MB/s \n",
            "\u001b[?25hCollecting pathvalidate<3,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/fa/1a951084aa93940399800e37ed6f096ad5c0de3c26604be62f9464a39fc1/pathvalidate-2.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (50.3.2)\n",
            "Collecting tabledata<2,>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/df/b2/264d9707502f0259a3eb82ec48064df98b1735d5a5f315b6a1d7105263f4/tabledata-1.1.3-py3-none-any.whl\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/02/51/bbb0cc7f30771c285c354634bf83653a2871d58c6923bd29bfddeb9c9cb1/tcolorpy-0.0.8-py3-none-any.whl\n",
            "Collecting typepy[datetime]<2,>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/55/a1111b2eb1f4096c28b14645ca62aec560b1768338af21620e470b60872f/typepy-1.1.1-py3-none-any.whl\n",
            "Collecting msgfy<1,>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/48/52/c4441871514276e7c4cb51c122e663b5ef19dc20030f6ab7723071118464/msgfy-0.1.0-py3-none-any.whl\n",
            "Collecting DataProperty<2,>=0.50.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/2d/e5413965af992f4e489b6f5eebf52db9c17953c772962d1223d434b05cef/DataProperty-0.50.0-py3-none-any.whl\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/57/3bb55beafe0a5e9883621f01a560d16bcef6d4f844dc2dd40caa0a8d9182/mbstrdecoder-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.17.0)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.5MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/c8/c16d30bbed11a1722060014c246d124582d1f781b26f5859d8dacc3e08e1/colorlog-4.6.2-py2.py3-none-any.whl\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2018.9; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.4 in /usr/local/lib/python3.6/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter) (3.0.4)\n",
            "Collecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/94/0f4f16cff4977188d715a95ea3f90f054b7eb73b05afaf51431a3d77b992/cmd2-1.3.11-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 29.3MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a1/004f04ba411a8002b02aadb089fd6868116c12ddc9f6d576175e89d07587/stevedore-3.2.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (2.0.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.4.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=26050b311c325a7ecbad68a4562675f9e3184f3af1103a96b3ba1a886f3479ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: box2d-kengz, PrettyTable, pyperclip\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp36-cp36m-linux_x86_64.whl size=2024813 sha256=356ea7e601d372aa93ac7b031d0449838bc52992e038be47b6b77aaa9ded17e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/ae/e5/8bc678d262caad94659c199c540550e59d03dd3bd3684d4f1a\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=4fd8109dac3983053fc1655ea68f72c0e1785c3eeb1217dcc0e0a3ee9b5d344c\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=d783c372754a76d058bccec145447ddbd73d221f15aa38d6f75ff88610752aa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built box2d-kengz PrettyTable pyperclip\n",
            "Installing collected packages: box2d, box2d-kengz, pathvalidate, mbstrdecoder, typepy, DataProperty, tabledata, tcolorpy, msgfy, pytablewriter, PrettyTable, pbr, pyperclip, colorama, cmd2, stevedore, cliff, Mako, python-editor, alembic, colorlog, cmaes, optuna, pyaml, scikit-optimize\n",
            "  Found existing installation: prettytable 1.0.1\n",
            "    Uninstalling prettytable-1.0.1:\n",
            "      Successfully uninstalled prettytable-1.0.1\n",
            "Successfully installed DataProperty-0.50.0 Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 box2d-2.3.10 box2d-kengz-2.3.3 cliff-3.4.0 cmaes-0.7.0 cmd2-1.3.11 colorama-0.4.4 colorlog-4.6.2 mbstrdecoder-1.0.0 msgfy-0.1.0 optuna-2.3.0 pathvalidate-2.3.0 pbr-5.5.1 pyaml-20.4.0 pyperclip-1.8.1 pytablewriter-0.58.0 python-editor-1.0.4 scikit-optimize-0.8.1 stevedore-3.2.2 tabledata-1.1.3 tcolorpy-0.0.8 typepy-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjF3qRg7oGH"
      },
      "source": [
        "## Clone RL Baselines Zoo Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCjGikdT1DFy",
        "outputId": "e2fd0fa5-1404-489e-b8dc-48e2b92389a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rl-baselines-zoo'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1829 (delta 12), reused 18 (delta 8), pack-reused 1796\u001b[K\n",
            "Receiving objects: 100% (1829/1829), 375.67 MiB | 35.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1077/1077), done.\n",
            "Checking out files: 100% (333/333), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMQlh-ezyVt",
        "outputId": "ec1fc116-0397-4f26-b3aa-7f14358890b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd rl-baselines-zoo/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rl-baselines-zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ-pAbF7zRZ"
      },
      "source": [
        "## Train an RL Agent\n",
        "\n",
        "\n",
        "The train agent can be found in the `logs/` folder.\n",
        "\n",
        "Here we will train A2C on CartPole-v1 environment for 100 000 steps. \n",
        "\n",
        "\n",
        "To train it on Pong (Atari), you just have to pass `--env PongNoFrameskip-v4`\n",
        "\n",
        "Note: You need to update `hyperparams/algo.yml` to support new environments. You can access it in the side panel of Google Colab. (see https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34lXM8ZfMQfG",
        "outputId": "2ce6f72a-2936-4523-a447-4d8483428ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gym-minigrid\n",
        "# go to gym-minigrid in \"/usr/local/lib/python3.6/dist-packages/gym_minigrid/envs\" and replace the modeled crossing env"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym-minigrid\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/57/15171eff6222dd012cc89c001f5c50ad9e11b8cef385873db3b4c0d89aff/gym_minigrid-1.0.1-py3-none-any.whl (47kB)\n",
            "\r\u001b[K     |███████                         | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 40kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from gym-minigrid) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from gym-minigrid) (1.18.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.6->gym-minigrid) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.6->gym-minigrid) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.6->gym-minigrid) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.9.6->gym-minigrid) (0.16.0)\n",
            "Installing collected packages: gym-minigrid\n",
            "Successfully installed gym-minigrid-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmsGh9A8p4NO",
        "outputId": "2b691bb7-a4bd-470e-a375-70d86427dca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# moving the mod crossing file (U MAZE MODELED) to the destination path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%rm \"/usr/local/lib/python3.6/dist-packages/gym_minigrid/envs/crossing.py\"\n",
        "%mv \"/content/drive/My Drive/Colab Notebooks/crossing.py\" \"/usr/local/lib/python3.6/dist-packages/gym_minigrid/envs\"\n",
        "\n",
        "#SIMULTANEAMENTE SE DEBE REEMPLAZAR LA INFORMACIÓN DEL ENTORNO EN LOS HIPERPARAMETROS PPO2 DEL PAQUETE ZOO\n",
        "%rm \"/content/rl-baselines-zoo/hyperparams/ppo2.yml\"\n",
        "%mv \"/content/drive/My Drive/Colab Notebooks/ppo2.yml\" \"/content/rl-baselines-zoo/hyperparams\"\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bIR_N7R11XI",
        "outputId": "ad8aeb0e-3ae2-4e21-8de1-4e6b3fb2b8c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!python train.py --algo ppo2 --env MiniGrid-SimpleCrossingEnvUmaze-v0 --gym-packages gym_minigrid\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "| serial_timesteps   | 338432        |\n",
            "| time_elapsed       | 3.04e+03      |\n",
            "| total_timesteps    | 2707456       |\n",
            "| value_loss         | 0.002713275   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2710000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.3245043e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 918           |\n",
            "| n_updates          | 662           |\n",
            "| policy_entropy     | 5.772765e-05  |\n",
            "| policy_loss        | 9.335054e-10  |\n",
            "| serial_timesteps   | 338944        |\n",
            "| time_elapsed       | 3.05e+03      |\n",
            "| total_timesteps    | 2711552       |\n",
            "| value_loss         | 0.0026911618  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.9797762e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 960           |\n",
            "| n_updates          | 663           |\n",
            "| policy_entropy     | 5.8263897e-05 |\n",
            "| policy_loss        | 1.2129021e-09 |\n",
            "| serial_timesteps   | 339456        |\n",
            "| time_elapsed       | 3.05e+03      |\n",
            "| total_timesteps    | 2715648       |\n",
            "| value_loss         | 0.0026685135  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.0487514e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 953           |\n",
            "| n_updates          | 664           |\n",
            "| policy_entropy     | 5.9554488e-05 |\n",
            "| policy_loss        | 6.2282196e-10 |\n",
            "| serial_timesteps   | 339968        |\n",
            "| time_elapsed       | 3.06e+03      |\n",
            "| total_timesteps    | 2719744       |\n",
            "| value_loss         | 0.0026831408  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2720000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 5.722898e-15 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.851        |\n",
            "| fps                | 897          |\n",
            "| n_updates          | 665          |\n",
            "| policy_entropy     | 6.100772e-05 |\n",
            "| policy_loss        | 2.474735e-09 |\n",
            "| serial_timesteps   | 340480       |\n",
            "| time_elapsed       | 3.06e+03     |\n",
            "| total_timesteps    | 2723840      |\n",
            "| value_loss         | 0.0026860128 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.406277e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 959           |\n",
            "| n_updates          | 666           |\n",
            "| policy_entropy     | 5.9321777e-05 |\n",
            "| policy_loss        | -9.199948e-09 |\n",
            "| serial_timesteps   | 340992        |\n",
            "| time_elapsed       | 3.06e+03      |\n",
            "| total_timesteps    | 2727936       |\n",
            "| value_loss         | 0.002693512   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2730000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1813994e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 910           |\n",
            "| n_updates          | 667           |\n",
            "| policy_entropy     | 5.7508638e-05 |\n",
            "| policy_loss        | 1.000626e-09  |\n",
            "| serial_timesteps   | 341504        |\n",
            "| time_elapsed       | 3.07e+03      |\n",
            "| total_timesteps    | 2732032       |\n",
            "| value_loss         | 0.0026952054  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 9.430782e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 964           |\n",
            "| n_updates          | 668           |\n",
            "| policy_entropy     | 5.782477e-05  |\n",
            "| policy_loss        | 1.1164957e-09 |\n",
            "| serial_timesteps   | 342016        |\n",
            "| time_elapsed       | 3.07e+03      |\n",
            "| total_timesteps    | 2736128       |\n",
            "| value_loss         | 0.0026744779  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2740000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 2.435794e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 915           |\n",
            "| n_updates          | 669           |\n",
            "| policy_entropy     | 5.7407957e-05 |\n",
            "| policy_loss        | 1.4035322e-09 |\n",
            "| serial_timesteps   | 342528        |\n",
            "| time_elapsed       | 3.08e+03      |\n",
            "| total_timesteps    | 2740224       |\n",
            "| value_loss         | 0.0026910664  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.0374683e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 975           |\n",
            "| n_updates          | 670           |\n",
            "| policy_entropy     | 5.7874568e-05 |\n",
            "| policy_loss        | 3.1286618e-10 |\n",
            "| serial_timesteps   | 343040        |\n",
            "| time_elapsed       | 3.08e+03      |\n",
            "| total_timesteps    | 2744320       |\n",
            "| value_loss         | 0.0026910263  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.343834e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 952           |\n",
            "| n_updates          | 671           |\n",
            "| policy_entropy     | 5.8600875e-05 |\n",
            "| policy_loss        | 8.047209e-10  |\n",
            "| serial_timesteps   | 343552        |\n",
            "| time_elapsed       | 3.09e+03      |\n",
            "| total_timesteps    | 2748416       |\n",
            "| value_loss         | 0.0026945912  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2750000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4783656e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 884           |\n",
            "| n_updates          | 672           |\n",
            "| policy_entropy     | 5.842126e-05  |\n",
            "| policy_loss        | 1.3809768e-09 |\n",
            "| serial_timesteps   | 344064        |\n",
            "| time_elapsed       | 3.09e+03      |\n",
            "| total_timesteps    | 2752512       |\n",
            "| value_loss         | 0.0027031645  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.0991806e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 956           |\n",
            "| n_updates          | 673           |\n",
            "| policy_entropy     | 5.981855e-05  |\n",
            "| policy_loss        | 1.0593795e-09 |\n",
            "| serial_timesteps   | 344576        |\n",
            "| time_elapsed       | 3.09e+03      |\n",
            "| total_timesteps    | 2756608       |\n",
            "| value_loss         | 0.0027356585  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2760000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.1432982e-15  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 916            |\n",
            "| n_updates          | 674            |\n",
            "| policy_entropy     | 6.0196915e-05  |\n",
            "| policy_loss        | -3.2196112e-10 |\n",
            "| serial_timesteps   | 345088         |\n",
            "| time_elapsed       | 3.1e+03        |\n",
            "| total_timesteps    | 2760704        |\n",
            "| value_loss         | 0.002695664    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.2029446e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 939            |\n",
            "| n_updates          | 675            |\n",
            "| policy_entropy     | 5.945765e-05   |\n",
            "| policy_loss        | -1.4653778e-09 |\n",
            "| serial_timesteps   | 345600         |\n",
            "| time_elapsed       | 3.1e+03        |\n",
            "| total_timesteps    | 2764800        |\n",
            "| value_loss         | 0.0027014473   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.726916e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 977            |\n",
            "| n_updates          | 676            |\n",
            "| policy_entropy     | 5.9579597e-05  |\n",
            "| policy_loss        | -2.3275788e-09 |\n",
            "| serial_timesteps   | 346112         |\n",
            "| time_elapsed       | 3.11e+03       |\n",
            "| total_timesteps    | 2768896        |\n",
            "| value_loss         | 0.002716234    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2770000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 2.1472797e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.849         |\n",
            "| fps                | 922           |\n",
            "| n_updates          | 677           |\n",
            "| policy_entropy     | 5.8622325e-05 |\n",
            "| policy_loss        | -8.547067e-09 |\n",
            "| serial_timesteps   | 346624        |\n",
            "| time_elapsed       | 3.11e+03      |\n",
            "| total_timesteps    | 2772992       |\n",
            "| value_loss         | 0.0027097848  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.65287e-14   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 965           |\n",
            "| n_updates          | 678           |\n",
            "| policy_entropy     | 5.564512e-05  |\n",
            "| policy_loss        | -2.687011e-09 |\n",
            "| serial_timesteps   | 347136        |\n",
            "| time_elapsed       | 3.12e+03      |\n",
            "| total_timesteps    | 2777088       |\n",
            "| value_loss         | 0.002689621   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2780000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 4.394047e-15 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.85         |\n",
            "| fps                | 896          |\n",
            "| n_updates          | 679          |\n",
            "| policy_entropy     | 5.504727e-05 |\n",
            "| policy_loss        | 9.626092e-10 |\n",
            "| serial_timesteps   | 347648       |\n",
            "| time_elapsed       | 3.12e+03     |\n",
            "| total_timesteps    | 2781184      |\n",
            "| value_loss         | 0.0026915453 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.9416905e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 945           |\n",
            "| n_updates          | 680           |\n",
            "| policy_entropy     | 5.488411e-05  |\n",
            "| policy_loss        | 1.4770193e-10 |\n",
            "| serial_timesteps   | 348160        |\n",
            "| time_elapsed       | 3.13e+03      |\n",
            "| total_timesteps    | 2785280       |\n",
            "| value_loss         | 0.0026820644  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.5442806e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 953            |\n",
            "| n_updates          | 681            |\n",
            "| policy_entropy     | 5.5180826e-05  |\n",
            "| policy_loss        | -1.7360435e-09 |\n",
            "| serial_timesteps   | 348672         |\n",
            "| time_elapsed       | 3.13e+03       |\n",
            "| total_timesteps    | 2789376        |\n",
            "| value_loss         | 0.0026512116   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2790000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.10339255e-13 |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 906            |\n",
            "| n_updates          | 682            |\n",
            "| policy_entropy     | 5.4689073e-05  |\n",
            "| policy_loss        | -5.537731e-09  |\n",
            "| serial_timesteps   | 349184         |\n",
            "| time_elapsed       | 3.13e+03       |\n",
            "| total_timesteps    | 2793472        |\n",
            "| value_loss         | 0.0026752786   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 5.719208e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 964           |\n",
            "| n_updates          | 683           |\n",
            "| policy_entropy     | 5.298724e-05  |\n",
            "| policy_loss        | 4.5693013e-10 |\n",
            "| serial_timesteps   | 349696        |\n",
            "| time_elapsed       | 3.14e+03      |\n",
            "| total_timesteps    | 2797568       |\n",
            "| value_loss         | 0.0026841997  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2800000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4484053e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 917           |\n",
            "| n_updates          | 684           |\n",
            "| policy_entropy     | 5.3343898e-05 |\n",
            "| policy_loss        | 1.9645086e-11 |\n",
            "| serial_timesteps   | 350208        |\n",
            "| time_elapsed       | 3.14e+03      |\n",
            "| total_timesteps    | 2801664       |\n",
            "| value_loss         | 0.0027068963  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3671184e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 938           |\n",
            "| n_updates          | 685           |\n",
            "| policy_entropy     | 5.4323085e-05 |\n",
            "| policy_loss        | 1.7316779e-10 |\n",
            "| serial_timesteps   | 350720        |\n",
            "| time_elapsed       | 3.15e+03      |\n",
            "| total_timesteps    | 2805760       |\n",
            "| value_loss         | 0.0026645148  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.6246908e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 947           |\n",
            "| n_updates          | 686           |\n",
            "| policy_entropy     | 5.548873e-05  |\n",
            "| policy_loss        | 1.0542862e-09 |\n",
            "| serial_timesteps   | 351232        |\n",
            "| time_elapsed       | 3.15e+03      |\n",
            "| total_timesteps    | 2809856       |\n",
            "| value_loss         | 0.0026892226  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2810000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.5117786e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 913           |\n",
            "| n_updates          | 687           |\n",
            "| policy_entropy     | 5.5129458e-05 |\n",
            "| policy_loss        | -7.887138e-10 |\n",
            "| serial_timesteps   | 351744        |\n",
            "| time_elapsed       | 3.16e+03      |\n",
            "| total_timesteps    | 2813952       |\n",
            "| value_loss         | 0.0026811273  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.0119252e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 949           |\n",
            "| n_updates          | 688           |\n",
            "| policy_entropy     | 5.3793607e-05 |\n",
            "| policy_loss        | 2.2570021e-09 |\n",
            "| serial_timesteps   | 352256        |\n",
            "| time_elapsed       | 3.16e+03      |\n",
            "| total_timesteps    | 2818048       |\n",
            "| value_loss         | 0.0027000098  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2820000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 4.926555e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 917            |\n",
            "| n_updates          | 689            |\n",
            "| policy_entropy     | 5.2407926e-05  |\n",
            "| policy_loss        | -2.6229827e-09 |\n",
            "| serial_timesteps   | 352768         |\n",
            "| time_elapsed       | 3.16e+03       |\n",
            "| total_timesteps    | 2822144        |\n",
            "| value_loss         | 0.0026773715   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.257645e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.849          |\n",
            "| fps                | 929            |\n",
            "| n_updates          | 690            |\n",
            "| policy_entropy     | 5.177028e-05   |\n",
            "| policy_loss        | -1.9339494e-09 |\n",
            "| serial_timesteps   | 353280         |\n",
            "| time_elapsed       | 3.17e+03       |\n",
            "| total_timesteps    | 2826240        |\n",
            "| value_loss         | 0.0026539047   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2830000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 4.0663023e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.849          |\n",
            "| fps                | 913            |\n",
            "| n_updates          | 691            |\n",
            "| policy_entropy     | 5.332405e-05   |\n",
            "| policy_loss        | -2.5989721e-09 |\n",
            "| serial_timesteps   | 353792         |\n",
            "| time_elapsed       | 3.17e+03       |\n",
            "| total_timesteps    | 2830336        |\n",
            "| value_loss         | 0.0026716904   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00051859993  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 946            |\n",
            "| n_updates          | 692            |\n",
            "| policy_entropy     | 0.0002007419   |\n",
            "| policy_loss        | -5.4897828e-05 |\n",
            "| serial_timesteps   | 354304         |\n",
            "| time_elapsed       | 3.18e+03       |\n",
            "| total_timesteps    | 2834432        |\n",
            "| value_loss         | 0.002689173    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.6420172e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 962            |\n",
            "| n_updates          | 693            |\n",
            "| policy_entropy     | 0.00022344683  |\n",
            "| policy_loss        | -4.7809227e-08 |\n",
            "| serial_timesteps   | 354816         |\n",
            "| time_elapsed       | 3.18e+03       |\n",
            "| total_timesteps    | 2838528        |\n",
            "| value_loss         | 0.0027146793   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2840000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.3165252e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.849          |\n",
            "| fps                | 909            |\n",
            "| n_updates          | 694            |\n",
            "| policy_entropy     | 0.00023019058  |\n",
            "| policy_loss        | -2.3384927e-09 |\n",
            "| serial_timesteps   | 355328         |\n",
            "| time_elapsed       | 3.19e+03       |\n",
            "| total_timesteps    | 2842624        |\n",
            "| value_loss         | 0.0026515783   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.426618e-14  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 943           |\n",
            "| n_updates          | 695           |\n",
            "| policy_entropy     | 0.00022226544 |\n",
            "| policy_loss        | 8.694769e-09  |\n",
            "| serial_timesteps   | 355840        |\n",
            "| time_elapsed       | 3.19e+03      |\n",
            "| total_timesteps    | 2846720       |\n",
            "| value_loss         | 0.0026560957  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2850000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.28659e-13   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 903           |\n",
            "| n_updates          | 696           |\n",
            "| policy_entropy     | 0.00021904625 |\n",
            "| policy_loss        | 6.708433e-09  |\n",
            "| serial_timesteps   | 356352        |\n",
            "| time_elapsed       | 3.2e+03       |\n",
            "| total_timesteps    | 2850816       |\n",
            "| value_loss         | 0.002664412   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.9579273e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 943           |\n",
            "| n_updates          | 697           |\n",
            "| policy_entropy     | 0.00022311551 |\n",
            "| policy_loss        | -2.01675e-08  |\n",
            "| serial_timesteps   | 356864        |\n",
            "| time_elapsed       | 3.2e+03       |\n",
            "| total_timesteps    | 2854912       |\n",
            "| value_loss         | 0.002684768   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4148201e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 957           |\n",
            "| n_updates          | 698           |\n",
            "| policy_entropy     | 0.00023327717 |\n",
            "| policy_loss        | 1.333392e-08  |\n",
            "| serial_timesteps   | 357376        |\n",
            "| time_elapsed       | 3.2e+03       |\n",
            "| total_timesteps    | 2859008       |\n",
            "| value_loss         | 0.002723881   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2860000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3974762e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 920           |\n",
            "| n_updates          | 699           |\n",
            "| policy_entropy     | 0.00023435868 |\n",
            "| policy_loss        | 9.503128e-09  |\n",
            "| serial_timesteps   | 357888        |\n",
            "| time_elapsed       | 3.21e+03      |\n",
            "| total_timesteps    | 2863104       |\n",
            "| value_loss         | 0.0026904766  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.18779205e-11 |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 967            |\n",
            "| n_updates          | 700            |\n",
            "| policy_entropy     | 0.00022688741  |\n",
            "| policy_loss        | -2.8395153e-08 |\n",
            "| serial_timesteps   | 358400         |\n",
            "| time_elapsed       | 3.21e+03       |\n",
            "| total_timesteps    | 2867200        |\n",
            "| value_loss         | 0.0026574933   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2870000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.330312e-12  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 888           |\n",
            "| n_updates          | 701           |\n",
            "| policy_entropy     | 0.00020559938 |\n",
            "| policy_loss        | 3.8344297e-09 |\n",
            "| serial_timesteps   | 358912        |\n",
            "| time_elapsed       | 3.22e+03      |\n",
            "| total_timesteps    | 2871296       |\n",
            "| value_loss         | 0.0027008879  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.2138284e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 942           |\n",
            "| n_updates          | 702           |\n",
            "| policy_entropy     | 0.00020199278 |\n",
            "| policy_loss        | 1.1779775e-08 |\n",
            "| serial_timesteps   | 359424        |\n",
            "| time_elapsed       | 3.22e+03      |\n",
            "| total_timesteps    | 2875392       |\n",
            "| value_loss         | 0.0026870037  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 6.4322068e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 963            |\n",
            "| n_updates          | 703            |\n",
            "| policy_entropy     | 0.00021429539  |\n",
            "| policy_loss        | -4.3728505e-09 |\n",
            "| serial_timesteps   | 359936         |\n",
            "| time_elapsed       | 3.23e+03       |\n",
            "| total_timesteps    | 2879488        |\n",
            "| value_loss         | 0.0026884316   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2880000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 7.530544e-11   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 910            |\n",
            "| n_updates          | 704            |\n",
            "| policy_entropy     | 0.0002586978   |\n",
            "| policy_loss        | -1.2318779e-07 |\n",
            "| serial_timesteps   | 360448         |\n",
            "| time_elapsed       | 3.23e+03       |\n",
            "| total_timesteps    | 2883584        |\n",
            "| value_loss         | 0.0027074744   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 7.6689446e-11  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 965            |\n",
            "| n_updates          | 705            |\n",
            "| policy_entropy     | 0.00027155652  |\n",
            "| policy_loss        | -9.1915716e-08 |\n",
            "| serial_timesteps   | 360960         |\n",
            "| time_elapsed       | 3.24e+03       |\n",
            "| total_timesteps    | 2887680        |\n",
            "| value_loss         | 0.0026937102   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2890000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| approxkl           | 0.0005504413    |\n",
            "| clipfrac           | 0.00021972656   |\n",
            "| ep_len_mean        | 16              |\n",
            "| ep_reward_mean     | 0.956           |\n",
            "| explained_variance | 0.851           |\n",
            "| fps                | 917             |\n",
            "| n_updates          | 706             |\n",
            "| policy_entropy     | 6.339694e-05    |\n",
            "| policy_loss        | -0.000112735994 |\n",
            "| serial_timesteps   | 361472          |\n",
            "| time_elapsed       | 3.24e+03        |\n",
            "| total_timesteps    | 2891776         |\n",
            "| value_loss         | 0.0026617697    |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3808346e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 957           |\n",
            "| n_updates          | 707           |\n",
            "| policy_entropy     | 5.8369034e-05 |\n",
            "| policy_loss        | 7.2359396e-10 |\n",
            "| serial_timesteps   | 361984        |\n",
            "| time_elapsed       | 3.24e+03      |\n",
            "| total_timesteps    | 2895872       |\n",
            "| value_loss         | 0.0026677041  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3546403e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 939           |\n",
            "| n_updates          | 708           |\n",
            "| policy_entropy     | 5.8533293e-05 |\n",
            "| policy_loss        | 7.530616e-10  |\n",
            "| serial_timesteps   | 362496        |\n",
            "| time_elapsed       | 3.25e+03      |\n",
            "| total_timesteps    | 2899968       |\n",
            "| value_loss         | 0.0026714832  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2900000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.045634e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 915           |\n",
            "| n_updates          | 709           |\n",
            "| policy_entropy     | 5.8470418e-05 |\n",
            "| policy_loss        | 1.2828423e-10 |\n",
            "| serial_timesteps   | 363008        |\n",
            "| time_elapsed       | 3.25e+03      |\n",
            "| total_timesteps    | 2904064       |\n",
            "| value_loss         | 0.0026466646  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.5006934e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 947            |\n",
            "| n_updates          | 710            |\n",
            "| policy_entropy     | 5.857046e-05   |\n",
            "| policy_loss        | -1.0739314e-09 |\n",
            "| serial_timesteps   | 363520         |\n",
            "| time_elapsed       | 3.26e+03       |\n",
            "| total_timesteps    | 2908160        |\n",
            "| value_loss         | 0.0026537327   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2910000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.7589558e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 897           |\n",
            "| n_updates          | 711           |\n",
            "| policy_entropy     | 5.857269e-05  |\n",
            "| policy_loss        | 3.3105607e-10 |\n",
            "| serial_timesteps   | 364032        |\n",
            "| time_elapsed       | 3.26e+03      |\n",
            "| total_timesteps    | 2912256       |\n",
            "| value_loss         | 0.002655453   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 932            |\n",
            "| n_updates          | 712            |\n",
            "| policy_entropy     | 5.8429454e-05  |\n",
            "| policy_loss        | -2.1827873e-11 |\n",
            "| serial_timesteps   | 364544         |\n",
            "| time_elapsed       | 3.27e+03       |\n",
            "| total_timesteps    | 2916352        |\n",
            "| value_loss         | 0.0026606184   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2920000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 6.8779737e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 903           |\n",
            "| n_updates          | 713           |\n",
            "| policy_entropy     | 5.8553902e-05 |\n",
            "| policy_loss        | -7.976268e-11 |\n",
            "| serial_timesteps   | 365056        |\n",
            "| time_elapsed       | 3.27e+03      |\n",
            "| total_timesteps    | 2920448       |\n",
            "| value_loss         | 0.0026725563  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.8518645e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 936            |\n",
            "| n_updates          | 714            |\n",
            "| policy_entropy     | 5.8491172e-05  |\n",
            "| policy_loss        | -3.6961864e-10 |\n",
            "| serial_timesteps   | 365568         |\n",
            "| time_elapsed       | 3.27e+03       |\n",
            "| total_timesteps    | 2924544        |\n",
            "| value_loss         | 0.0026737049   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 960           |\n",
            "| n_updates          | 715           |\n",
            "| policy_entropy     | 5.819146e-05  |\n",
            "| policy_loss        | 4.2737155e-10 |\n",
            "| serial_timesteps   | 366080        |\n",
            "| time_elapsed       | 3.28e+03      |\n",
            "| total_timesteps    | 2928640       |\n",
            "| value_loss         | 0.002666879   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2930000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 3.0008885e-17  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 919            |\n",
            "| n_updates          | 716            |\n",
            "| policy_entropy     | 5.820971e-05   |\n",
            "| policy_loss        | -1.2820237e-09 |\n",
            "| serial_timesteps   | 366592         |\n",
            "| time_elapsed       | 3.28e+03       |\n",
            "| total_timesteps    | 2932736        |\n",
            "| value_loss         | 0.0026604242   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 3.7155516e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 964            |\n",
            "| n_updates          | 717            |\n",
            "| policy_entropy     | 5.830124e-05   |\n",
            "| policy_loss        | -8.6802177e-10 |\n",
            "| serial_timesteps   | 367104         |\n",
            "| time_elapsed       | 3.29e+03       |\n",
            "| total_timesteps    | 2936832        |\n",
            "| value_loss         | 0.002626495    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2940000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3703479e-17 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 922           |\n",
            "| n_updates          | 718           |\n",
            "| policy_entropy     | 5.836761e-05  |\n",
            "| policy_loss        | 9.575161e-10  |\n",
            "| serial_timesteps   | 367616        |\n",
            "| time_elapsed       | 3.29e+03      |\n",
            "| total_timesteps    | 2940928       |\n",
            "| value_loss         | 0.0026699733  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.7182875e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 958            |\n",
            "| n_updates          | 719            |\n",
            "| policy_entropy     | 5.8399844e-05  |\n",
            "| policy_loss        | -3.0850061e-10 |\n",
            "| serial_timesteps   | 368128         |\n",
            "| time_elapsed       | 3.3e+03        |\n",
            "| total_timesteps    | 2945024        |\n",
            "| value_loss         | 0.002641766    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 3.622127e-15   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 944            |\n",
            "| n_updates          | 720            |\n",
            "| policy_entropy     | 5.863047e-05   |\n",
            "| policy_loss        | 1.07684174e-10 |\n",
            "| serial_timesteps   | 368640         |\n",
            "| time_elapsed       | 3.3e+03        |\n",
            "| total_timesteps    | 2949120        |\n",
            "| value_loss         | 0.0026695395   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=2950000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.4477853e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 721           |\n",
            "| policy_entropy     | 5.8733312e-05 |\n",
            "| policy_loss        | 6.184564e-11  |\n",
            "| serial_timesteps   | 369152        |\n",
            "| time_elapsed       | 3.31e+03      |\n",
            "| total_timesteps    | 2953216       |\n",
            "| value_loss         | 0.002633421   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.1988364e-17 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 942           |\n",
            "| n_updates          | 722           |\n",
            "| policy_entropy     | 5.8363534e-05 |\n",
            "| policy_loss        | 2.066372e-10  |\n",
            "| serial_timesteps   | 369664        |\n",
            "| time_elapsed       | 3.31e+03      |\n",
            "| total_timesteps    | 2957312       |\n",
            "| value_loss         | 0.002601819   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2960000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.197037e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 723           |\n",
            "| policy_entropy     | 5.842881e-05  |\n",
            "| policy_loss        | 1.3009412e-09 |\n",
            "| serial_timesteps   | 370176        |\n",
            "| time_elapsed       | 3.31e+03      |\n",
            "| total_timesteps    | 2961408       |\n",
            "| value_loss         | 0.0026133829  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.05331715e-14 |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 958            |\n",
            "| n_updates          | 724            |\n",
            "| policy_entropy     | 5.923685e-05   |\n",
            "| policy_loss        | 7.3050616e-10  |\n",
            "| serial_timesteps   | 370688         |\n",
            "| time_elapsed       | 3.32e+03       |\n",
            "| total_timesteps    | 2965504        |\n",
            "| value_loss         | 0.0026445086   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.569946e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 954           |\n",
            "| n_updates          | 725           |\n",
            "| policy_entropy     | 5.9674156e-05 |\n",
            "| policy_loss        | 2.6255293e-09 |\n",
            "| serial_timesteps   | 371200        |\n",
            "| time_elapsed       | 3.32e+03      |\n",
            "| total_timesteps    | 2969600       |\n",
            "| value_loss         | 0.0026259804  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2970000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 2.4897155e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 909            |\n",
            "| n_updates          | 726            |\n",
            "| policy_entropy     | 6.0218008e-05  |\n",
            "| policy_loss        | -1.9397703e-09 |\n",
            "| serial_timesteps   | 371712         |\n",
            "| time_elapsed       | 3.33e+03       |\n",
            "| total_timesteps    | 2973696        |\n",
            "| value_loss         | 0.0026783843   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.9513794e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 954           |\n",
            "| n_updates          | 727           |\n",
            "| policy_entropy     | 6.061318e-05  |\n",
            "| policy_loss        | -6.388291e-10 |\n",
            "| serial_timesteps   | 372224        |\n",
            "| time_elapsed       | 3.33e+03      |\n",
            "| total_timesteps    | 2977792       |\n",
            "| value_loss         | 0.002618543   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2980000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.350624e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 914           |\n",
            "| n_updates          | 728           |\n",
            "| policy_entropy     | 6.0447353e-05 |\n",
            "| policy_loss        | 5.9972083e-10 |\n",
            "| serial_timesteps   | 372736        |\n",
            "| time_elapsed       | 3.34e+03      |\n",
            "| total_timesteps    | 2981888       |\n",
            "| value_loss         | 0.0026641532  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.753758e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 729           |\n",
            "| policy_entropy     | 6.045996e-05  |\n",
            "| policy_loss        | 2.0163498e-09 |\n",
            "| serial_timesteps   | 373248        |\n",
            "| time_elapsed       | 3.34e+03      |\n",
            "| total_timesteps    | 2985984       |\n",
            "| value_loss         | 0.0026635875  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=2990000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.351465e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 911           |\n",
            "| n_updates          | 730           |\n",
            "| policy_entropy     | 6.011626e-05  |\n",
            "| policy_loss        | 1.4151738e-09 |\n",
            "| serial_timesteps   | 373760        |\n",
            "| time_elapsed       | 3.34e+03      |\n",
            "| total_timesteps    | 2990080       |\n",
            "| value_loss         | 0.0026674396  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.6693773e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 957           |\n",
            "| n_updates          | 731           |\n",
            "| policy_entropy     | 5.9548212e-05 |\n",
            "| policy_loss        | 1.5788828e-09 |\n",
            "| serial_timesteps   | 374272        |\n",
            "| time_elapsed       | 3.35e+03      |\n",
            "| total_timesteps    | 2994176       |\n",
            "| value_loss         | 0.002645697   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 3.3058808e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 951            |\n",
            "| n_updates          | 732            |\n",
            "| policy_entropy     | 5.843279e-05   |\n",
            "| policy_loss        | -1.1765223e-09 |\n",
            "| serial_timesteps   | 374784         |\n",
            "| time_elapsed       | 3.35e+03       |\n",
            "| total_timesteps    | 2998272        |\n",
            "| value_loss         | 0.0025946822   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3000000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.7944273e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 911           |\n",
            "| n_updates          | 733           |\n",
            "| policy_entropy     | 5.8351834e-05 |\n",
            "| policy_loss        | 2.2846507e-10 |\n",
            "| serial_timesteps   | 375296        |\n",
            "| time_elapsed       | 3.36e+03      |\n",
            "| total_timesteps    | 3002368       |\n",
            "| value_loss         | 0.0026108867  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.011848e-14  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 968           |\n",
            "| n_updates          | 734           |\n",
            "| policy_entropy     | 5.8501442e-05 |\n",
            "| policy_loss        | 7.3123375e-11 |\n",
            "| serial_timesteps   | 375808        |\n",
            "| time_elapsed       | 3.36e+03      |\n",
            "| total_timesteps    | 3006464       |\n",
            "| value_loss         | 0.0026220535  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3010000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 3.6404903e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 916            |\n",
            "| n_updates          | 735            |\n",
            "| policy_entropy     | 5.692072e-05   |\n",
            "| policy_loss        | -1.1052179e-09 |\n",
            "| serial_timesteps   | 376320         |\n",
            "| time_elapsed       | 3.37e+03       |\n",
            "| total_timesteps    | 3010560        |\n",
            "| value_loss         | 0.0026259113   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.416532e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 935           |\n",
            "| n_updates          | 736           |\n",
            "| policy_entropy     | 5.623966e-05  |\n",
            "| policy_loss        | 1.0928488e-09 |\n",
            "| serial_timesteps   | 376832        |\n",
            "| time_elapsed       | 3.37e+03      |\n",
            "| total_timesteps    | 3014656       |\n",
            "| value_loss         | 0.002655082   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 5.68068e-14   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 946           |\n",
            "| n_updates          | 737           |\n",
            "| policy_entropy     | 5.5269695e-05 |\n",
            "| policy_loss        | -3.715104e-09 |\n",
            "| serial_timesteps   | 377344        |\n",
            "| time_elapsed       | 3.38e+03      |\n",
            "| total_timesteps    | 3018752       |\n",
            "| value_loss         | 0.0026363505  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3020000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 3.2482853e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 926            |\n",
            "| n_updates          | 738            |\n",
            "| policy_entropy     | 5.345552e-05   |\n",
            "| policy_loss        | -2.0780135e-09 |\n",
            "| serial_timesteps   | 377856         |\n",
            "| time_elapsed       | 3.38e+03       |\n",
            "| total_timesteps    | 3022848        |\n",
            "| value_loss         | 0.0026558086   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 5.3930486e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 942           |\n",
            "| n_updates          | 739           |\n",
            "| policy_entropy     | 5.323714e-05  |\n",
            "| policy_loss        | 2.701563e-09  |\n",
            "| serial_timesteps   | 378368        |\n",
            "| time_elapsed       | 3.38e+03      |\n",
            "| total_timesteps    | 3026944       |\n",
            "| value_loss         | 0.0026663456  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3030000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.9423353e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 908            |\n",
            "| n_updates          | 740            |\n",
            "| policy_entropy     | 5.3060387e-05  |\n",
            "| policy_loss        | -3.8708095e-10 |\n",
            "| serial_timesteps   | 378880         |\n",
            "| time_elapsed       | 3.39e+03       |\n",
            "| total_timesteps    | 3031040        |\n",
            "| value_loss         | 0.0026381363   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.7589566e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 958           |\n",
            "| n_updates          | 741           |\n",
            "| policy_entropy     | 5.2794458e-05 |\n",
            "| policy_loss        | -5.646143e-10 |\n",
            "| serial_timesteps   | 379392        |\n",
            "| time_elapsed       | 3.39e+03      |\n",
            "| total_timesteps    | 3035136       |\n",
            "| value_loss         | 0.0026704161  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 8.310805e-16   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 956            |\n",
            "| n_updates          | 742            |\n",
            "| policy_entropy     | 5.265419e-05   |\n",
            "| policy_loss        | -4.5911291e-10 |\n",
            "| serial_timesteps   | 379904         |\n",
            "| time_elapsed       | 3.4e+03        |\n",
            "| total_timesteps    | 3039232        |\n",
            "| value_loss         | 0.0026319185   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3040000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.9365998e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 901           |\n",
            "| n_updates          | 743           |\n",
            "| policy_entropy     | 5.2562224e-05 |\n",
            "| policy_loss        | 5.3987603e-10 |\n",
            "| serial_timesteps   | 380416        |\n",
            "| time_elapsed       | 3.4e+03       |\n",
            "| total_timesteps    | 3043328       |\n",
            "| value_loss         | 0.0026423314  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.661512e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 956            |\n",
            "| n_updates          | 744            |\n",
            "| policy_entropy     | 5.2011066e-05  |\n",
            "| policy_loss        | -1.4406396e-09 |\n",
            "| serial_timesteps   | 380928         |\n",
            "| time_elapsed       | 3.41e+03       |\n",
            "| total_timesteps    | 3047424        |\n",
            "| value_loss         | 0.0026326217   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3050000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 3.8216073e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 909            |\n",
            "| n_updates          | 745            |\n",
            "| policy_entropy     | 5.1899075e-05  |\n",
            "| policy_loss        | -2.6600901e-09 |\n",
            "| serial_timesteps   | 381440         |\n",
            "| time_elapsed       | 3.41e+03       |\n",
            "| total_timesteps    | 3051520        |\n",
            "| value_loss         | 0.0026726243   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.2517273e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 959           |\n",
            "| n_updates          | 746           |\n",
            "| policy_entropy     | 5.276993e-05  |\n",
            "| policy_loss        | 2.3806934e-09 |\n",
            "| serial_timesteps   | 381952        |\n",
            "| time_elapsed       | 3.42e+03      |\n",
            "| total_timesteps    | 3055616       |\n",
            "| value_loss         | 0.0026763952  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3672749e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 945           |\n",
            "| n_updates          | 747           |\n",
            "| policy_entropy     | 5.2725576e-05 |\n",
            "| policy_loss        | 1.4159014e-09 |\n",
            "| serial_timesteps   | 382464        |\n",
            "| time_elapsed       | 3.42e+03      |\n",
            "| total_timesteps    | 3059712       |\n",
            "| value_loss         | 0.0026769985  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3060000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 9.314039e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 896           |\n",
            "| n_updates          | 748           |\n",
            "| policy_entropy     | 5.3157622e-05 |\n",
            "| policy_loss        | 3.979949e-10  |\n",
            "| serial_timesteps   | 382976        |\n",
            "| time_elapsed       | 3.42e+03      |\n",
            "| total_timesteps    | 3063808       |\n",
            "| value_loss         | 0.0026333882  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4026813e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 918           |\n",
            "| n_updates          | 749           |\n",
            "| policy_entropy     | 5.4102675e-05 |\n",
            "| policy_loss        | 1.3744283e-09 |\n",
            "| serial_timesteps   | 383488        |\n",
            "| time_elapsed       | 3.43e+03      |\n",
            "| total_timesteps    | 3067904       |\n",
            "| value_loss         | 0.0026545918  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3070000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 2.4385631e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 911           |\n",
            "| n_updates          | 750           |\n",
            "| policy_entropy     | 5.5100263e-05 |\n",
            "| policy_loss        | 5.4569682e-11 |\n",
            "| serial_timesteps   | 384000        |\n",
            "| time_elapsed       | 3.43e+03      |\n",
            "| total_timesteps    | 3072000       |\n",
            "| value_loss         | 0.0026658424  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.0767053e-15  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 946            |\n",
            "| n_updates          | 751            |\n",
            "| policy_entropy     | 5.5578003e-05  |\n",
            "| policy_loss        | -4.9476513e-11 |\n",
            "| serial_timesteps   | 384512         |\n",
            "| time_elapsed       | 3.44e+03       |\n",
            "| total_timesteps    | 3076096        |\n",
            "| value_loss         | 0.0026555818   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3080000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.5153585e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 918           |\n",
            "| n_updates          | 752           |\n",
            "| policy_entropy     | 5.4911834e-05 |\n",
            "| policy_loss        | 7.279596e-10  |\n",
            "| serial_timesteps   | 385024        |\n",
            "| time_elapsed       | 3.44e+03      |\n",
            "| total_timesteps    | 3080192       |\n",
            "| value_loss         | 0.0026357118  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4607637e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 966           |\n",
            "| n_updates          | 753           |\n",
            "| policy_entropy     | 5.4335727e-05 |\n",
            "| policy_loss        | 5.0822563e-10 |\n",
            "| serial_timesteps   | 385536        |\n",
            "| time_elapsed       | 3.45e+03      |\n",
            "| total_timesteps    | 3084288       |\n",
            "| value_loss         | 0.002633404   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.5841203e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 955           |\n",
            "| n_updates          | 754           |\n",
            "| policy_entropy     | 5.4708595e-05 |\n",
            "| policy_loss        | 1.0608346e-09 |\n",
            "| serial_timesteps   | 386048        |\n",
            "| time_elapsed       | 3.45e+03      |\n",
            "| total_timesteps    | 3088384       |\n",
            "| value_loss         | 0.0026628035  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3090000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.467095e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 755           |\n",
            "| policy_entropy     | 5.4869008e-05 |\n",
            "| policy_loss        | 1.2601958e-09 |\n",
            "| serial_timesteps   | 386560        |\n",
            "| time_elapsed       | 3.45e+03      |\n",
            "| total_timesteps    | 3092480       |\n",
            "| value_loss         | 0.002653209   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4945797e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 937           |\n",
            "| n_updates          | 756           |\n",
            "| policy_entropy     | 5.4938922e-05 |\n",
            "| policy_loss        | 6.6393113e-10 |\n",
            "| serial_timesteps   | 387072        |\n",
            "| time_elapsed       | 3.46e+03      |\n",
            "| total_timesteps    | 3096576       |\n",
            "| value_loss         | 0.002645705   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3100000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.0786923e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 912           |\n",
            "| n_updates          | 757           |\n",
            "| policy_entropy     | 5.4843393e-05 |\n",
            "| policy_loss        | 6.9521777e-10 |\n",
            "| serial_timesteps   | 387584        |\n",
            "| time_elapsed       | 3.46e+03      |\n",
            "| total_timesteps    | 3100672       |\n",
            "| value_loss         | 0.0026397146  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.3386265e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 966           |\n",
            "| n_updates          | 758           |\n",
            "| policy_entropy     | 5.501134e-05  |\n",
            "| policy_loss        | 2.1682353e-10 |\n",
            "| serial_timesteps   | 388096        |\n",
            "| time_elapsed       | 3.47e+03      |\n",
            "| total_timesteps    | 3104768       |\n",
            "| value_loss         | 0.0026233702  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.8362083e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 924           |\n",
            "| n_updates          | 759           |\n",
            "| policy_entropy     | 5.5373035e-05 |\n",
            "| policy_loss        | 2.9831426e-10 |\n",
            "| serial_timesteps   | 388608        |\n",
            "| time_elapsed       | 3.47e+03      |\n",
            "| total_timesteps    | 3108864       |\n",
            "| value_loss         | 0.0026332322  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3110000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.176807e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 916           |\n",
            "| n_updates          | 760           |\n",
            "| policy_entropy     | 5.5868226e-05 |\n",
            "| policy_loss        | 2.3756002e-09 |\n",
            "| serial_timesteps   | 389120        |\n",
            "| time_elapsed       | 3.48e+03      |\n",
            "| total_timesteps    | 3112960       |\n",
            "| value_loss         | 0.0026318177  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.7614175e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 939           |\n",
            "| n_updates          | 761           |\n",
            "| policy_entropy     | 5.6055753e-05 |\n",
            "| policy_loss        | 2.575689e-10  |\n",
            "| serial_timesteps   | 389632        |\n",
            "| time_elapsed       | 3.48e+03      |\n",
            "| total_timesteps    | 3117056       |\n",
            "| value_loss         | 0.0026364517  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3120000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 9.9444304e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 896           |\n",
            "| n_updates          | 762           |\n",
            "| policy_entropy     | 5.4516924e-05 |\n",
            "| policy_loss        | -2.613524e-09 |\n",
            "| serial_timesteps   | 390144        |\n",
            "| time_elapsed       | 3.49e+03      |\n",
            "| total_timesteps    | 3121152       |\n",
            "| value_loss         | 0.0026084608  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.278654e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 936           |\n",
            "| n_updates          | 763           |\n",
            "| policy_entropy     | 5.3194053e-05 |\n",
            "| policy_loss        | 2.1100277e-10 |\n",
            "| serial_timesteps   | 390656        |\n",
            "| time_elapsed       | 3.49e+03      |\n",
            "| total_timesteps    | 3125248       |\n",
            "| value_loss         | 0.002628101   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 9.227552e-15   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 953            |\n",
            "| n_updates          | 764            |\n",
            "| policy_entropy     | 5.3475273e-05  |\n",
            "| policy_loss        | -7.7852745e-11 |\n",
            "| serial_timesteps   | 391168         |\n",
            "| time_elapsed       | 3.49e+03       |\n",
            "| total_timesteps    | 3129344        |\n",
            "| value_loss         | 0.002628841    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3130000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.9159179e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 913            |\n",
            "| n_updates          | 765            |\n",
            "| policy_entropy     | 5.34429e-05    |\n",
            "| policy_loss        | -4.9476513e-11 |\n",
            "| serial_timesteps   | 391680         |\n",
            "| time_elapsed       | 3.5e+03        |\n",
            "| total_timesteps    | 3133440        |\n",
            "| value_loss         | 0.0026212533   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 3.272379e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 931            |\n",
            "| n_updates          | 766            |\n",
            "| policy_entropy     | 5.3523632e-05  |\n",
            "| policy_loss        | -1.6370905e-09 |\n",
            "| serial_timesteps   | 392192         |\n",
            "| time_elapsed       | 3.5e+03        |\n",
            "| total_timesteps    | 3137536        |\n",
            "| value_loss         | 0.0026812602   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3140000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 8.546676e-15   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 886            |\n",
            "| n_updates          | 767            |\n",
            "| policy_entropy     | 5.4766704e-05  |\n",
            "| policy_loss        | -2.3137545e-10 |\n",
            "| serial_timesteps   | 392704         |\n",
            "| time_elapsed       | 3.51e+03       |\n",
            "| total_timesteps    | 3141632        |\n",
            "| value_loss         | 0.002665483    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.9768797e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 948           |\n",
            "| n_updates          | 768           |\n",
            "| policy_entropy     | 5.5937933e-05 |\n",
            "| policy_loss        | -5.83168e-10  |\n",
            "| serial_timesteps   | 393216        |\n",
            "| time_elapsed       | 3.51e+03      |\n",
            "| total_timesteps    | 3145728       |\n",
            "| value_loss         | 0.0026785678  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.6147436e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 954           |\n",
            "| n_updates          | 769           |\n",
            "| policy_entropy     | 5.5902317e-05 |\n",
            "| policy_loss        | -8.905772e-10 |\n",
            "| serial_timesteps   | 393728        |\n",
            "| time_elapsed       | 3.52e+03      |\n",
            "| total_timesteps    | 3149824       |\n",
            "| value_loss         | 0.0026178283  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3150000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 7.31922e-15    |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 908            |\n",
            "| n_updates          | 770            |\n",
            "| policy_entropy     | 5.489935e-05   |\n",
            "| policy_loss        | -1.4842953e-10 |\n",
            "| serial_timesteps   | 394240         |\n",
            "| time_elapsed       | 3.52e+03       |\n",
            "| total_timesteps    | 3153920        |\n",
            "| value_loss         | 0.0026256135   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.6273033e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 945            |\n",
            "| n_updates          | 771            |\n",
            "| policy_entropy     | 5.3887274e-05  |\n",
            "| policy_loss        | -4.5183696e-10 |\n",
            "| serial_timesteps   | 394752         |\n",
            "| time_elapsed       | 3.53e+03       |\n",
            "| total_timesteps    | 3158016        |\n",
            "| value_loss         | 0.002599193    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3160000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.834605e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 894           |\n",
            "| n_updates          | 772           |\n",
            "| policy_entropy     | 5.3696644e-05 |\n",
            "| policy_loss        | 9.065843e-10  |\n",
            "| serial_timesteps   | 395264        |\n",
            "| time_elapsed       | 3.53e+03      |\n",
            "| total_timesteps    | 3162112       |\n",
            "| value_loss         | 0.002615958   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.493095e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 935           |\n",
            "| n_updates          | 773           |\n",
            "| policy_entropy     | 5.4251297e-05 |\n",
            "| policy_loss        | 8.9457897e-10 |\n",
            "| serial_timesteps   | 395776        |\n",
            "| time_elapsed       | 3.53e+03      |\n",
            "| total_timesteps    | 3166208       |\n",
            "| value_loss         | 0.0026165284  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3170000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.7465292e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 894           |\n",
            "| n_updates          | 774           |\n",
            "| policy_entropy     | 5.4333872e-05 |\n",
            "| policy_loss        | 3.765308e-10  |\n",
            "| serial_timesteps   | 396288        |\n",
            "| time_elapsed       | 3.54e+03      |\n",
            "| total_timesteps    | 3170304       |\n",
            "| value_loss         | 0.0026355633  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.3198245e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 954            |\n",
            "| n_updates          | 775            |\n",
            "| policy_entropy     | 5.5115524e-05  |\n",
            "| policy_loss        | -1.6269042e-09 |\n",
            "| serial_timesteps   | 396800         |\n",
            "| time_elapsed       | 3.54e+03       |\n",
            "| total_timesteps    | 3174400        |\n",
            "| value_loss         | 0.0026247813   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.175353e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 922           |\n",
            "| n_updates          | 776           |\n",
            "| policy_entropy     | 5.5890334e-05 |\n",
            "| policy_loss        | 5.6652427e-10 |\n",
            "| serial_timesteps   | 397312        |\n",
            "| time_elapsed       | 3.55e+03      |\n",
            "| total_timesteps    | 3178496       |\n",
            "| value_loss         | 0.0026112986  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3180000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.367295e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 910           |\n",
            "| n_updates          | 777           |\n",
            "| policy_entropy     | 5.5866287e-05 |\n",
            "| policy_loss        | 4.5693013e-10 |\n",
            "| serial_timesteps   | 397824        |\n",
            "| time_elapsed       | 3.55e+03      |\n",
            "| total_timesteps    | 3182592       |\n",
            "| value_loss         | 0.0026217136  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.602077e-14  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 945           |\n",
            "| n_updates          | 778           |\n",
            "| policy_entropy     | 5.611685e-05  |\n",
            "| policy_loss        | 1.0040822e-09 |\n",
            "| serial_timesteps   | 398336        |\n",
            "| time_elapsed       | 3.56e+03      |\n",
            "| total_timesteps    | 3186688       |\n",
            "| value_loss         | 0.002664925   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3190000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.0670515e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 907            |\n",
            "| n_updates          | 779            |\n",
            "| policy_entropy     | 5.602488e-05   |\n",
            "| policy_loss        | -1.5752448e-10 |\n",
            "| serial_timesteps   | 398848         |\n",
            "| time_elapsed       | 3.56e+03       |\n",
            "| total_timesteps    | 3190784        |\n",
            "| value_loss         | 0.0026484996   |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 7.749571e-15 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.851        |\n",
            "| fps                | 933          |\n",
            "| n_updates          | 780          |\n",
            "| policy_entropy     | 5.520627e-05 |\n",
            "| policy_loss        | 9.564246e-10 |\n",
            "| serial_timesteps   | 399360       |\n",
            "| time_elapsed       | 3.57e+03     |\n",
            "| total_timesteps    | 3194880      |\n",
            "| value_loss         | 0.0026200188 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.0227556e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 938           |\n",
            "| n_updates          | 781           |\n",
            "| policy_entropy     | 5.485098e-05  |\n",
            "| policy_loss        | 9.0512914e-10 |\n",
            "| serial_timesteps   | 399872        |\n",
            "| time_elapsed       | 3.57e+03      |\n",
            "| total_timesteps    | 3198976       |\n",
            "| value_loss         | 0.0026208924  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3200000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.377372e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 931           |\n",
            "| n_updates          | 782           |\n",
            "| policy_entropy     | 5.4702454e-05 |\n",
            "| policy_loss        | 1.2154487e-09 |\n",
            "| serial_timesteps   | 400384        |\n",
            "| time_elapsed       | 3.57e+03      |\n",
            "| total_timesteps    | 3203072       |\n",
            "| value_loss         | 0.0025828758  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.560791e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 951           |\n",
            "| n_updates          | 783           |\n",
            "| policy_entropy     | 5.445409e-05  |\n",
            "| policy_loss        | 1.3707904e-09 |\n",
            "| serial_timesteps   | 400896        |\n",
            "| time_elapsed       | 3.58e+03      |\n",
            "| total_timesteps    | 3207168       |\n",
            "| value_loss         | 0.0026085959  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3210000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.463334e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 868           |\n",
            "| n_updates          | 784           |\n",
            "| policy_entropy     | 5.3900585e-05 |\n",
            "| policy_loss        | 8.04539e-10   |\n",
            "| serial_timesteps   | 401408        |\n",
            "| time_elapsed       | 3.58e+03      |\n",
            "| total_timesteps    | 3211264       |\n",
            "| value_loss         | 0.0026118679  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 9.858108e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 965           |\n",
            "| n_updates          | 785           |\n",
            "| policy_entropy     | 5.3533236e-05 |\n",
            "| policy_loss        | -9.604264e-11 |\n",
            "| serial_timesteps   | 401920        |\n",
            "| time_elapsed       | 3.59e+03      |\n",
            "| total_timesteps    | 3215360       |\n",
            "| value_loss         | 0.0026444802  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.8947196e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 952           |\n",
            "| n_updates          | 786           |\n",
            "| policy_entropy     | 5.3370535e-05 |\n",
            "| policy_loss        | 8.6656654e-10 |\n",
            "| serial_timesteps   | 402432        |\n",
            "| time_elapsed       | 3.59e+03      |\n",
            "| total_timesteps    | 3219456       |\n",
            "| value_loss         | 0.0026050636  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3220000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.825109e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 912           |\n",
            "| n_updates          | 787           |\n",
            "| policy_entropy     | 5.3383927e-05 |\n",
            "| policy_loss        | 8.89122e-10   |\n",
            "| serial_timesteps   | 402944        |\n",
            "| time_elapsed       | 3.6e+03       |\n",
            "| total_timesteps    | 3223552       |\n",
            "| value_loss         | 0.0026266428  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.7691852e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 947           |\n",
            "| n_updates          | 788           |\n",
            "| policy_entropy     | 5.3212767e-05 |\n",
            "| policy_loss        | 2.3868778e-09 |\n",
            "| serial_timesteps   | 403456        |\n",
            "| time_elapsed       | 3.6e+03       |\n",
            "| total_timesteps    | 3227648       |\n",
            "| value_loss         | 0.0026276056  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3230000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.8666205e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 901           |\n",
            "| n_updates          | 789           |\n",
            "| policy_entropy     | 5.282688e-05  |\n",
            "| policy_loss        | 7.6397555e-10 |\n",
            "| serial_timesteps   | 403968        |\n",
            "| time_elapsed       | 3.6e+03       |\n",
            "| total_timesteps    | 3231744       |\n",
            "| value_loss         | 0.0026445158  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 5.1676035e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 928           |\n",
            "| n_updates          | 790           |\n",
            "| policy_entropy     | 5.2676194e-05 |\n",
            "| policy_loss        | 1.6701961e-09 |\n",
            "| serial_timesteps   | 404480        |\n",
            "| time_elapsed       | 3.61e+03      |\n",
            "| total_timesteps    | 3235840       |\n",
            "| value_loss         | 0.0026493224  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.2934555e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 791           |\n",
            "| policy_entropy     | 5.304967e-05  |\n",
            "| policy_loss        | 1.6047125e-09 |\n",
            "| serial_timesteps   | 404992        |\n",
            "| time_elapsed       | 3.61e+03      |\n",
            "| total_timesteps    | 3239936       |\n",
            "| value_loss         | 0.0026687048  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3240000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 2.8144978e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 897           |\n",
            "| n_updates          | 792           |\n",
            "| policy_entropy     | 5.3242286e-05 |\n",
            "| policy_loss        | 2.275192e-09  |\n",
            "| serial_timesteps   | 405504        |\n",
            "| time_elapsed       | 3.62e+03      |\n",
            "| total_timesteps    | 3244032       |\n",
            "| value_loss         | 0.002618711   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.3281396e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 945           |\n",
            "| n_updates          | 793           |\n",
            "| policy_entropy     | 5.307755e-05  |\n",
            "| policy_loss        | 1.0191797e-09 |\n",
            "| serial_timesteps   | 406016        |\n",
            "| time_elapsed       | 3.62e+03      |\n",
            "| total_timesteps    | 3248128       |\n",
            "| value_loss         | 0.002599509   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3250000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.957682e-14   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 911            |\n",
            "| n_updates          | 794            |\n",
            "| policy_entropy     | 5.3586475e-05  |\n",
            "| policy_loss        | -1.1639714e-09 |\n",
            "| serial_timesteps   | 406528         |\n",
            "| time_elapsed       | 3.63e+03       |\n",
            "| total_timesteps    | 3252224        |\n",
            "| value_loss         | 0.002627414    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.8270282e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 895            |\n",
            "| n_updates          | 795            |\n",
            "| policy_entropy     | 5.3565163e-05  |\n",
            "| policy_loss        | -2.3319444e-09 |\n",
            "| serial_timesteps   | 407040         |\n",
            "| time_elapsed       | 3.63e+03       |\n",
            "| total_timesteps    | 3256320        |\n",
            "| value_loss         | 0.0026098327   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3260000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 4.1203617e-15  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 891            |\n",
            "| n_updates          | 796            |\n",
            "| policy_entropy     | 5.261508e-05   |\n",
            "| policy_loss        | -4.3655746e-11 |\n",
            "| serial_timesteps   | 407552         |\n",
            "| time_elapsed       | 3.64e+03       |\n",
            "| total_timesteps    | 3260416        |\n",
            "| value_loss         | 0.0025981877   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.5601675e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 927           |\n",
            "| n_updates          | 797           |\n",
            "| policy_entropy     | 5.2601332e-05 |\n",
            "| policy_loss        | 2.134766e-09  |\n",
            "| serial_timesteps   | 408064        |\n",
            "| time_elapsed       | 3.64e+03      |\n",
            "| total_timesteps    | 3264512       |\n",
            "| value_loss         | 0.0026080157  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.0446098e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 964            |\n",
            "| n_updates          | 798            |\n",
            "| policy_entropy     | 5.347602e-05   |\n",
            "| policy_loss        | -1.3484168e-09 |\n",
            "| serial_timesteps   | 408576         |\n",
            "| time_elapsed       | 3.65e+03       |\n",
            "| total_timesteps    | 3268608        |\n",
            "| value_loss         | 0.0026267057   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3270000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.4639237e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 799           |\n",
            "| policy_entropy     | 5.3850275e-05 |\n",
            "| policy_loss        | 1.3882527e-09 |\n",
            "| serial_timesteps   | 409088        |\n",
            "| time_elapsed       | 3.65e+03      |\n",
            "| total_timesteps    | 3272704       |\n",
            "| value_loss         | 0.002604536   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00045981864  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 924            |\n",
            "| n_updates          | 800            |\n",
            "| policy_entropy     | 0.00016190528  |\n",
            "| policy_loss        | -5.5670807e-05 |\n",
            "| serial_timesteps   | 409600         |\n",
            "| time_elapsed       | 3.65e+03       |\n",
            "| total_timesteps    | 3276800        |\n",
            "| value_loss         | 0.0025886823   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3280000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 5.865945e-14 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.852        |\n",
            "| fps                | 881          |\n",
            "| n_updates          | 801          |\n",
            "| policy_entropy     | 0.0001771408 |\n",
            "| policy_loss        | 3.569221e-09 |\n",
            "| serial_timesteps   | 410112       |\n",
            "| time_elapsed       | 3.66e+03     |\n",
            "| total_timesteps    | 3280896      |\n",
            "| value_loss         | 0.0025907848 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.8306044e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 802           |\n",
            "| policy_entropy     | 0.00017434653 |\n",
            "| policy_loss        | -9.651558e-09 |\n",
            "| serial_timesteps   | 410624        |\n",
            "| time_elapsed       | 3.66e+03      |\n",
            "| total_timesteps    | 3284992       |\n",
            "| value_loss         | 0.0025499722  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1790226e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 935           |\n",
            "| n_updates          | 803           |\n",
            "| policy_entropy     | 0.00016699702 |\n",
            "| policy_loss        | -1.510234e-08 |\n",
            "| serial_timesteps   | 411136        |\n",
            "| time_elapsed       | 3.67e+03      |\n",
            "| total_timesteps    | 3289088       |\n",
            "| value_loss         | 0.002551718   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3290000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.678418e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 887           |\n",
            "| n_updates          | 804           |\n",
            "| policy_entropy     | 0.0001601745  |\n",
            "| policy_loss        | -4.471076e-09 |\n",
            "| serial_timesteps   | 411648        |\n",
            "| time_elapsed       | 3.67e+03      |\n",
            "| total_timesteps    | 3293184       |\n",
            "| value_loss         | 0.0025556362  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4561917e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 955           |\n",
            "| n_updates          | 805           |\n",
            "| policy_entropy     | 0.00015593389 |\n",
            "| policy_loss        | 3.9428416e-09 |\n",
            "| serial_timesteps   | 412160        |\n",
            "| time_elapsed       | 3.68e+03      |\n",
            "| total_timesteps    | 3297280       |\n",
            "| value_loss         | 0.0025896246  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3300000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.405066e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 902           |\n",
            "| n_updates          | 806           |\n",
            "| policy_entropy     | 0.00015370165 |\n",
            "| policy_loss        | 5.944457e-10  |\n",
            "| serial_timesteps   | 412672        |\n",
            "| time_elapsed       | 3.68e+03      |\n",
            "| total_timesteps    | 3301376       |\n",
            "| value_loss         | 0.0025512057  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.750249e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 933           |\n",
            "| n_updates          | 807           |\n",
            "| policy_entropy     | 0.00015225331 |\n",
            "| policy_loss        | 2.8696376e-09 |\n",
            "| serial_timesteps   | 413184        |\n",
            "| time_elapsed       | 3.69e+03      |\n",
            "| total_timesteps    | 3305472       |\n",
            "| value_loss         | 0.0025731912  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.307304e-14  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 956           |\n",
            "| n_updates          | 808           |\n",
            "| policy_entropy     | 0.00015242552 |\n",
            "| policy_loss        | 4.424874e-09  |\n",
            "| serial_timesteps   | 413696        |\n",
            "| time_elapsed       | 3.69e+03      |\n",
            "| total_timesteps    | 3309568       |\n",
            "| value_loss         | 0.0026122897  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3310000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.0519918e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 915           |\n",
            "| n_updates          | 809           |\n",
            "| policy_entropy     | 0.00015172928 |\n",
            "| policy_loss        | 8.440838e-09  |\n",
            "| serial_timesteps   | 414208        |\n",
            "| time_elapsed       | 3.69e+03      |\n",
            "| total_timesteps    | 3313664       |\n",
            "| value_loss         | 0.002594668   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.0553084e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 948           |\n",
            "| n_updates          | 810           |\n",
            "| policy_entropy     | 0.00015104678 |\n",
            "| policy_loss        | 5.6505085e-09 |\n",
            "| serial_timesteps   | 414720        |\n",
            "| time_elapsed       | 3.7e+03       |\n",
            "| total_timesteps    | 3317760       |\n",
            "| value_loss         | 0.0025970943  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3320000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.4162213e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 897           |\n",
            "| n_updates          | 811           |\n",
            "| policy_entropy     | 0.00014738803 |\n",
            "| policy_loss        | 4.4305124e-09 |\n",
            "| serial_timesteps   | 415232        |\n",
            "| time_elapsed       | 3.7e+03       |\n",
            "| total_timesteps    | 3321856       |\n",
            "| value_loss         | 0.002604509   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.9477614e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 928           |\n",
            "| n_updates          | 812           |\n",
            "| policy_entropy     | 0.00014596575 |\n",
            "| policy_loss        | 8.652568e-09  |\n",
            "| serial_timesteps   | 415744        |\n",
            "| time_elapsed       | 3.71e+03      |\n",
            "| total_timesteps    | 3325952       |\n",
            "| value_loss         | 0.0025755987  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3330000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.9575886e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 900           |\n",
            "| n_updates          | 813           |\n",
            "| policy_entropy     | 0.00014419845 |\n",
            "| policy_loss        | 3.6219716e-09 |\n",
            "| serial_timesteps   | 416256        |\n",
            "| time_elapsed       | 3.71e+03      |\n",
            "| total_timesteps    | 3330048       |\n",
            "| value_loss         | 0.0025492895  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00053223607  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 948            |\n",
            "| n_updates          | 814            |\n",
            "| policy_entropy     | 0.0007271875   |\n",
            "| policy_loss        | -5.6155073e-05 |\n",
            "| serial_timesteps   | 416768         |\n",
            "| time_elapsed       | 3.72e+03       |\n",
            "| total_timesteps    | 3334144        |\n",
            "| value_loss         | 0.0025615827   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.0133677e-10 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 929           |\n",
            "| n_updates          | 815           |\n",
            "| policy_entropy     | 0.0008181127  |\n",
            "| policy_loss        | 9.445357e-08  |\n",
            "| serial_timesteps   | 417280        |\n",
            "| time_elapsed       | 3.72e+03      |\n",
            "| total_timesteps    | 3338240       |\n",
            "| value_loss         | 0.002600782   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3340000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.2480752e-09  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 915            |\n",
            "| n_updates          | 816            |\n",
            "| policy_entropy     | 0.000759988    |\n",
            "| policy_loss        | -1.6615232e-07 |\n",
            "| serial_timesteps   | 417792         |\n",
            "| time_elapsed       | 3.72e+03       |\n",
            "| total_timesteps    | 3342336        |\n",
            "| value_loss         | 0.00259535     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.91368e-11   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 947           |\n",
            "| n_updates          | 817           |\n",
            "| policy_entropy     | 0.00064902694 |\n",
            "| policy_loss        | 8.452726e-08  |\n",
            "| serial_timesteps   | 418304        |\n",
            "| time_elapsed       | 3.73e+03      |\n",
            "| total_timesteps    | 3346432       |\n",
            "| value_loss         | 0.0025735968  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3350000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.4660275e-10 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 911           |\n",
            "| n_updates          | 818           |\n",
            "| policy_entropy     | 0.0005833827  |\n",
            "| policy_loss        | -1.183158e-07 |\n",
            "| serial_timesteps   | 418816        |\n",
            "| time_elapsed       | 3.73e+03      |\n",
            "| total_timesteps    | 3350528       |\n",
            "| value_loss         | 0.0026163796  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.8555978e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 955           |\n",
            "| n_updates          | 819           |\n",
            "| policy_entropy     | 0.00054586196 |\n",
            "| policy_loss        | 1.0091899e-07 |\n",
            "| serial_timesteps   | 419328        |\n",
            "| time_elapsed       | 3.74e+03      |\n",
            "| total_timesteps    | 3354624       |\n",
            "| value_loss         | 0.0026018266  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0005093376   |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 950            |\n",
            "| n_updates          | 820            |\n",
            "| policy_entropy     | 0.00312058     |\n",
            "| policy_loss        | -5.2811356e-05 |\n",
            "| serial_timesteps   | 419840         |\n",
            "| time_elapsed       | 3.74e+03       |\n",
            "| total_timesteps    | 3358720        |\n",
            "| value_loss         | 0.0026133545   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3360000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0009447352   |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 898            |\n",
            "| n_updates          | 821            |\n",
            "| policy_entropy     | 0.022789815    |\n",
            "| policy_loss        | -5.5060744e-05 |\n",
            "| serial_timesteps   | 420352         |\n",
            "| time_elapsed       | 3.75e+03       |\n",
            "| total_timesteps    | 3362816        |\n",
            "| value_loss         | 0.002651644    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.001038475   |\n",
            "| clipfrac           | 0.0073974608  |\n",
            "| ep_len_mean        | 16.2          |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.844         |\n",
            "| fps                | 922           |\n",
            "| n_updates          | 822           |\n",
            "| policy_entropy     | 0.02825432    |\n",
            "| policy_loss        | -0.0010364891 |\n",
            "| serial_timesteps   | 420864        |\n",
            "| time_elapsed       | 3.75e+03      |\n",
            "| total_timesteps    | 3366912       |\n",
            "| value_loss         | 0.0027787327  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3370000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 9.6404474e-05 |\n",
            "| clipfrac           | 0.0012207031  |\n",
            "| ep_len_mean        | 16.1          |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.848         |\n",
            "| fps                | 916           |\n",
            "| n_updates          | 823           |\n",
            "| policy_entropy     | 0.017798083   |\n",
            "| policy_loss        | 0.00017410432 |\n",
            "| serial_timesteps   | 421376        |\n",
            "| time_elapsed       | 3.76e+03      |\n",
            "| total_timesteps    | 3371008       |\n",
            "| value_loss         | 0.0026708576  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00027494127 |\n",
            "| clipfrac           | 0.0035888671  |\n",
            "| ep_len_mean        | 16.1          |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.847         |\n",
            "| fps                | 955           |\n",
            "| n_updates          | 824           |\n",
            "| policy_entropy     | 0.017941589   |\n",
            "| policy_loss        | -0.0008385839 |\n",
            "| serial_timesteps   | 421888        |\n",
            "| time_elapsed       | 3.76e+03      |\n",
            "| total_timesteps    | 3375104       |\n",
            "| value_loss         | 0.002675064   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 9.218506e-05  |\n",
            "| clipfrac           | 0.0011962891  |\n",
            "| ep_len_mean        | 16.1          |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.849         |\n",
            "| fps                | 928           |\n",
            "| n_updates          | 825           |\n",
            "| policy_entropy     | 0.015733695   |\n",
            "| policy_loss        | 0.00015117644 |\n",
            "| serial_timesteps   | 422400        |\n",
            "| time_elapsed       | 3.76e+03      |\n",
            "| total_timesteps    | 3379200       |\n",
            "| value_loss         | 0.0026547264  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3380000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 6.0894476e-05 |\n",
            "| clipfrac           | 0.0008789062  |\n",
            "| ep_len_mean        | 16.1          |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 912           |\n",
            "| n_updates          | 826           |\n",
            "| policy_entropy     | 0.012688016   |\n",
            "| policy_loss        | 4.30431e-05   |\n",
            "| serial_timesteps   | 422912        |\n",
            "| time_elapsed       | 3.77e+03      |\n",
            "| total_timesteps    | 3383296       |\n",
            "| value_loss         | 0.002613672   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 8.275161e-05   |\n",
            "| clipfrac           | 0.0015869141   |\n",
            "| ep_len_mean        | 16.1           |\n",
            "| ep_reward_mean     | 0.955          |\n",
            "| explained_variance | 0.849          |\n",
            "| fps                | 950            |\n",
            "| n_updates          | 827            |\n",
            "| policy_entropy     | 0.010852421    |\n",
            "| policy_loss        | -0.00019571479 |\n",
            "| serial_timesteps   | 423424         |\n",
            "| time_elapsed       | 3.77e+03       |\n",
            "| total_timesteps    | 3387392        |\n",
            "| value_loss         | 0.002667207    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3390000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.2613916e-05 |\n",
            "| clipfrac           | 0.00078125    |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 913           |\n",
            "| n_updates          | 828           |\n",
            "| policy_entropy     | 0.008160448   |\n",
            "| policy_loss        | -0.0002741471 |\n",
            "| serial_timesteps   | 423936        |\n",
            "| time_elapsed       | 3.78e+03      |\n",
            "| total_timesteps    | 3391488       |\n",
            "| value_loss         | 0.0026591818  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.3098076e-05  |\n",
            "| clipfrac           | 0.0009033203   |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.955          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 941            |\n",
            "| n_updates          | 829            |\n",
            "| policy_entropy     | 0.006074476    |\n",
            "| policy_loss        | -0.00016544711 |\n",
            "| serial_timesteps   | 424448         |\n",
            "| time_elapsed       | 3.78e+03       |\n",
            "| total_timesteps    | 3395584        |\n",
            "| value_loss         | 0.002650228    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.7948095e-06 |\n",
            "| clipfrac           | 7.324219e-05  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 928           |\n",
            "| n_updates          | 830           |\n",
            "| policy_entropy     | 0.005359855   |\n",
            "| policy_loss        | 4.883193e-05  |\n",
            "| serial_timesteps   | 424960        |\n",
            "| time_elapsed       | 3.79e+03      |\n",
            "| total_timesteps    | 3399680       |\n",
            "| value_loss         | 0.0026627227  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3400000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 8.647239e-06  |\n",
            "| clipfrac           | 0.00012207031 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 915           |\n",
            "| n_updates          | 831           |\n",
            "| policy_entropy     | 0.0044564935  |\n",
            "| policy_loss        | 4.713916e-05  |\n",
            "| serial_timesteps   | 425472        |\n",
            "| time_elapsed       | 3.79e+03      |\n",
            "| total_timesteps    | 3403776       |\n",
            "| value_loss         | 0.002596008   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.7773e-06    |\n",
            "| clipfrac           | 4.8828126e-05 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 970           |\n",
            "| n_updates          | 832           |\n",
            "| policy_entropy     | 0.0040374957  |\n",
            "| policy_loss        | 5.74588e-05   |\n",
            "| serial_timesteps   | 425984        |\n",
            "| time_elapsed       | 3.8e+03       |\n",
            "| total_timesteps    | 3407872       |\n",
            "| value_loss         | 0.002610475   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3410000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| approxkl           | 1.6929427e-05   |\n",
            "| clipfrac           | 0.0001953125    |\n",
            "| ep_len_mean        | 16              |\n",
            "| ep_reward_mean     | 0.956           |\n",
            "| explained_variance | 0.851           |\n",
            "| fps                | 905             |\n",
            "| n_updates          | 833             |\n",
            "| policy_entropy     | 0.0028718933    |\n",
            "| policy_loss        | -0.000106283675 |\n",
            "| serial_timesteps   | 426496          |\n",
            "| time_elapsed       | 3.8e+03         |\n",
            "| total_timesteps    | 3411968         |\n",
            "| value_loss         | 0.0026311916    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 8.51452e-06    |\n",
            "| clipfrac           | 0.0001953125   |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 953            |\n",
            "| n_updates          | 834            |\n",
            "| policy_entropy     | 0.003330899    |\n",
            "| policy_loss        | -5.3833704e-05 |\n",
            "| serial_timesteps   | 427008         |\n",
            "| time_elapsed       | 3.8e+03        |\n",
            "| total_timesteps    | 3416064        |\n",
            "| value_loss         | 0.0026358243   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3420000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.9914821e-10 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 908           |\n",
            "| n_updates          | 835           |\n",
            "| policy_entropy     | 0.003443826   |\n",
            "| policy_loss        | 2.1363522e-07 |\n",
            "| serial_timesteps   | 427520        |\n",
            "| time_elapsed       | 3.81e+03      |\n",
            "| total_timesteps    | 3420160       |\n",
            "| value_loss         | 0.0026341157  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.7257267e-05  |\n",
            "| clipfrac           | 0.0001953125   |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 931            |\n",
            "| n_updates          | 836            |\n",
            "| policy_entropy     | 0.0047123367   |\n",
            "| policy_loss        | -5.4725962e-05 |\n",
            "| serial_timesteps   | 428032         |\n",
            "| time_elapsed       | 3.81e+03       |\n",
            "| total_timesteps    | 3424256        |\n",
            "| value_loss         | 0.0026159643   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.740874e-05   |\n",
            "| clipfrac           | 0.00034179687  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 936            |\n",
            "| n_updates          | 837            |\n",
            "| policy_entropy     | 0.003956176    |\n",
            "| policy_loss        | -4.3083783e-06 |\n",
            "| serial_timesteps   | 428544         |\n",
            "| time_elapsed       | 3.82e+03       |\n",
            "| total_timesteps    | 3428352        |\n",
            "| value_loss         | 0.0026054368   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3430000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3168621e-09 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 908           |\n",
            "| n_updates          | 838           |\n",
            "| policy_entropy     | 0.003818205   |\n",
            "| policy_loss        | 3.0489537e-07 |\n",
            "| serial_timesteps   | 429056        |\n",
            "| time_elapsed       | 3.82e+03      |\n",
            "| total_timesteps    | 3432448       |\n",
            "| value_loss         | 0.0025952023  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.5100275e-05 |\n",
            "| clipfrac           | 0.0004394531  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 940           |\n",
            "| n_updates          | 839           |\n",
            "| policy_entropy     | 0.0029878535  |\n",
            "| policy_loss        | -0.0001634035 |\n",
            "| serial_timesteps   | 429568        |\n",
            "| time_elapsed       | 3.83e+03      |\n",
            "| total_timesteps    | 3436544       |\n",
            "| value_loss         | 0.0026561439  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3440000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 3.1678268e-05  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 911            |\n",
            "| n_updates          | 840            |\n",
            "| policy_entropy     | 0.0018180743   |\n",
            "| policy_loss        | -0.00011454371 |\n",
            "| serial_timesteps   | 430080         |\n",
            "| time_elapsed       | 3.83e+03       |\n",
            "| total_timesteps    | 3440640        |\n",
            "| value_loss         | 0.0025851564   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.1842288e-10 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 950           |\n",
            "| n_updates          | 841           |\n",
            "| policy_entropy     | 0.0016903229  |\n",
            "| policy_loss        | -1.70985e-09  |\n",
            "| serial_timesteps   | 430592        |\n",
            "| time_elapsed       | 3.84e+03      |\n",
            "| total_timesteps    | 3444736       |\n",
            "| value_loss         | 0.0025976566  |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| approxkl           | 6.208511e-05    |\n",
            "| clipfrac           | 0.00021972656   |\n",
            "| ep_len_mean        | 16              |\n",
            "| ep_reward_mean     | 0.956           |\n",
            "| explained_variance | 0.851           |\n",
            "| fps                | 927             |\n",
            "| n_updates          | 842             |\n",
            "| policy_entropy     | 0.0009489971    |\n",
            "| policy_loss        | -0.000107275046 |\n",
            "| serial_timesteps   | 431104          |\n",
            "| time_elapsed       | 3.84e+03        |\n",
            "| total_timesteps    | 3448832         |\n",
            "| value_loss         | 0.0025739598    |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=3450000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| approxkl           | 7.6251985e-05   |\n",
            "| clipfrac           | 0.00021972656   |\n",
            "| ep_len_mean        | 16              |\n",
            "| ep_reward_mean     | 0.956           |\n",
            "| explained_variance | 0.851           |\n",
            "| fps                | 901             |\n",
            "| n_updates          | 843             |\n",
            "| policy_entropy     | 0.00046982578   |\n",
            "| policy_loss        | -0.000108528475 |\n",
            "| serial_timesteps   | 431616          |\n",
            "| time_elapsed       | 3.84e+03        |\n",
            "| total_timesteps    | 3452928         |\n",
            "| value_loss         | 0.0026236277    |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.671899e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 957           |\n",
            "| n_updates          | 844           |\n",
            "| policy_entropy     | 0.00044206987 |\n",
            "| policy_loss        | 2.5320332e-10 |\n",
            "| serial_timesteps   | 432128        |\n",
            "| time_elapsed       | 3.85e+03      |\n",
            "| total_timesteps    | 3457024       |\n",
            "| value_loss         | 0.002617941   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3460000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 6.7702605e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 901           |\n",
            "| n_updates          | 845           |\n",
            "| policy_entropy     | 0.00044511637 |\n",
            "| policy_loss        | 6.875143e-09  |\n",
            "| serial_timesteps   | 432640        |\n",
            "| time_elapsed       | 3.85e+03      |\n",
            "| total_timesteps    | 3461120       |\n",
            "| value_loss         | 0.0026182882  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 5.0643246e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 944           |\n",
            "| n_updates          | 846           |\n",
            "| policy_entropy     | 0.0004414015  |\n",
            "| policy_loss        | 9.409268e-09  |\n",
            "| serial_timesteps   | 433152        |\n",
            "| time_elapsed       | 3.86e+03      |\n",
            "| total_timesteps    | 3465216       |\n",
            "| value_loss         | 0.0026041227  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.0310376e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 953           |\n",
            "| n_updates          | 847           |\n",
            "| policy_entropy     | 0.00043920605 |\n",
            "| policy_loss        | 1.1598604e-08 |\n",
            "| serial_timesteps   | 433664        |\n",
            "| time_elapsed       | 3.86e+03      |\n",
            "| total_timesteps    | 3469312       |\n",
            "| value_loss         | 0.0026141154  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3470000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 7.3474135e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 905            |\n",
            "| n_updates          | 848            |\n",
            "| policy_entropy     | 0.00044968436  |\n",
            "| policy_loss        | -1.6179001e-08 |\n",
            "| serial_timesteps   | 434176         |\n",
            "| time_elapsed       | 3.87e+03       |\n",
            "| total_timesteps    | 3473408        |\n",
            "| value_loss         | 0.002614792    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 9.8454904e-05 |\n",
            "| clipfrac           | 0.00021972656 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 939           |\n",
            "| n_updates          | 849           |\n",
            "| policy_entropy     | 0.0009505072  |\n",
            "| policy_loss        | -5.913414e-05 |\n",
            "| serial_timesteps   | 434688        |\n",
            "| time_elapsed       | 3.87e+03      |\n",
            "| total_timesteps    | 3477504       |\n",
            "| value_loss         | 0.0026572472  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3480000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.6944156e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 902           |\n",
            "| n_updates          | 850           |\n",
            "| policy_entropy     | 0.0010228207  |\n",
            "| policy_loss        | 4.5548042e-08 |\n",
            "| serial_timesteps   | 435200        |\n",
            "| time_elapsed       | 3.87e+03      |\n",
            "| total_timesteps    | 3481600       |\n",
            "| value_loss         | 0.0026363775  |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 9.341511e-11 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.851        |\n",
            "| fps                | 933          |\n",
            "| n_updates          | 851          |\n",
            "| policy_entropy     | 0.0010618262 |\n",
            "| policy_loss        | 5.106849e-08 |\n",
            "| serial_timesteps   | 435712       |\n",
            "| time_elapsed       | 3.88e+03     |\n",
            "| total_timesteps    | 3485696      |\n",
            "| value_loss         | 0.0026513257 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.3664254e-05 |\n",
            "| clipfrac           | 0.0003173828  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 963           |\n",
            "| n_updates          | 852           |\n",
            "| policy_entropy     | 0.0007935756  |\n",
            "| policy_loss        | 1.8937742e-05 |\n",
            "| serial_timesteps   | 436224        |\n",
            "| time_elapsed       | 3.88e+03      |\n",
            "| total_timesteps    | 3489792       |\n",
            "| value_loss         | 0.0026089556  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3490000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 4.794169e-10 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.851        |\n",
            "| fps                | 911          |\n",
            "| n_updates          | 853          |\n",
            "| policy_entropy     | 0.0007662272 |\n",
            "| policy_loss        | 6.704977e-09 |\n",
            "| serial_timesteps   | 436736       |\n",
            "| time_elapsed       | 3.89e+03     |\n",
            "| total_timesteps    | 3493888      |\n",
            "| value_loss         | 0.0025915685 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.6860851e-05 |\n",
            "| clipfrac           | 0.00021972656 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 963           |\n",
            "| n_updates          | 854           |\n",
            "| policy_entropy     | 0.0010474661  |\n",
            "| policy_loss        | -5.602686e-05 |\n",
            "| serial_timesteps   | 437248        |\n",
            "| time_elapsed       | 3.89e+03      |\n",
            "| total_timesteps    | 3497984       |\n",
            "| value_loss         | 0.0025894751  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3500000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 9.431391e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 894           |\n",
            "| n_updates          | 855           |\n",
            "| policy_entropy     | 0.0010362811  |\n",
            "| policy_loss        | 3.6801065e-08 |\n",
            "| serial_timesteps   | 437760        |\n",
            "| time_elapsed       | 3.9e+03       |\n",
            "| total_timesteps    | 3502080       |\n",
            "| value_loss         | 0.0025905175  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 3.6698057e-05  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 941            |\n",
            "| n_updates          | 856            |\n",
            "| policy_entropy     | 0.0016247062   |\n",
            "| policy_loss        | -5.5056636e-05 |\n",
            "| serial_timesteps   | 438272         |\n",
            "| time_elapsed       | 3.9e+03        |\n",
            "| total_timesteps    | 3506176        |\n",
            "| value_loss         | 0.0025746922   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3510000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 4.906447e-05   |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 885            |\n",
            "| n_updates          | 857            |\n",
            "| policy_entropy     | 0.002926703    |\n",
            "| policy_loss        | -5.4498145e-05 |\n",
            "| serial_timesteps   | 438784         |\n",
            "| time_elapsed       | 3.91e+03       |\n",
            "| total_timesteps    | 3510272        |\n",
            "| value_loss         | 0.0026049083   |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| approxkl           | 9.483841e-05    |\n",
            "| clipfrac           | 0.00046386718   |\n",
            "| ep_len_mean        | 16              |\n",
            "| ep_reward_mean     | 0.956           |\n",
            "| explained_variance | 0.852           |\n",
            "| fps                | 918             |\n",
            "| n_updates          | 858             |\n",
            "| policy_entropy     | 0.0050546178    |\n",
            "| policy_loss        | -0.000109922665 |\n",
            "| serial_timesteps   | 439296          |\n",
            "| time_elapsed       | 3.91e+03        |\n",
            "| total_timesteps    | 3514368         |\n",
            "| value_loss         | 0.0026093354    |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00016981982 |\n",
            "| clipfrac           | 0.0012695312  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 932           |\n",
            "| n_updates          | 859           |\n",
            "| policy_entropy     | 0.0036711623  |\n",
            "| policy_loss        | -9.592921e-05 |\n",
            "| serial_timesteps   | 439808        |\n",
            "| time_elapsed       | 3.91e+03      |\n",
            "| total_timesteps    | 3518464       |\n",
            "| value_loss         | 0.002626392   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3520000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.000118354685 |\n",
            "| clipfrac           | 0.0004394531   |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 906            |\n",
            "| n_updates          | 860            |\n",
            "| policy_entropy     | 0.0020873942   |\n",
            "| policy_loss        | -0.00022723115 |\n",
            "| serial_timesteps   | 440320         |\n",
            "| time_elapsed       | 3.92e+03       |\n",
            "| total_timesteps    | 3522560        |\n",
            "| value_loss         | 0.0025754613   |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 4.303349e-11 |\n",
            "| clipfrac           | 0.0          |\n",
            "| ep_len_mean        | 16           |\n",
            "| ep_reward_mean     | 0.956        |\n",
            "| explained_variance | 0.852        |\n",
            "| fps                | 977          |\n",
            "| n_updates          | 861          |\n",
            "| policy_entropy     | 0.0020233418 |\n",
            "| policy_loss        | 8.867937e-08 |\n",
            "| serial_timesteps   | 440832       |\n",
            "| time_elapsed       | 3.92e+03     |\n",
            "| total_timesteps    | 3526656      |\n",
            "| value_loss         | 0.0025540956 |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=3530000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 6.736193e-06  |\n",
            "| clipfrac           | 0.00021972656 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 900           |\n",
            "| n_updates          | 862           |\n",
            "| policy_entropy     | 0.0024809751  |\n",
            "| policy_loss        | -5.083474e-05 |\n",
            "| serial_timesteps   | 441344        |\n",
            "| time_elapsed       | 3.93e+03      |\n",
            "| total_timesteps    | 3530752       |\n",
            "| value_loss         | 0.0025758077  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.8928441e-10 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 941           |\n",
            "| n_updates          | 863           |\n",
            "| policy_entropy     | 0.0025266318  |\n",
            "| policy_loss        | 1.5440382e-07 |\n",
            "| serial_timesteps   | 441856        |\n",
            "| time_elapsed       | 3.93e+03      |\n",
            "| total_timesteps    | 3534848       |\n",
            "| value_loss         | 0.0025821584  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.2937213e-05  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 956            |\n",
            "| n_updates          | 864            |\n",
            "| policy_entropy     | 0.0034001053   |\n",
            "| policy_loss        | -5.2362167e-05 |\n",
            "| serial_timesteps   | 442368         |\n",
            "| time_elapsed       | 3.94e+03       |\n",
            "| total_timesteps    | 3538944        |\n",
            "| value_loss         | 0.00262629     |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3540000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00047163974  |\n",
            "| clipfrac           | 0.0009033203   |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.955          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 916            |\n",
            "| n_updates          | 865            |\n",
            "| policy_entropy     | 0.0076715997   |\n",
            "| policy_loss        | -0.00022009842 |\n",
            "| serial_timesteps   | 442880         |\n",
            "| time_elapsed       | 3.94e+03       |\n",
            "| total_timesteps    | 3543040        |\n",
            "| value_loss         | 0.002614211    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.454767e-05  |\n",
            "| clipfrac           | 0.00070800784 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 940           |\n",
            "| n_updates          | 866           |\n",
            "| policy_entropy     | 0.0058963737  |\n",
            "| policy_loss        | 4.427214e-05  |\n",
            "| serial_timesteps   | 443392        |\n",
            "| time_elapsed       | 3.95e+03      |\n",
            "| total_timesteps    | 3547136       |\n",
            "| value_loss         | 0.002572048   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3550000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 2.1496928e-05 |\n",
            "| clipfrac           | 0.000390625   |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.955         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 905           |\n",
            "| n_updates          | 867           |\n",
            "| policy_entropy     | 0.005885423   |\n",
            "| policy_loss        | 6.242325e-05  |\n",
            "| serial_timesteps   | 443904        |\n",
            "| time_elapsed       | 3.95e+03      |\n",
            "| total_timesteps    | 3551232       |\n",
            "| value_loss         | 0.0025392103  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.0517883e-05  |\n",
            "| clipfrac           | 0.00070800784  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 950            |\n",
            "| n_updates          | 868            |\n",
            "| policy_entropy     | 0.0045536975   |\n",
            "| policy_loss        | -3.6202826e-05 |\n",
            "| serial_timesteps   | 444416         |\n",
            "| time_elapsed       | 3.95e+03       |\n",
            "| total_timesteps    | 3555328        |\n",
            "| value_loss         | 0.002580701    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.3004164e-09 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 961           |\n",
            "| n_updates          | 869           |\n",
            "| policy_entropy     | 0.0048068604  |\n",
            "| policy_loss        | 2.1442102e-07 |\n",
            "| serial_timesteps   | 444928        |\n",
            "| time_elapsed       | 3.96e+03      |\n",
            "| total_timesteps    | 3559424       |\n",
            "| value_loss         | 0.0026010864  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3560000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.4894594e-05  |\n",
            "| clipfrac           | 0.00029296876  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 914            |\n",
            "| n_updates          | 870            |\n",
            "| policy_entropy     | 0.003969808    |\n",
            "| policy_loss        | -1.9929961e-05 |\n",
            "| serial_timesteps   | 445440         |\n",
            "| time_elapsed       | 3.96e+03       |\n",
            "| total_timesteps    | 3563520        |\n",
            "| value_loss         | 0.0025947408   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.6363352e-05  |\n",
            "| clipfrac           | 0.00029296876  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 952            |\n",
            "| n_updates          | 871            |\n",
            "| policy_entropy     | 0.002995511    |\n",
            "| policy_loss        | -2.2786218e-05 |\n",
            "| serial_timesteps   | 445952         |\n",
            "| time_elapsed       | 3.97e+03       |\n",
            "| total_timesteps    | 3567616        |\n",
            "| value_loss         | 0.0026384073   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3570000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.8600853e-05  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 901            |\n",
            "| n_updates          | 872            |\n",
            "| policy_entropy     | 0.002317033    |\n",
            "| policy_loss        | -9.9990124e-05 |\n",
            "| serial_timesteps   | 446464         |\n",
            "| time_elapsed       | 3.97e+03       |\n",
            "| total_timesteps    | 3571712        |\n",
            "| value_loss         | 0.0026550996   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 8.3293183e-10  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 929            |\n",
            "| n_updates          | 873            |\n",
            "| policy_entropy     | 0.0023094737   |\n",
            "| policy_loss        | -3.2636746e-07 |\n",
            "| serial_timesteps   | 446976         |\n",
            "| time_elapsed       | 3.98e+03       |\n",
            "| total_timesteps    | 3575808        |\n",
            "| value_loss         | 0.002657873    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.109076e-11  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 925           |\n",
            "| n_updates          | 874           |\n",
            "| policy_entropy     | 0.002243375   |\n",
            "| policy_loss        | 1.2747769e-07 |\n",
            "| serial_timesteps   | 447488        |\n",
            "| time_elapsed       | 3.98e+03      |\n",
            "| total_timesteps    | 3579904       |\n",
            "| value_loss         | 0.0025867228  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3580000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.7182442e-05 |\n",
            "| clipfrac           | 0.0006591797  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 916           |\n",
            "| n_updates          | 875           |\n",
            "| policy_entropy     | 0.0018672652  |\n",
            "| policy_loss        | 1.9042647e-05 |\n",
            "| serial_timesteps   | 448000        |\n",
            "| time_elapsed       | 3.98e+03      |\n",
            "| total_timesteps    | 3584000       |\n",
            "| value_loss         | 0.0026251161  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 2.328855e-05   |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.85           |\n",
            "| fps                | 935            |\n",
            "| n_updates          | 876            |\n",
            "| policy_entropy     | 0.001465677    |\n",
            "| policy_loss        | -0.00011102816 |\n",
            "| serial_timesteps   | 448512         |\n",
            "| time_elapsed       | 3.99e+03       |\n",
            "| total_timesteps    | 3588096        |\n",
            "| value_loss         | 0.0026255934   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3590000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.6947687e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 877           |\n",
            "| policy_entropy     | 0.0014375943  |\n",
            "| policy_loss        | 4.2158355e-08 |\n",
            "| serial_timesteps   | 449024        |\n",
            "| time_elapsed       | 3.99e+03      |\n",
            "| total_timesteps    | 3592192       |\n",
            "| value_loss         | 0.0026078247  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 6.957764e-05  |\n",
            "| clipfrac           | 0.0005859375  |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 952           |\n",
            "| n_updates          | 878           |\n",
            "| policy_entropy     | 0.0010473519  |\n",
            "| policy_loss        | -9.479902e-05 |\n",
            "| serial_timesteps   | 449536        |\n",
            "| time_elapsed       | 4e+03         |\n",
            "| total_timesteps    | 3596288       |\n",
            "| value_loss         | 0.0026495806  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3600000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 4.9040333e-05 |\n",
            "| clipfrac           | 0.00046386718 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 923           |\n",
            "| n_updates          | 879           |\n",
            "| policy_entropy     | 0.00066475576 |\n",
            "| policy_loss        | -0.0002274086 |\n",
            "| serial_timesteps   | 450048        |\n",
            "| time_elapsed       | 4e+03         |\n",
            "| total_timesteps    | 3600384       |\n",
            "| value_loss         | 0.002677528   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.1717122e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.85          |\n",
            "| fps                | 942           |\n",
            "| n_updates          | 880           |\n",
            "| policy_entropy     | 0.0006410157  |\n",
            "| policy_loss        | -2.165325e-08 |\n",
            "| serial_timesteps   | 450560        |\n",
            "| time_elapsed       | 4.01e+03      |\n",
            "| total_timesteps    | 3604480       |\n",
            "| value_loss         | 0.0026520551  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.6259464e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 964           |\n",
            "| n_updates          | 881           |\n",
            "| policy_entropy     | 0.0006348297  |\n",
            "| policy_loss        | 1.0566145e-08 |\n",
            "| serial_timesteps   | 451072        |\n",
            "| time_elapsed       | 4.01e+03      |\n",
            "| total_timesteps    | 3608576       |\n",
            "| value_loss         | 0.0026264612  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3610000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.0549181e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 906           |\n",
            "| n_updates          | 882           |\n",
            "| policy_entropy     | 0.00063506735 |\n",
            "| policy_loss        | 7.21393e-09   |\n",
            "| serial_timesteps   | 451584        |\n",
            "| time_elapsed       | 4.02e+03      |\n",
            "| total_timesteps    | 3612672       |\n",
            "| value_loss         | 0.002622902   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.412308e-05  |\n",
            "| clipfrac           | 0.00021972656 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 943           |\n",
            "| n_updates          | 883           |\n",
            "| policy_entropy     | 0.0008362766  |\n",
            "| policy_loss        | -5.614311e-05 |\n",
            "| serial_timesteps   | 452096        |\n",
            "| time_elapsed       | 4.02e+03      |\n",
            "| total_timesteps    | 3616768       |\n",
            "| value_loss         | 0.0026356652  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3620000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.5407446e-11  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.851          |\n",
            "| fps                | 900            |\n",
            "| n_updates          | 884            |\n",
            "| policy_entropy     | 0.00085552456  |\n",
            "| policy_loss        | -1.9688741e-08 |\n",
            "| serial_timesteps   | 452608         |\n",
            "| time_elapsed       | 4.02e+03       |\n",
            "| total_timesteps    | 3620864        |\n",
            "| value_loss         | 0.0026205338   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.8982305e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 957           |\n",
            "| n_updates          | 885           |\n",
            "| policy_entropy     | 0.00086945936 |\n",
            "| policy_loss        | 1.909575e-08  |\n",
            "| serial_timesteps   | 453120        |\n",
            "| time_elapsed       | 4.03e+03      |\n",
            "| total_timesteps    | 3624960       |\n",
            "| value_loss         | 0.002580387   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1740653e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 941           |\n",
            "| n_updates          | 886           |\n",
            "| policy_entropy     | 0.0008609658  |\n",
            "| policy_loss        | 2.8102658e-08 |\n",
            "| serial_timesteps   | 453632        |\n",
            "| time_elapsed       | 4.03e+03      |\n",
            "| total_timesteps    | 3629056       |\n",
            "| value_loss         | 0.0025953897  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3630000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 9.980126e-12  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.851         |\n",
            "| fps                | 916           |\n",
            "| n_updates          | 887           |\n",
            "| policy_entropy     | 0.0008413225  |\n",
            "| policy_loss        | 1.1886004e-08 |\n",
            "| serial_timesteps   | 454144        |\n",
            "| time_elapsed       | 4.04e+03      |\n",
            "| total_timesteps    | 3633152       |\n",
            "| value_loss         | 0.0025859945  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 8.161977e-05   |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 950            |\n",
            "| n_updates          | 888            |\n",
            "| policy_entropy     | 0.00043825884  |\n",
            "| policy_loss        | -0.00011520357 |\n",
            "| serial_timesteps   | 454656         |\n",
            "| time_elapsed       | 4.04e+03       |\n",
            "| total_timesteps    | 3637248        |\n",
            "| value_loss         | 0.002565647    |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3640000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 6.719255e-13   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 917            |\n",
            "| n_updates          | 889            |\n",
            "| policy_entropy     | 0.00041325213  |\n",
            "| policy_loss        | -1.6878403e-09 |\n",
            "| serial_timesteps   | 455168         |\n",
            "| time_elapsed       | 4.05e+03       |\n",
            "| total_timesteps    | 3641344        |\n",
            "| value_loss         | 0.0025606067   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.7696085e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 955            |\n",
            "| n_updates          | 890            |\n",
            "| policy_entropy     | 0.00041350134  |\n",
            "| policy_loss        | -1.2031523e-08 |\n",
            "| serial_timesteps   | 455680         |\n",
            "| time_elapsed       | 4.05e+03       |\n",
            "| total_timesteps    | 3645440        |\n",
            "| value_loss         | 0.0025950316   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.1885307e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 960           |\n",
            "| n_updates          | 891           |\n",
            "| policy_entropy     | 0.00041698717 |\n",
            "| policy_loss        | 6.825485e-09  |\n",
            "| serial_timesteps   | 456192        |\n",
            "| time_elapsed       | 4.06e+03      |\n",
            "| total_timesteps    | 3649536       |\n",
            "| value_loss         | 0.0026149247  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3650000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 5.3584173e-12  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 920            |\n",
            "| n_updates          | 892            |\n",
            "| policy_entropy     | 0.00040751565  |\n",
            "| policy_loss        | -3.3576363e-08 |\n",
            "| serial_timesteps   | 456704         |\n",
            "| time_elapsed       | 4.06e+03       |\n",
            "| total_timesteps    | 3653632        |\n",
            "| value_loss         | 0.0026019777   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.5370846e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 948           |\n",
            "| n_updates          | 893           |\n",
            "| policy_entropy     | 0.0003955983  |\n",
            "| policy_loss        | 6.8754162e-09 |\n",
            "| serial_timesteps   | 457216        |\n",
            "| time_elapsed       | 4.06e+03      |\n",
            "| total_timesteps    | 3657728       |\n",
            "| value_loss         | 0.002600472   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3660000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4496152e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 907           |\n",
            "| n_updates          | 894           |\n",
            "| policy_entropy     | 0.0004018039  |\n",
            "| policy_loss        | -6.990704e-08 |\n",
            "| serial_timesteps   | 457728        |\n",
            "| time_elapsed       | 4.07e+03      |\n",
            "| total_timesteps    | 3661824       |\n",
            "| value_loss         | 0.0026328047  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 3.6481785e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 956           |\n",
            "| n_updates          | 895           |\n",
            "| policy_entropy     | 0.00041777868 |\n",
            "| policy_loss        | 1.6203558e-08 |\n",
            "| serial_timesteps   | 458240        |\n",
            "| time_elapsed       | 4.07e+03      |\n",
            "| total_timesteps    | 3665920       |\n",
            "| value_loss         | 0.0025932062  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3670000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.3697042e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 896           |\n",
            "| policy_entropy     | 0.00042224614 |\n",
            "| policy_loss        | 4.0716257e-09 |\n",
            "| serial_timesteps   | 458752        |\n",
            "| time_elapsed       | 4.08e+03      |\n",
            "| total_timesteps    | 3670016       |\n",
            "| value_loss         | 0.0025978384  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.2910264e-13 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 948           |\n",
            "| n_updates          | 897           |\n",
            "| policy_entropy     | 0.000427871   |\n",
            "| policy_loss        | 1.6966078e-08 |\n",
            "| serial_timesteps   | 459264        |\n",
            "| time_elapsed       | 4.08e+03      |\n",
            "| total_timesteps    | 3674112       |\n",
            "| value_loss         | 0.0025685446  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.1716808e-11  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 953            |\n",
            "| n_updates          | 898            |\n",
            "| policy_entropy     | 0.00043602815  |\n",
            "| policy_loss        | -2.6164344e-09 |\n",
            "| serial_timesteps   | 459776         |\n",
            "| time_elapsed       | 4.09e+03       |\n",
            "| total_timesteps    | 3678208        |\n",
            "| value_loss         | 0.0025794334   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3680000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.0807573e-12 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 924           |\n",
            "| n_updates          | 899           |\n",
            "| policy_entropy     | 0.00044360053 |\n",
            "| policy_loss        | 4.7238427e-08 |\n",
            "| serial_timesteps   | 460288        |\n",
            "| time_elapsed       | 4.09e+03      |\n",
            "| total_timesteps    | 3682304       |\n",
            "| value_loss         | 0.0026091938  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 8.16091e-11   |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 960           |\n",
            "| n_updates          | 900           |\n",
            "| policy_entropy     | 0.00046924938 |\n",
            "| policy_loss        | -4.840258e-08 |\n",
            "| serial_timesteps   | 460800        |\n",
            "| time_elapsed       | 4.09e+03      |\n",
            "| total_timesteps    | 3686400       |\n",
            "| value_loss         | 0.002570178   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3690000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 9.346279e-11   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 920            |\n",
            "| n_updates          | 901            |\n",
            "| policy_entropy     | 0.00047152946  |\n",
            "| policy_loss        | -7.3884436e-08 |\n",
            "| serial_timesteps   | 461312         |\n",
            "| time_elapsed       | 4.1e+03        |\n",
            "| total_timesteps    | 3690496        |\n",
            "| value_loss         | 0.0025572674   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.8475208e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 955           |\n",
            "| n_updates          | 902           |\n",
            "| policy_entropy     | 0.00042881066 |\n",
            "| policy_loss        | 2.1318556e-09 |\n",
            "| serial_timesteps   | 461824        |\n",
            "| time_elapsed       | 4.1e+03       |\n",
            "| total_timesteps    | 3694592       |\n",
            "| value_loss         | 0.002568692   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 9.833147e-13  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 951           |\n",
            "| n_updates          | 903           |\n",
            "| policy_entropy     | 0.00040977634 |\n",
            "| policy_loss        | 4.1232852e-08 |\n",
            "| serial_timesteps   | 462336        |\n",
            "| time_elapsed       | 4.11e+03      |\n",
            "| total_timesteps    | 3698688       |\n",
            "| value_loss         | 0.002584125   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3700000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1027014e-11 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 919           |\n",
            "| n_updates          | 904           |\n",
            "| policy_entropy     | 0.00040134304 |\n",
            "| policy_loss        | 5.155598e-08  |\n",
            "| serial_timesteps   | 462848        |\n",
            "| time_elapsed       | 4.11e+03      |\n",
            "| total_timesteps    | 3702784       |\n",
            "| value_loss         | 0.0025561939  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 6.5230356e-11  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 941            |\n",
            "| n_updates          | 905            |\n",
            "| policy_entropy     | 0.0004185415   |\n",
            "| policy_loss        | -5.1318786e-08 |\n",
            "| serial_timesteps   | 463360         |\n",
            "| time_elapsed       | 4.12e+03       |\n",
            "| total_timesteps    | 3706880        |\n",
            "| value_loss         | 0.0025374265   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3710000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00016367743  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 933            |\n",
            "| n_updates          | 906            |\n",
            "| policy_entropy     | 0.00021283973  |\n",
            "| policy_loss        | -0.00011209096 |\n",
            "| serial_timesteps   | 463872         |\n",
            "| time_elapsed       | 4.12e+03       |\n",
            "| total_timesteps    | 3710976        |\n",
            "| value_loss         | 0.002604606    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.4801118e-14  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 954            |\n",
            "| n_updates          | 907            |\n",
            "| policy_entropy     | 0.00018621192  |\n",
            "| policy_loss        | -1.0200892e-09 |\n",
            "| serial_timesteps   | 464384         |\n",
            "| time_elapsed       | 4.13e+03       |\n",
            "| total_timesteps    | 3715072        |\n",
            "| value_loss         | 0.0025734198   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1407211e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 925           |\n",
            "| n_updates          | 908           |\n",
            "| policy_entropy     | 0.0001856041  |\n",
            "| policy_loss        | 1.6370905e-09 |\n",
            "| serial_timesteps   | 464896        |\n",
            "| time_elapsed       | 4.13e+03      |\n",
            "| total_timesteps    | 3719168       |\n",
            "| value_loss         | 0.0025955145  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3720000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 3.980424e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 918           |\n",
            "| n_updates          | 909           |\n",
            "| policy_entropy     | 0.00018557206 |\n",
            "| policy_loss        | 1.5861588e-09 |\n",
            "| serial_timesteps   | 465408        |\n",
            "| time_elapsed       | 4.13e+03      |\n",
            "| total_timesteps    | 3723264       |\n",
            "| value_loss         | 0.0025657471  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00074496417  |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 921            |\n",
            "| n_updates          | 910            |\n",
            "| policy_entropy     | 0.0001642571   |\n",
            "| policy_loss        | -0.00010552849 |\n",
            "| serial_timesteps   | 465920         |\n",
            "| time_elapsed       | 4.14e+03       |\n",
            "| total_timesteps    | 3727360        |\n",
            "| value_loss         | 0.0025595347   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3730000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.0195748e-14 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 902           |\n",
            "| n_updates          | 911           |\n",
            "| policy_entropy     | 0.0001633209  |\n",
            "| policy_loss        | 8.440111e-10  |\n",
            "| serial_timesteps   | 466432        |\n",
            "| time_elapsed       | 4.14e+03      |\n",
            "| total_timesteps    | 3731456       |\n",
            "| value_loss         | 0.002580876   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0002386313  |\n",
            "| clipfrac           | 0.00021972656 |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 923           |\n",
            "| n_updates          | 912           |\n",
            "| policy_entropy     | 7.287038e-05  |\n",
            "| policy_loss        | -0.0001152487 |\n",
            "| serial_timesteps   | 466944        |\n",
            "| time_elapsed       | 4.15e+03      |\n",
            "| total_timesteps    | 3735552       |\n",
            "| value_loss         | 0.0025957471  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.6426829e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 931           |\n",
            "| n_updates          | 913           |\n",
            "| policy_entropy     | 6.0834973e-05 |\n",
            "| policy_loss        | 2.1827873e-11 |\n",
            "| serial_timesteps   | 467456        |\n",
            "| time_elapsed       | 4.15e+03      |\n",
            "| total_timesteps    | 3739648       |\n",
            "| value_loss         | 0.002552119   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3740000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 901           |\n",
            "| n_updates          | 914           |\n",
            "| policy_entropy     | 6.077721e-05  |\n",
            "| policy_loss        | -6.933988e-10 |\n",
            "| serial_timesteps   | 467968        |\n",
            "| time_elapsed       | 4.16e+03      |\n",
            "| total_timesteps    | 3743744       |\n",
            "| value_loss         | 0.002532119   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 966            |\n",
            "| n_updates          | 915            |\n",
            "| policy_entropy     | 6.0774393e-05  |\n",
            "| policy_loss        | -1.9681465e-09 |\n",
            "| serial_timesteps   | 468480         |\n",
            "| time_elapsed       | 4.16e+03       |\n",
            "| total_timesteps    | 3747840        |\n",
            "| value_loss         | 0.0025601024   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3750000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 923           |\n",
            "| n_updates          | 916           |\n",
            "| policy_entropy     | 6.0774975e-05 |\n",
            "| policy_loss        | 2.1711457e-09 |\n",
            "| serial_timesteps   | 468992        |\n",
            "| time_elapsed       | 4.16e+03      |\n",
            "| total_timesteps    | 3751936       |\n",
            "| value_loss         | 0.0025680256  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 967           |\n",
            "| n_updates          | 917           |\n",
            "| policy_entropy     | 6.07325e-05   |\n",
            "| policy_loss        | -6.635673e-10 |\n",
            "| serial_timesteps   | 469504        |\n",
            "| time_elapsed       | 4.17e+03      |\n",
            "| total_timesteps    | 3756032       |\n",
            "| value_loss         | 0.0025787996  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3760000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 7.903158e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 925           |\n",
            "| n_updates          | 918           |\n",
            "| policy_entropy     | 6.06531e-05   |\n",
            "| policy_loss        | 8.0035535e-12 |\n",
            "| serial_timesteps   | 470016        |\n",
            "| time_elapsed       | 4.17e+03      |\n",
            "| total_timesteps    | 3760128       |\n",
            "| value_loss         | 0.0025756555  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 960           |\n",
            "| n_updates          | 919           |\n",
            "| policy_entropy     | 6.0636805e-05 |\n",
            "| policy_loss        | 1.3977115e-09 |\n",
            "| serial_timesteps   | 470528        |\n",
            "| time_elapsed       | 4.18e+03      |\n",
            "| total_timesteps    | 3764224       |\n",
            "| value_loss         | 0.0025661893  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.4694865e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 953           |\n",
            "| n_updates          | 920           |\n",
            "| policy_entropy     | 6.0741906e-05 |\n",
            "| policy_loss        | 6.8394e-10    |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 4.18e+03      |\n",
            "| total_timesteps    | 3768320       |\n",
            "| value_loss         | 0.002593962   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3770000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 5.1153844e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 910            |\n",
            "| n_updates          | 921            |\n",
            "| policy_entropy     | 6.0856917e-05  |\n",
            "| policy_loss        | -1.1277734e-09 |\n",
            "| serial_timesteps   | 471552         |\n",
            "| time_elapsed       | 4.19e+03       |\n",
            "| total_timesteps    | 3772416        |\n",
            "| value_loss         | 0.0025724473   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 6.2515616e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 935            |\n",
            "| n_updates          | 922            |\n",
            "| policy_entropy     | 6.081487e-05   |\n",
            "| policy_loss        | -2.2482709e-10 |\n",
            "| serial_timesteps   | 472064         |\n",
            "| time_elapsed       | 4.19e+03       |\n",
            "| total_timesteps    | 3776512        |\n",
            "| value_loss         | 0.0025840872   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3780000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.000374995    |\n",
            "| clipfrac           | 0.00021972656  |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 907            |\n",
            "| n_updates          | 923            |\n",
            "| policy_entropy     | 3.4839566e-05  |\n",
            "| policy_loss        | -0.00011075869 |\n",
            "| serial_timesteps   | 472576         |\n",
            "| time_elapsed       | 4.2e+03        |\n",
            "| total_timesteps    | 3780608        |\n",
            "| value_loss         | 0.0025914353   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 951           |\n",
            "| n_updates          | 924           |\n",
            "| policy_entropy     | 3.4172677e-05 |\n",
            "| policy_loss        | 7.872586e-10  |\n",
            "| serial_timesteps   | 473088        |\n",
            "| time_elapsed       | 4.2e+03       |\n",
            "| total_timesteps    | 3784704       |\n",
            "| value_loss         | 0.0025648822  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 958           |\n",
            "| n_updates          | 925           |\n",
            "| policy_entropy     | 3.4190296e-05 |\n",
            "| policy_loss        | 6.402843e-11  |\n",
            "| serial_timesteps   | 473600        |\n",
            "| time_elapsed       | 4.2e+03       |\n",
            "| total_timesteps    | 3788800       |\n",
            "| value_loss         | 0.0025867452  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3790000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 914           |\n",
            "| n_updates          | 926           |\n",
            "| policy_entropy     | 3.4188757e-05 |\n",
            "| policy_loss        | 9.62973e-10   |\n",
            "| serial_timesteps   | 474112        |\n",
            "| time_elapsed       | 4.21e+03      |\n",
            "| total_timesteps    | 3792896       |\n",
            "| value_loss         | 0.0025854683  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 970           |\n",
            "| n_updates          | 927           |\n",
            "| policy_entropy     | 3.415487e-05  |\n",
            "| policy_loss        | 6.8248485e-10 |\n",
            "| serial_timesteps   | 474624        |\n",
            "| time_elapsed       | 4.21e+03      |\n",
            "| total_timesteps    | 3796992       |\n",
            "| value_loss         | 0.0025346656  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3800000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 896           |\n",
            "| n_updates          | 928           |\n",
            "| policy_entropy     | 3.4146185e-05 |\n",
            "| policy_loss        | 1.9950677e-09 |\n",
            "| serial_timesteps   | 475136        |\n",
            "| time_elapsed       | 4.22e+03      |\n",
            "| total_timesteps    | 3801088       |\n",
            "| value_loss         | 0.0025560786  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 975           |\n",
            "| n_updates          | 929           |\n",
            "| policy_entropy     | 3.419475e-05  |\n",
            "| policy_loss        | -6.693881e-10 |\n",
            "| serial_timesteps   | 475648        |\n",
            "| time_elapsed       | 4.22e+03      |\n",
            "| total_timesteps    | 3805184       |\n",
            "| value_loss         | 0.0025438822  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 935            |\n",
            "| n_updates          | 930            |\n",
            "| policy_entropy     | 3.421923e-05   |\n",
            "| policy_loss        | -1.5701517e-09 |\n",
            "| serial_timesteps   | 476160         |\n",
            "| time_elapsed       | 4.23e+03       |\n",
            "| total_timesteps    | 3809280        |\n",
            "| value_loss         | 0.0025620288   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3810000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 897           |\n",
            "| n_updates          | 931           |\n",
            "| policy_entropy     | 3.4229262e-05 |\n",
            "| policy_loss        | 3.063178e-10  |\n",
            "| serial_timesteps   | 476672        |\n",
            "| time_elapsed       | 4.23e+03      |\n",
            "| total_timesteps    | 3813376       |\n",
            "| value_loss         | 0.0025461833  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 938           |\n",
            "| n_updates          | 932           |\n",
            "| policy_entropy     | 3.4226985e-05 |\n",
            "| policy_loss        | -2.408342e-09 |\n",
            "| serial_timesteps   | 477184        |\n",
            "| time_elapsed       | 4.23e+03      |\n",
            "| total_timesteps    | 3817472       |\n",
            "| value_loss         | 0.0025695509  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3820000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 881            |\n",
            "| n_updates          | 933            |\n",
            "| policy_entropy     | 3.4217785e-05  |\n",
            "| policy_loss        | -1.2903911e-09 |\n",
            "| serial_timesteps   | 477696         |\n",
            "| time_elapsed       | 4.24e+03       |\n",
            "| total_timesteps    | 3821568        |\n",
            "| value_loss         | 0.0025487803   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 959           |\n",
            "| n_updates          | 934           |\n",
            "| policy_entropy     | 3.420648e-05  |\n",
            "| policy_loss        | 4.5110936e-11 |\n",
            "| serial_timesteps   | 478208        |\n",
            "| time_elapsed       | 4.24e+03      |\n",
            "| total_timesteps    | 3825664       |\n",
            "| value_loss         | 0.0025778378  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 935           |\n",
            "| policy_entropy     | 3.4189106e-05 |\n",
            "| policy_loss        | 6.511982e-10  |\n",
            "| serial_timesteps   | 478720        |\n",
            "| time_elapsed       | 4.25e+03      |\n",
            "| total_timesteps    | 3829760       |\n",
            "| value_loss         | 0.0025549454  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3830000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 887            |\n",
            "| n_updates          | 936            |\n",
            "| policy_entropy     | 3.416049e-05   |\n",
            "| policy_loss        | -6.7848305e-10 |\n",
            "| serial_timesteps   | 479232         |\n",
            "| time_elapsed       | 4.25e+03       |\n",
            "| total_timesteps    | 3833856        |\n",
            "| value_loss         | 0.0025458452   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 942           |\n",
            "| n_updates          | 937           |\n",
            "| policy_entropy     | 3.4120734e-05 |\n",
            "| policy_loss        | 6.693881e-10  |\n",
            "| serial_timesteps   | 479744        |\n",
            "| time_elapsed       | 4.26e+03      |\n",
            "| total_timesteps    | 3837952       |\n",
            "| value_loss         | 0.0025547289  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3840000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 910           |\n",
            "| n_updates          | 938           |\n",
            "| policy_entropy     | 3.41067e-05   |\n",
            "| policy_loss        | 6.3810146e-10 |\n",
            "| serial_timesteps   | 480256        |\n",
            "| time_elapsed       | 4.26e+03      |\n",
            "| total_timesteps    | 3842048       |\n",
            "| value_loss         | 0.0025386207  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 956           |\n",
            "| n_updates          | 939           |\n",
            "| policy_entropy     | 3.4075143e-05 |\n",
            "| policy_loss        | 9.167707e-11  |\n",
            "| serial_timesteps   | 480768        |\n",
            "| time_elapsed       | 4.27e+03      |\n",
            "| total_timesteps    | 3846144       |\n",
            "| value_loss         | 0.0026085463  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3850000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 900           |\n",
            "| n_updates          | 940           |\n",
            "| policy_entropy     | 3.4070115e-05 |\n",
            "| policy_loss        | 1.7120328e-09 |\n",
            "| serial_timesteps   | 481280        |\n",
            "| time_elapsed       | 4.27e+03      |\n",
            "| total_timesteps    | 3850240       |\n",
            "| value_loss         | 0.0025896048  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 947           |\n",
            "| n_updates          | 941           |\n",
            "| policy_entropy     | 3.4106837e-05 |\n",
            "| policy_loss        | 7.705239e-10  |\n",
            "| serial_timesteps   | 481792        |\n",
            "| time_elapsed       | 4.27e+03      |\n",
            "| total_timesteps    | 3854336       |\n",
            "| value_loss         | 0.00258979    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 959            |\n",
            "| n_updates          | 942            |\n",
            "| policy_entropy     | 3.4125573e-05  |\n",
            "| policy_loss        | -2.8521754e-10 |\n",
            "| serial_timesteps   | 482304         |\n",
            "| time_elapsed       | 4.28e+03       |\n",
            "| total_timesteps    | 3858432        |\n",
            "| value_loss         | 0.0025936347   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3860000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 910           |\n",
            "| n_updates          | 943           |\n",
            "| policy_entropy     | 3.41176e-05   |\n",
            "| policy_loss        | 3.2960087e-10 |\n",
            "| serial_timesteps   | 482816        |\n",
            "| time_elapsed       | 4.28e+03      |\n",
            "| total_timesteps    | 3862528       |\n",
            "| value_loss         | 0.0025527175  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 965            |\n",
            "| n_updates          | 944            |\n",
            "| policy_entropy     | 3.4097488e-05  |\n",
            "| policy_loss        | -1.1888914e-09 |\n",
            "| serial_timesteps   | 483328         |\n",
            "| time_elapsed       | 4.29e+03       |\n",
            "| total_timesteps    | 3866624        |\n",
            "| value_loss         | 0.0025370466   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3870000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 904           |\n",
            "| n_updates          | 945           |\n",
            "| policy_entropy     | 3.4067692e-05 |\n",
            "| policy_loss        | 2.6382623e-09 |\n",
            "| serial_timesteps   | 483840        |\n",
            "| time_elapsed       | 4.29e+03      |\n",
            "| total_timesteps    | 3870720       |\n",
            "| value_loss         | 0.0025204157  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 928           |\n",
            "| n_updates          | 946           |\n",
            "| policy_entropy     | 3.4058212e-05 |\n",
            "| policy_loss        | 2.7866917e-10 |\n",
            "| serial_timesteps   | 484352        |\n",
            "| time_elapsed       | 4.3e+03       |\n",
            "| total_timesteps    | 3874816       |\n",
            "| value_loss         | 0.0025373101  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 934            |\n",
            "| n_updates          | 947            |\n",
            "| policy_entropy     | 3.410087e-05   |\n",
            "| policy_loss        | -8.8239177e-10 |\n",
            "| serial_timesteps   | 484864         |\n",
            "| time_elapsed       | 4.3e+03        |\n",
            "| total_timesteps    | 3878912        |\n",
            "| value_loss         | 0.0025587294   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3880000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 918           |\n",
            "| n_updates          | 948           |\n",
            "| policy_entropy     | 3.4153847e-05 |\n",
            "| policy_loss        | 8.250936e-10  |\n",
            "| serial_timesteps   | 485376        |\n",
            "| time_elapsed       | 4.31e+03      |\n",
            "| total_timesteps    | 3883008       |\n",
            "| value_loss         | 0.002598172   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 940           |\n",
            "| n_updates          | 949           |\n",
            "| policy_entropy     | 3.416559e-05  |\n",
            "| policy_loss        | 1.1768861e-09 |\n",
            "| serial_timesteps   | 485888        |\n",
            "| time_elapsed       | 4.31e+03      |\n",
            "| total_timesteps    | 3887104       |\n",
            "| value_loss         | 0.0025359956  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3890000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 927           |\n",
            "| n_updates          | 950           |\n",
            "| policy_entropy     | 3.4182405e-05 |\n",
            "| policy_loss        | 1.8135324e-09 |\n",
            "| serial_timesteps   | 486400        |\n",
            "| time_elapsed       | 4.31e+03      |\n",
            "| total_timesteps    | 3891200       |\n",
            "| value_loss         | 0.0025344982  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 936           |\n",
            "| n_updates          | 951           |\n",
            "| policy_entropy     | 3.4271234e-05 |\n",
            "| policy_loss        | 1.314038e-09  |\n",
            "| serial_timesteps   | 486912        |\n",
            "| time_elapsed       | 4.32e+03      |\n",
            "| total_timesteps    | 3895296       |\n",
            "| value_loss         | 0.0025762348  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 1.734697e-16   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 932            |\n",
            "| n_updates          | 952            |\n",
            "| policy_entropy     | 3.434819e-05   |\n",
            "| policy_loss        | -2.4592736e-10 |\n",
            "| serial_timesteps   | 487424         |\n",
            "| time_elapsed       | 4.32e+03       |\n",
            "| total_timesteps    | 3899392        |\n",
            "| value_loss         | 0.0026421188   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3900000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1917366e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 905           |\n",
            "| n_updates          | 953           |\n",
            "| policy_entropy     | 3.435098e-05  |\n",
            "| policy_loss        | 4.2255124e-10 |\n",
            "| serial_timesteps   | 487936        |\n",
            "| time_elapsed       | 4.33e+03      |\n",
            "| total_timesteps    | 3903488       |\n",
            "| value_loss         | 0.0025997744  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 4.8571516e-18  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 947            |\n",
            "| n_updates          | 954            |\n",
            "| policy_entropy     | 3.428972e-05   |\n",
            "| policy_loss        | -4.5110937e-10 |\n",
            "| serial_timesteps   | 488448         |\n",
            "| time_elapsed       | 4.33e+03       |\n",
            "| total_timesteps    | 3907584        |\n",
            "| value_loss         | 0.0025859363   |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=3910000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 1.9463296e-16  |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 906            |\n",
            "| n_updates          | 955            |\n",
            "| policy_entropy     | 3.4323948e-05  |\n",
            "| policy_loss        | -2.1536835e-10 |\n",
            "| serial_timesteps   | 488960         |\n",
            "| time_elapsed       | 4.34e+03       |\n",
            "| total_timesteps    | 3911680        |\n",
            "| value_loss         | 0.0026124476   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0            |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 940            |\n",
            "| n_updates          | 956            |\n",
            "| policy_entropy     | 3.4354925e-05  |\n",
            "| policy_loss        | -2.6993802e-10 |\n",
            "| serial_timesteps   | 489472         |\n",
            "| time_elapsed       | 4.34e+03       |\n",
            "| total_timesteps    | 3915776        |\n",
            "| value_loss         | 0.0025526788   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 7.9258466e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 934           |\n",
            "| n_updates          | 957           |\n",
            "| policy_entropy     | 3.4305824e-05 |\n",
            "| policy_loss        | 1.0022632e-09 |\n",
            "| serial_timesteps   | 489984        |\n",
            "| time_elapsed       | 4.35e+03      |\n",
            "| total_timesteps    | 3919872       |\n",
            "| value_loss         | 0.002553433   |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3920000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| approxkl           | 6.938841e-18   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 903            |\n",
            "| n_updates          | 958            |\n",
            "| policy_entropy     | 3.4291443e-05  |\n",
            "| policy_loss        | -1.0175427e-09 |\n",
            "| serial_timesteps   | 490496         |\n",
            "| time_elapsed       | 4.35e+03       |\n",
            "| total_timesteps    | 3923968        |\n",
            "| value_loss         | 0.0025891496   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.8466604e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 933           |\n",
            "| n_updates          | 959           |\n",
            "| policy_entropy     | 3.4245568e-05 |\n",
            "| policy_loss        | 1.056469e-09  |\n",
            "| serial_timesteps   | 491008        |\n",
            "| time_elapsed       | 4.35e+03      |\n",
            "| total_timesteps    | 3928064       |\n",
            "| value_loss         | 0.0025268472  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3930000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4935855e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 907           |\n",
            "| n_updates          | 960           |\n",
            "| policy_entropy     | 3.4224202e-05 |\n",
            "| policy_loss        | 6.3155314e-10 |\n",
            "| serial_timesteps   | 491520        |\n",
            "| time_elapsed       | 4.36e+03      |\n",
            "| total_timesteps    | 3932160       |\n",
            "| value_loss         | 0.0025541037  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.458205e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 937           |\n",
            "| n_updates          | 961           |\n",
            "| policy_entropy     | 3.4298148e-05 |\n",
            "| policy_loss        | -7.821655e-12 |\n",
            "| serial_timesteps   | 492032        |\n",
            "| time_elapsed       | 4.36e+03      |\n",
            "| total_timesteps    | 3936256       |\n",
            "| value_loss         | 0.0025640016  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3940000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3391961e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 894           |\n",
            "| n_updates          | 962           |\n",
            "| policy_entropy     | 3.4436194e-05 |\n",
            "| policy_loss        | 1.5825208e-09 |\n",
            "| serial_timesteps   | 492544        |\n",
            "| time_elapsed       | 4.37e+03      |\n",
            "| total_timesteps    | 3940352       |\n",
            "| value_loss         | 0.0025783705  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 2.0563347e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 944           |\n",
            "| n_updates          | 963           |\n",
            "| policy_entropy     | 3.4643588e-05 |\n",
            "| policy_loss        | 3.263267e-10  |\n",
            "| serial_timesteps   | 493056        |\n",
            "| time_elapsed       | 4.37e+03      |\n",
            "| total_timesteps    | 3944448       |\n",
            "| value_loss         | 0.0025815424  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.1865418e-16 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 936           |\n",
            "| n_updates          | 964           |\n",
            "| policy_entropy     | 3.4719596e-05 |\n",
            "| policy_loss        | 1.0113581e-09 |\n",
            "| serial_timesteps   | 493568        |\n",
            "| time_elapsed       | 4.38e+03      |\n",
            "| total_timesteps    | 3948544       |\n",
            "| value_loss         | 0.0025541233  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3950000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.7479039e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 868           |\n",
            "| n_updates          | 965           |\n",
            "| policy_entropy     | 3.481637e-05  |\n",
            "| policy_loss        | 3.6543496e-10 |\n",
            "| serial_timesteps   | 494080        |\n",
            "| time_elapsed       | 4.38e+03      |\n",
            "| total_timesteps    | 3952640       |\n",
            "| value_loss         | 0.0025688796  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.3877576e-18 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 938           |\n",
            "| n_updates          | 966           |\n",
            "| policy_entropy     | 3.4885197e-05 |\n",
            "| policy_loss        | 2.7222995e-09 |\n",
            "| serial_timesteps   | 494592        |\n",
            "| time_elapsed       | 4.39e+03      |\n",
            "| total_timesteps    | 3956736       |\n",
            "| value_loss         | 0.0025467318  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3960000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 1.6665295e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 895           |\n",
            "| n_updates          | 967           |\n",
            "| policy_entropy     | 3.4995457e-05 |\n",
            "| policy_loss        | -2.172601e-09 |\n",
            "| serial_timesteps   | 495104        |\n",
            "| time_elapsed       | 4.39e+03      |\n",
            "| total_timesteps    | 3960832       |\n",
            "| value_loss         | 0.0025755467  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 6.432326e-16   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 944            |\n",
            "| n_updates          | 968            |\n",
            "| policy_entropy     | 3.5114346e-05  |\n",
            "| policy_loss        | -6.1663744e-11 |\n",
            "| serial_timesteps   | 495616         |\n",
            "| time_elapsed       | 4.39e+03       |\n",
            "| total_timesteps    | 3964928        |\n",
            "| value_loss         | 0.0026073738   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.095809e-15  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 941           |\n",
            "| n_updates          | 969           |\n",
            "| policy_entropy     | 3.5061505e-05 |\n",
            "| policy_loss        | -1.033186e-10 |\n",
            "| serial_timesteps   | 496128        |\n",
            "| time_elapsed       | 4.4e+03       |\n",
            "| total_timesteps    | 3969024       |\n",
            "| value_loss         | 0.0026217054  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3970000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 5.818173e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 905           |\n",
            "| n_updates          | 970           |\n",
            "| policy_entropy     | 3.5091074e-05 |\n",
            "| policy_loss        | 1.0481017e-09 |\n",
            "| serial_timesteps   | 496640        |\n",
            "| time_elapsed       | 4.4e+03       |\n",
            "| total_timesteps    | 3973120       |\n",
            "| value_loss         | 0.0025943948  |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.9274391e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 930           |\n",
            "| n_updates          | 971           |\n",
            "| policy_entropy     | 3.52242e-05   |\n",
            "| policy_loss        | 1.6589183e-10 |\n",
            "| serial_timesteps   | 497152        |\n",
            "| time_elapsed       | 4.41e+03      |\n",
            "| total_timesteps    | 3977216       |\n",
            "| value_loss         | 0.0025687043  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3980000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 929           |\n",
            "| n_updates          | 972           |\n",
            "| policy_entropy     | 3.5268742e-05 |\n",
            "| policy_loss        | 1.5861588e-09 |\n",
            "| serial_timesteps   | 497664        |\n",
            "| time_elapsed       | 4.41e+03      |\n",
            "| total_timesteps    | 3981312       |\n",
            "| value_loss         | 0.0025344186  |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 9.985013e-16   |\n",
            "| clipfrac           | 0.0            |\n",
            "| ep_len_mean        | 16             |\n",
            "| ep_reward_mean     | 0.956          |\n",
            "| explained_variance | 0.852          |\n",
            "| fps                | 960            |\n",
            "| n_updates          | 973            |\n",
            "| policy_entropy     | 3.537782e-05   |\n",
            "| policy_loss        | -4.2091414e-10 |\n",
            "| serial_timesteps   | 498176         |\n",
            "| time_elapsed       | 4.42e+03       |\n",
            "| total_timesteps    | 3985408        |\n",
            "| value_loss         | 0.0025526609   |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 4.373196e-16  |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 935           |\n",
            "| n_updates          | 974           |\n",
            "| policy_entropy     | 3.542306e-05  |\n",
            "| policy_loss        | -7.566996e-10 |\n",
            "| serial_timesteps   | 498688        |\n",
            "| time_elapsed       | 4.42e+03      |\n",
            "| total_timesteps    | 3989504       |\n",
            "| value_loss         | 0.0025594882  |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=3990000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 16.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0           |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 898           |\n",
            "| n_updates          | 975           |\n",
            "| policy_entropy     | 3.529984e-05  |\n",
            "| policy_loss        | 8.6292856e-10 |\n",
            "| serial_timesteps   | 499200        |\n",
            "| time_elapsed       | 4.42e+03      |\n",
            "| total_timesteps    | 3993600       |\n",
            "| value_loss         | 0.002552853   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 1.4427616e-15 |\n",
            "| clipfrac           | 0.0           |\n",
            "| ep_len_mean        | 16            |\n",
            "| ep_reward_mean     | 0.956         |\n",
            "| explained_variance | 0.852         |\n",
            "| fps                | 945           |\n",
            "| n_updates          | 976           |\n",
            "| policy_entropy     | 3.516167e-05  |\n",
            "| policy_loss        | -3.263267e-10 |\n",
            "| serial_timesteps   | 499712        |\n",
            "| time_elapsed       | 4.43e+03      |\n",
            "| total_timesteps    | 3997696       |\n",
            "| value_loss         | 0.002551312   |\n",
            "--------------------------------------\n",
            "Saving to logs/ppo2/MiniGrid-SimpleCrossingEnvUmaze-v0_2\n",
            "\u001b[0m[17051bd71e7d:02755] *** Process received signal ***\n",
            "[17051bd71e7d:02755] Signal: Segmentation fault (11)\n",
            "[17051bd71e7d:02755] Signal code: Address not mapped (1)\n",
            "[17051bd71e7d:02755] Failing at address: 0x7f33bac3420d\n",
            "[17051bd71e7d:02755] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7f33bdee9980]\n",
            "[17051bd71e7d:02755] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f33bdb288a5]\n",
            "[17051bd71e7d:02755] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f33be393e44]\n",
            "[17051bd71e7d:02755] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f33bdb29735]\n",
            "[17051bd71e7d:02755] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f33be391cb3]\n",
            "[17051bd71e7d:02755] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHBq73665yD"
      },
      "source": [
        "#### Evaluate trained agent\n",
        "\n",
        "\n",
        "You can remove the `--folder logs/` to evaluate pretrained agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw8YuEgU6bT3",
        "outputId": "1216c13d-837b-42ac-c15a-85ec3126ad10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python enjoy.py --algo ppo2 --env MiniGrid-SimpleCrossingS9N1-v0 --no-render --n-timesteps 5000 --folder logs/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"enjoy.py\", line 182, in <module>\n",
            "    main()\n",
            "  File \"enjoy.py\", line 77, in main\n",
            "    model_path = find_saved_model(algo, log_path, env_id, load_best=args.load_best)\n",
            "  File \"/content/rl-baselines-zoo/utils/utils.py\", line 369, in find_saved_model\n",
            "    raise ValueError(\"No model found for {} on {}, path: {}\".format(algo, env_id, model_path))\n",
            "ValueError: No model found for ppo2 on MiniGrid-SimpleCrossingS9N1-v0, path: logs/ppo2/MiniGrid-SimpleCrossingS9N1-v0.zip\n",
            "[821dccaef3a6:03091] *** Process received signal ***\n",
            "[821dccaef3a6:03091] Signal: Segmentation fault (11)\n",
            "[821dccaef3a6:03091] Signal code: Address not mapped (1)\n",
            "[821dccaef3a6:03091] Failing at address: 0x7fec1431620d\n",
            "[821dccaef3a6:03091] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7fec16dbb980]\n",
            "[821dccaef3a6:03091] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7fec169fa8a5]\n",
            "[821dccaef3a6:03091] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7fec17265e44]\n",
            "[821dccaef3a6:03091] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7fec169fb735]\n",
            "[821dccaef3a6:03091] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7fec17263cb3]\n",
            "[821dccaef3a6:03091] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Il2J0VHPLC"
      },
      "source": [
        "#### Tune Hyperparameters\n",
        "\n",
        "We use [Optuna](https://optuna.org/) for optimizing the hyperparameters.\n",
        "\n",
        "Tune the hyperparameters for PPO2, using a tpe sampler and median pruner, 2 parallels jobs,\n",
        "with a budget of 1000 trials and a maximum of 50000 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2sC22eGHTH-"
      },
      "source": [
        "!python -m train.py --algo ppo2 --env MiniGrid-SimpleCrossingS9N1-v0 --gym-packages gym_minigrid -n 5000 -optimize --n-trials 100 --n-jobs 8 --sampler tpe --pruner median"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Record  a Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS1VBBaQ_emT"
      },
      "source": [
        "!pip install pyglet==1.3.1  # pyglet v1.4.1 throws an error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip3AauLzwNGP"
      },
      "source": [
        "!python -m utils.record_video --algo a2c --env CartPole-v1 --exp-id 0 -f logs/ -n 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBuUfnzI8DN6"
      },
      "source": [
        "### Display the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC3OTfpf8CXu"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKOjFuwK9HI0"
      },
      "source": [
        "show_videos(prefix='a2c')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjdpP0HE8D2p"
      },
      "source": [
        "### Continue Training\n",
        "\n",
        "Here, we will continue training of the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgMZQJJF6u1C"
      },
      "source": [
        "!python train.py --algo a2c --env CartPole-v1 --n-timesteps 50000 -i logs/a2c/CartPole-v1.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSaoyiAE8cVj"
      },
      "source": [
        "!python enjoy.py --algo a2c --env CartPole-v1 --no-render --n-timesteps 1000 --folder logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL9u4I1H-48O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}