{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo StableBaselines.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KLpmSgmeN6PX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxXV_TQMVTV"
      },
      "source": [
        "### Descarga de Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3Jqzp-yr7r",
        "outputId": "6a1dd070-6e2e-4670-b127-e02a5b94125b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/maximecb/gym-minigrid.git\n",
        "%cd gym-minigrid\n",
        "!python setup.py install\n",
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines[mpi]==2.10.0\n",
        "!pip3 install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gym-minigrid'...\n",
            "remote: Enumerating objects: 1777, done.\u001b[K\n",
            "remote: Total 1777 (delta 0), reused 0 (delta 0), pack-reused 1777\u001b[K\n",
            "Receiving objects: 100% (1777/1777), 7.11 MiB | 36.22 MiB/s, done.\n",
            "Resolving deltas: 100% (1221/1221), done.\n",
            "/content/gym-minigrid\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating gym_minigrid.egg-info\n",
            "writing gym_minigrid.egg-info/PKG-INFO\n",
            "writing dependency_links to gym_minigrid.egg-info/dependency_links.txt\n",
            "writing requirements to gym_minigrid.egg-info/requires.txt\n",
            "writing top-level names to gym_minigrid.egg-info/top_level.txt\n",
            "writing manifest file 'gym_minigrid.egg-info/SOURCES.txt'\n",
            "writing manifest file 'gym_minigrid.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/gym_minigrid\n",
            "copying gym_minigrid/roomgrid.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/minigrid.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/__init__.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/wrappers.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/rendering.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/window.py -> build/lib/gym_minigrid\n",
            "copying gym_minigrid/register.py -> build/lib/gym_minigrid\n",
            "creating build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/playground_v0.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/fourrooms.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/lavagap.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/multiroom.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/gotodoor.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/keycorridor.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/distshift.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/unlockpickup.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/fetch.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/memory.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/putnear.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/redbluedoors.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/__init__.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/empty.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/unlock.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/doorkey.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/blockedunlockpickup.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/obstructedmaze.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/lockedroom.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/dynamicobstacles.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/crossing.py -> build/lib/gym_minigrid/envs\n",
            "copying gym_minigrid/envs/gotoobject.py -> build/lib/gym_minigrid/envs\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "creating build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/playground_v0.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/fourrooms.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/lavagap.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/multiroom.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/gotodoor.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/keycorridor.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/distshift.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/unlockpickup.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/fetch.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/memory.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/putnear.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/redbluedoors.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/__init__.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/empty.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/unlock.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/doorkey.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/blockedunlockpickup.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/obstructedmaze.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/lockedroom.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/dynamicobstacles.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/crossing.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/envs/gotoobject.py -> build/bdist.linux-x86_64/egg/gym_minigrid/envs\n",
            "copying build/lib/gym_minigrid/roomgrid.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/minigrid.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/__init__.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/wrappers.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/rendering.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/window.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "copying build/lib/gym_minigrid/register.py -> build/bdist.linux-x86_64/egg/gym_minigrid\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/playground_v0.py to playground_v0.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/fourrooms.py to fourrooms.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/lavagap.py to lavagap.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/multiroom.py to multiroom.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/gotodoor.py to gotodoor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/keycorridor.py to keycorridor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/distshift.py to distshift.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/unlockpickup.py to unlockpickup.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/fetch.py to fetch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/memory.py to memory.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/putnear.py to putnear.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/redbluedoors.py to redbluedoors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/empty.py to empty.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/unlock.py to unlock.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/doorkey.py to doorkey.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/blockedunlockpickup.py to blockedunlockpickup.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/obstructedmaze.py to obstructedmaze.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/lockedroom.py to lockedroom.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/dynamicobstacles.py to dynamicobstacles.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/crossing.py to crossing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/envs/gotoobject.py to gotoobject.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/roomgrid.py to roomgrid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/minigrid.py to minigrid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/wrappers.py to wrappers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/rendering.py to rendering.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/window.py to window.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/gym_minigrid/register.py to register.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gym_minigrid.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gym_minigrid.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gym_minigrid.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gym_minigrid.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying gym_minigrid.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/gym_minigrid-1.0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing gym_minigrid-1.0.1-py3.6.egg\n",
            "Copying gym_minigrid-1.0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding gym-minigrid 1.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/gym_minigrid-1.0.1-py3.6.egg\n",
            "Processing dependencies for gym-minigrid==1.0.1\n",
            "Searching for numpy==1.18.5\n",
            "Best match: numpy 1.18.5\n",
            "Adding numpy 1.18.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gym==0.17.3\n",
            "Best match: gym 0.17.3\n",
            "Adding gym 0.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyglet==1.5.0\n",
            "Best match: pyglet 1.5.0\n",
            "Adding pyglet 1.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cloudpickle==1.3.0\n",
            "Best match: cloudpickle 1.3.0\n",
            "Adding cloudpickle 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for gym-minigrid==1.0.1\n",
            "TensorFlow 1.x selected.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7 [783 kB]\n",
            "Fetched 783 kB in 1s (707 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting stable-baselines[mpi]==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/fe/db8159d4d79109c6c8942abe77c7ba6b6e008c32ae55870a35e73fa10db3/stable_baselines-2.10.0-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.18.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->stable-baselines[mpi]==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Installing collected packages: stable-baselines\n",
            "  Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.0\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56usX4V4MgTq"
      },
      "source": [
        "### Importar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "outputId": "41d85658-d17a-4735-a92a-118d183fc12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import gym_minigrid\n",
        "import numpy as np\n",
        "from stable_baselines.common.vec_env import *\n",
        "from stable_baselines.bench.monitor import *\n",
        "from stable_baselines.common import set_global_seeds\n",
        "from stable_baselines import PPO2, DDPG, DQN, A2C, ACER, TRPO\n",
        "from stable_baselines.common.policies import MlpPolicy, CnnPolicy, MlpLstmPolicy, MlpLnLstmPolicy, CnnLstmPolicy, CnnLnLstmPolicy\n",
        "# from stable_baselines.deepq.policies import MlpPolicy, CnnPolicy\n",
        "from stable_baselines.common.evaluation import evaluate_policy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_X-G5NnMr2i"
      },
      "source": [
        "### Carga de Entorno Minigrid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "source": [
        "# Eenvironement for learning\n",
        "# Use a separate environement for evaluation\n",
        "from gym_minigrid.wrappers import *\n",
        "\n",
        "env_id = 'MiniGrid-LavaCrossingS9N1-v0'\n",
        "eval_env = gym.make(env_id)\n",
        "# env = make_vec_env(env, n_envs=2)\n",
        "eval_env = RGBImgObsWrapper(eval_env) # Get pixel observations\n",
        "eval_env  = ImgObsWrapper(eval_env) # Get rid of the 'mission' field\n",
        "# env = DirectionObsWrapper(env)\n",
        "# env = FlatObsWrapper(env)\n",
        "# env = gym.make('MiniGrid-DoorKey-5x5-v0')\n",
        "# print(env.observation_space)\n",
        "# print(env.action_space) # 7\n",
        "\n",
        "# vectorized environments allow to easily multiprocess training\n",
        "# we demonstrate its usefulness in the next examples\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggH5T4vIJLqM"
      },
      "source": [
        "def make_env(env_id, rank, seed=0):\n",
        "    \"\"\"\n",
        "    Utility function for multiprocessed env.\n",
        "    \n",
        "    :param env_id: (str) the environment ID\n",
        "    :param seed: (int) the inital seed for RNG\n",
        "    :param rank: (int) index of the subprocess\n",
        "    \"\"\"\n",
        "    def _init():\n",
        "        env = gym.make(env_id)\n",
        "        env = RGBImgObsWrapper(env) # Get pixel observations\n",
        "        env = ImgObsWrapper(env)\n",
        "        env = Monitor(env, './monitor_ppo2')\n",
        "        # Important: use a different seed for each environment\n",
        "        env.seed(seed + rank)\n",
        "        return env\n",
        "    set_global_seeds(seed)\n",
        "    return _init"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAcx8k-JMtm",
        "outputId": "4b157a9c-cf4a-4e4c-f61a-1f4ecc145a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_process = 8\n",
        "env = DummyVecEnv([make_env(env_id, i) for i in range(n_process)])\n",
        "train_env = VecNormalize(env)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xz3YmHXN_Nw",
        "outputId": "4d18356f-6c6e-42bc-dfeb-cba00d465d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%cd /content/gym-minigrid/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gym-minigrid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHLMA6NFk95"
      },
      "source": [
        "# Use a separate environement for evaluation\n",
        "# eval_env = gym.make('CartPole-v1')\n",
        "\n",
        "# Random Agent, before training\n",
        "# mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
        "\n",
        "# print(f\"mean_reward for random agent:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyygEePNZB5"
      },
      "source": [
        "### Definicion de Modelo del Agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCys-Vg-yYR"
      },
      "source": [
        "agent_model = PPO2(\n",
        "    'CnnPolicy',\n",
        "     train_env,\n",
        "      ent_coef=0.0,\n",
        "       nminibatches=32,\n",
        "        noptepochs=10,\n",
        "         verbose=1,\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k9PbbcWNn68"
      },
      "source": [
        "### Evaluar Agente Ingenuo/Aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqks9c0T-IDm"
      },
      "source": [
        "def evaluate(model, eval_env, num_episodes=100):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param model: (BaseRLModel object) the RL Agent\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    # This function will only work for a single Environment\n",
        "    # env = gnwrapper.LoopAnimation(model.get_env()) # Start Xvfb\n",
        "    env = eval_env\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset()\n",
        "        while not done:\n",
        "            # _states are only useful when using LSTM policies\n",
        "            action, _states = model.predict(obs)\n",
        "            # here, action, rewards and dones are arrays\n",
        "            # because we are using vectorized env\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            # env.render()\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "        \n",
        "\n",
        "    # env.display()\n",
        "    max_episode_reward = np.amax(all_episode_rewards)\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    min_episode_reward = np.amin(all_episode_rewards)\n",
        "    print(\n",
        "        \"Max reward:\", max_episode_reward,\n",
        "        \"Mean reward:\", mean_episode_reward,\n",
        "        \"Min reward:\", min_episode_reward,\n",
        "         \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return max_episode_reward, mean_episode_reward, min_episode_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQTdpYv9xJN",
        "outputId": "65fdcbc0-8a75-4160-8139-d72775dd3056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Random Agent, before training using property\n",
        "# from stable_baselines.common.evaluation import evaluate_policy\n",
        "max_r, mean_r, min_r = evaluate(agent_model, eval_env, num_episodes=1000)\n",
        "\n",
        "# print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max reward: 0 Mean reward: 0.0 Min reward: 0 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjAP8NWNu_6"
      },
      "source": [
        "### Entrenar Agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHGB-VN-81O",
        "outputId": "8c3a6a2c-9b96-4080-f6e5-8d9ea4c358a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "agent_model.learn(total_timesteps=10000, log_interval=10)\n",
        "train_env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| approxkl           | 0.011721635   |\n",
            "| clipfrac           | 0.175         |\n",
            "| ep_len_mean        | 58.6          |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | 0.636         |\n",
            "| fps                | 258           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 1.9330553     |\n",
            "| policy_loss        | -0.022883493  |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.98e-05      |\n",
            "| total_timesteps    | 1024          |\n",
            "| value_loss         | 0.00035427717 |\n",
            "--------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcsEVysINz9j"
      },
      "source": [
        "### Evaluar Agente Entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5chx6sxfN76",
        "outputId": "ee2d11b3-c408-41ba-a662-a9b318ccc8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Trained Agent, after training using property\n",
        "# from stable_baselines.common.evaluation import evaluate_policy\n",
        "max_r, mean_r, min_r = evaluate(agent_model, eval_env, num_episodes=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max reward: 0.4666666666666667 Mean reward: 0.004666666666666667 Min reward: 0.0 Num episodes: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP9AbAmzqDYP"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create save dir\n",
        "save_dir = \"/tmp/gym/\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLpmSgmeN6PX"
      },
      "source": [
        "### Extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIe43E_dSBRy"
      },
      "source": [
        "import gym_minigrid\n",
        "\n",
        "env = gym.make('MiniGrid-SimpleCrossingEnvUmaze-v0')\n",
        "for i_episode in range(3):\n",
        "    obs = env.reset()\n",
        "    for t_steps in range(100):\n",
        "        # env.render()\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        print(obs)\n",
        "        if done:\n",
        "            print(\"Episode finished after {} timesteps\".format(t_steps+1))\n",
        "            break\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df08vXY_MtHg"
      },
      "source": [
        "!apt update && apt install xvfb\n",
        "!pip install gym-notebook-wrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4A_IOZ_9fzW"
      },
      "source": [
        "# Random Agent, before training using function\n",
        "mean_reward_before_train = evaluate(agent_model, eval_env, num_episodes=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXOU1gvsHyT"
      },
      "source": [
        "!pip install tensorboard==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuCkk1M-kPGP"
      },
      "source": [
        "# Trained Agent\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(agent_model, train_env, n_eval_episodes=100)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA5AjICfkVZl"
      },
      "source": [
        "!tensorboard --logdir ./ppo2_minigriddoorkey/ --host localhost "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}