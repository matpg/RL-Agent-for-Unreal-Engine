{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo zoo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matpg/RL-Agent-for-Unreal-Engine/blob/main/Codigo_zoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJy9QoDC7XA7"
      },
      "source": [
        "# RL Baselines Zoo: Training in Colab\n",
        "\n",
        "\n",
        "\n",
        "Github Repo: [https://github.com/araffin/rl-baselines-zoo](https://github.com/araffin/rl-baselines-zoo)\n",
        "\n",
        "Stable-Baselines Repo: [https://github.com/hill-a/stable-baselines](https://github.com/hill-a/stable-baselines)\n",
        "\n",
        "Medium article: [https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82](https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-df87c4b2fc82)\n",
        "\n",
        "# Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXVDDlTn02M9",
        "outputId": "0799908c-2a11-4d53-a54a-5f5a4afed93c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!apt-get update\n",
        "!apt-get install swig cmake libopenmpi-dev zlib1g-dev ffmpeg freeglut3-dev xvfb\n",
        "!pip install stable-baselines[mpi] --upgrade\n",
        "!pip install pybullet\n",
        "!pip install box2d box2d-kengz pyyaml pytablewriter optuna scikit-optimize\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,750 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,354 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [405 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,687 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,167 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,119 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n",
            "Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [48.9 kB]\n",
            "Fetched 10.7 MB in 3s (3,885 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0 xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,884 kB of archives.\n",
            "After this operation, 8,089 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7 [783 kB]\n",
            "Fetched 1,884 kB in 1s (2,439 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting stable-baselines[mpi]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/48/d428b79bd4360727925f9fe34afeea7a9da381da3dc8748df834a349ad1d/stable_baselines-2.10.1-py3-none-any.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.3)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: mpi4py; extra == \"mpi\" in /tensorflow-1.15.2/python3.6 (from stable-baselines[mpi]) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.6)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Installing collected packages: stable-baselines\n",
            "  Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.1\n",
            "Collecting pybullet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/61/2fc2c19327966ca4e4133211be3f4dcc56c1ee6f392d71d0da8c6c1a4cba/pybullet-3.0.6-cp36-cp36m-manylinux1_x86_64.whl (102.2MB)\n",
            "\u001b[K     |████████████████████████████████| 102.2MB 100kB/s \n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.0.6\n",
            "Collecting box2d\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/0b/d48d42dd9e19ce83a3fb4eee074e785b6c6ea612a2244dc2ef69427d338b/Box2D-2.3.10-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 10.5MB/s \n",
            "\u001b[?25hCollecting box2d-kengz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/20/51d6c0c87f7642efb709c518fb0ca8e5eab068259588552c41da5926ae27/Box2D-kengz-2.3.3.tar.gz (425kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting pytablewriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/e2/62b208cdb8771dee1849bd2b4ed129284e1efff7669985697e4c124c1000/pytablewriter-0.58.0-py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
            "\u001b[?25hCollecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 60.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (50.3.2)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/57/3bb55beafe0a5e9883621f01a560d16bcef6d4f844dc2dd40caa0a8d9182/mbstrdecoder-1.0.0-py3-none-any.whl\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/02/51/bbb0cc7f30771c285c354634bf83653a2871d58c6923bd29bfddeb9c9cb1/tcolorpy-0.0.8-py3-none-any.whl\n",
            "Collecting DataProperty<2,>=0.50.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/2d/e5413965af992f4e489b6f5eebf52db9c17953c772962d1223d434b05cef/DataProperty-0.50.0-py3-none-any.whl\n",
            "Collecting typepy[datetime]<2,>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/55/a1111b2eb1f4096c28b14645ca62aec560b1768338af21620e470b60872f/typepy-1.1.1-py3-none-any.whl\n",
            "Collecting msgfy<1,>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/48/52/c4441871514276e7c4cb51c122e663b5ef19dc20030f6ab7723071118464/msgfy-0.1.0-py3-none-any.whl\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/fa/1a951084aa93940399800e37ed6f096ad5c0de3c26604be62f9464a39fc1/pathvalidate-2.3.0-py3-none-any.whl\n",
            "Collecting tabledata<2,>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/df/b2/264d9707502f0259a3eb82ec48064df98b1735d5a5f315b6a1d7105263f4/tabledata-1.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.17.0)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/c5/3b70cdb81cc865e8a554d7945ed5e09c2973056294ae5a3123345a1d93a3/colorlog-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.4 in /usr/local/lib/python3.6/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2018.9; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter) (2018.9)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<2,>=1.1.1->pytablewriter) (2.8.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/94/0f4f16cff4977188d715a95ea3f90f054b7eb73b05afaf51431a3d77b992/cmd2-1.3.11-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 50.8MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a1/004f04ba411a8002b02aadb089fd6868116c12ddc9f6d576175e89d07587/stevedore-3.2.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (2.0.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.2.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.4.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=2146ae106dcf3ace3213557b870c52f027ce996b8d888ab037adcf85d13d2b15\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: box2d-kengz, PrettyTable, pyperclip\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp36-cp36m-linux_x86_64.whl size=2009687 sha256=2c6ed0170f8677ddeb86036293dc39ee86fef59281653ce2330a2683895ade87\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/ae/e5/8bc678d262caad94659c199c540550e59d03dd3bd3684d4f1a\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=feb1827cebc874bede13ee205115ca7c637c65ebff1bac41ef9aa7c889871bad\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=db7358eaaed4e00c7492281ad8dc7e77c2dd6964d40b7ff57f3b92478a8daa0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built box2d-kengz PrettyTable pyperclip\n",
            "Installing collected packages: box2d, box2d-kengz, mbstrdecoder, tcolorpy, typepy, DataProperty, msgfy, pathvalidate, tabledata, pytablewriter, cmaes, python-editor, Mako, alembic, colorlog, colorama, pyperclip, cmd2, pbr, PrettyTable, stevedore, cliff, optuna, pyaml, scikit-optimize\n",
            "  Found existing installation: prettytable 1.0.1\n",
            "    Uninstalling prettytable-1.0.1:\n",
            "      Successfully uninstalled prettytable-1.0.1\n",
            "Successfully installed DataProperty-0.50.0 Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 box2d-2.3.10 box2d-kengz-2.3.3 cliff-3.4.0 cmaes-0.7.0 cmd2-1.3.11 colorama-0.4.4 colorlog-4.5.0 mbstrdecoder-1.0.0 msgfy-0.1.0 optuna-2.3.0 pathvalidate-2.3.0 pbr-5.5.1 pyaml-20.4.0 pyperclip-1.8.1 pytablewriter-0.58.0 python-editor-1.0.4 scikit-optimize-0.8.1 stevedore-3.2.2 tabledata-1.1.3 tcolorpy-0.0.8 typepy-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjF3qRg7oGH"
      },
      "source": [
        "## Clone RL Baselines Zoo Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCjGikdT1DFy",
        "outputId": "0b833aac-72a7-4be2-db48-a01f4f808ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rl-baselines-zoo'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1829 (delta 12), reused 18 (delta 8), pack-reused 1796\u001b[K\n",
            "Receiving objects: 100% (1829/1829), 375.67 MiB | 40.61 MiB/s, done.\n",
            "Resolving deltas: 100% (1077/1077), done.\n",
            "Checking out files: 100% (333/333), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMQlh-ezyVt",
        "outputId": "fab1b3fd-5159-4010-d3e7-5e87e665ae2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd rl-baselines-zoo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rl-baselines-zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ-pAbF7zRZ"
      },
      "source": [
        "## Train an RL Agent\n",
        "\n",
        "\n",
        "The train agent can be found in the `logs/` folder.\n",
        "\n",
        "Here we will train A2C on CartPole-v1 environment for 100 000 steps. \n",
        "\n",
        "\n",
        "To train it on Pong (Atari), you just have to pass `--env PongNoFrameskip-v4`\n",
        "\n",
        "Note: You need to update `hyperparams/algo.yml` to support new environments. You can access it in the side panel of Google Colab. (see https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34lXM8ZfMQfG"
      },
      "source": [
        "!pip install gym-minigrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bIR_N7R11XI",
        "outputId": "4560a7c9-867a-44f4-b448-ee4656a0af2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!python train.py --algo ppo2 --env MiniGrid-SimpleCrossingEnvUmaze-v0 --gym-packages gym_minigrid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "========== MiniGrid-SimpleCrossingEnvUmaze-v0 ==========\n",
            "Seed: 0\n",
            "OrderedDict([('cliprange', 0.2),\n",
            "             ('ent_coef', 0.0),\n",
            "             ('env_wrapper', 'gym_minigrid.wrappers.FlatObsWrapper'),\n",
            "             ('gamma', 0.99),\n",
            "             ('lam', 0.95),\n",
            "             ('learning_rate', 0.00025),\n",
            "             ('n_envs', 8),\n",
            "             ('n_steps', 128),\n",
            "             ('n_timesteps', 100000.0),\n",
            "             ('nminibatches', 32),\n",
            "             ('noptepochs', 10),\n",
            "             ('normalize', True),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 8 environments\n",
            "Normalizing input and reward\n",
            "Creating test environment\n",
            "Normalization activated: {'norm_reward': False}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Log path: logs/ppo2/MiniGrid-SimpleCrossingEnvUmaze-v0_1\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0067002177 |\n",
            "| clipfrac           | 0.09746094   |\n",
            "| explained_variance | -0.959       |\n",
            "| fps                | 390          |\n",
            "| n_updates          | 1            |\n",
            "| policy_entropy     | 1.9388874    |\n",
            "| policy_loss        | -0.030959154 |\n",
            "| serial_timesteps   | 128          |\n",
            "| time_elapsed       | 1.69e-05     |\n",
            "| total_timesteps    | 1024         |\n",
            "| value_loss         | 0.07331496   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009055118  |\n",
            "| clipfrac           | 0.14003906   |\n",
            "| explained_variance | -4.54        |\n",
            "| fps                | 498          |\n",
            "| n_updates          | 2            |\n",
            "| policy_entropy     | 1.9242947    |\n",
            "| policy_loss        | -0.036122512 |\n",
            "| serial_timesteps   | 256          |\n",
            "| time_elapsed       | 2.62         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 0.03716311   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010128113  |\n",
            "| clipfrac           | 0.15488282   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -2.07        |\n",
            "| fps                | 504          |\n",
            "| n_updates          | 3            |\n",
            "| policy_entropy     | 1.9206661    |\n",
            "| policy_loss        | -0.028009912 |\n",
            "| serial_timesteps   | 384          |\n",
            "| time_elapsed       | 4.67         |\n",
            "| total_timesteps    | 3072         |\n",
            "| value_loss         | 0.023809709  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.005576391  |\n",
            "| clipfrac           | 0.07392578   |\n",
            "| ep_len_mean        | 306          |\n",
            "| ep_reward_mean     | 0.0605       |\n",
            "| explained_variance | -0.0571      |\n",
            "| fps                | 423          |\n",
            "| n_updates          | 4            |\n",
            "| policy_entropy     | 1.9057281    |\n",
            "| policy_loss        | -0.018616717 |\n",
            "| serial_timesteps   | 512          |\n",
            "| time_elapsed       | 6.71         |\n",
            "| total_timesteps    | 4096         |\n",
            "| value_loss         | 0.36904645   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0073329573 |\n",
            "| clipfrac           | 0.11123047   |\n",
            "| ep_len_mean        | 295          |\n",
            "| ep_reward_mean     | 0.108        |\n",
            "| explained_variance | -0.0385      |\n",
            "| fps                | 492          |\n",
            "| n_updates          | 5            |\n",
            "| policy_entropy     | 1.9020917    |\n",
            "| policy_loss        | -0.017872697 |\n",
            "| serial_timesteps   | 640          |\n",
            "| time_elapsed       | 9.12         |\n",
            "| total_timesteps    | 5120         |\n",
            "| value_loss         | 0.75931454   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.012403693 |\n",
            "| clipfrac           | 0.17216797  |\n",
            "| ep_len_mean        | 304         |\n",
            "| ep_reward_mean     | 0.0745      |\n",
            "| explained_variance | -2.08       |\n",
            "| fps                | 505         |\n",
            "| n_updates          | 6           |\n",
            "| policy_entropy     | 1.8736448   |\n",
            "| policy_loss        | -0.02592639 |\n",
            "| serial_timesteps   | 768         |\n",
            "| time_elapsed       | 11.2        |\n",
            "| total_timesteps    | 6144        |\n",
            "| value_loss         | 0.005882794 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007767327  |\n",
            "| clipfrac           | 0.095898435  |\n",
            "| ep_len_mean        | 306          |\n",
            "| ep_reward_mean     | 0.0736       |\n",
            "| explained_variance | -0.0275      |\n",
            "| fps                | 503          |\n",
            "| n_updates          | 7            |\n",
            "| policy_entropy     | 1.8616793    |\n",
            "| policy_loss        | -0.013249968 |\n",
            "| serial_timesteps   | 896          |\n",
            "| time_elapsed       | 13.2         |\n",
            "| total_timesteps    | 7168         |\n",
            "| value_loss         | 0.36794958   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010831436  |\n",
            "| clipfrac           | 0.16220704   |\n",
            "| ep_len_mean        | 310          |\n",
            "| ep_reward_mean     | 0.0552       |\n",
            "| explained_variance | -1.93        |\n",
            "| fps                | 497          |\n",
            "| n_updates          | 8            |\n",
            "| policy_entropy     | 1.8845932    |\n",
            "| policy_loss        | -0.026034664 |\n",
            "| serial_timesteps   | 1024         |\n",
            "| time_elapsed       | 15.3         |\n",
            "| total_timesteps    | 8192         |\n",
            "| value_loss         | 0.011687205  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0075779483 |\n",
            "| clipfrac           | 0.11464844   |\n",
            "| ep_len_mean        | 309          |\n",
            "| ep_reward_mean     | 0.0621       |\n",
            "| explained_variance | 0.0379       |\n",
            "| fps                | 504          |\n",
            "| n_updates          | 9            |\n",
            "| policy_entropy     | 1.879406     |\n",
            "| policy_loss        | -0.016552422 |\n",
            "| serial_timesteps   | 1152         |\n",
            "| time_elapsed       | 17.3         |\n",
            "| total_timesteps    | 9216         |\n",
            "| value_loss         | 0.36566836   |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "New best mean reward!\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008561641  |\n",
            "| clipfrac           | 0.11875      |\n",
            "| ep_len_mean        | 305          |\n",
            "| ep_reward_mean     | 0.0745       |\n",
            "| explained_variance | 0.00737      |\n",
            "| fps                | 185          |\n",
            "| n_updates          | 10           |\n",
            "| policy_entropy     | 1.8487804    |\n",
            "| policy_loss        | -0.020714018 |\n",
            "| serial_timesteps   | 1280         |\n",
            "| time_elapsed       | 19.4         |\n",
            "| total_timesteps    | 10240        |\n",
            "| value_loss         | 0.26223537   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.008477587 |\n",
            "| clipfrac           | 0.12539062  |\n",
            "| ep_len_mean        | 307         |\n",
            "| ep_reward_mean     | 0.0652      |\n",
            "| explained_variance | -1.99       |\n",
            "| fps                | 496         |\n",
            "| n_updates          | 11          |\n",
            "| policy_entropy     | 1.8309158   |\n",
            "| policy_loss        | -0.02629121 |\n",
            "| serial_timesteps   | 1408        |\n",
            "| time_elapsed       | 24.9        |\n",
            "| total_timesteps    | 11264       |\n",
            "| value_loss         | 0.007844612 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009638061  |\n",
            "| clipfrac           | 0.14335938   |\n",
            "| ep_len_mean        | 309          |\n",
            "| ep_reward_mean     | 0.0596       |\n",
            "| explained_variance | -0.868       |\n",
            "| fps                | 504          |\n",
            "| n_updates          | 12           |\n",
            "| policy_entropy     | 1.8123935    |\n",
            "| policy_loss        | -0.025806347 |\n",
            "| serial_timesteps   | 1536         |\n",
            "| time_elapsed       | 26.9         |\n",
            "| total_timesteps    | 12288        |\n",
            "| value_loss         | 0.0018443319 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011035143  |\n",
            "| clipfrac           | 0.18955079   |\n",
            "| ep_len_mean        | 311          |\n",
            "| ep_reward_mean     | 0.0522       |\n",
            "| explained_variance | -1.59        |\n",
            "| fps                | 492          |\n",
            "| n_updates          | 13           |\n",
            "| policy_entropy     | 1.7924677    |\n",
            "| policy_loss        | -0.02906003  |\n",
            "| serial_timesteps   | 1664         |\n",
            "| time_elapsed       | 29           |\n",
            "| total_timesteps    | 13312        |\n",
            "| value_loss         | 0.0026625972 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012140665  |\n",
            "| clipfrac           | 0.21279296   |\n",
            "| ep_len_mean        | 311          |\n",
            "| ep_reward_mean     | 0.0497       |\n",
            "| explained_variance | -1.13        |\n",
            "| fps                | 503          |\n",
            "| n_updates          | 14           |\n",
            "| policy_entropy     | 1.7962229    |\n",
            "| policy_loss        | -0.02745809  |\n",
            "| serial_timesteps   | 1792         |\n",
            "| time_elapsed       | 31           |\n",
            "| total_timesteps    | 14336        |\n",
            "| value_loss         | 0.0022953732 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010901492  |\n",
            "| clipfrac           | 0.14453125   |\n",
            "| ep_len_mean        | 312          |\n",
            "| ep_reward_mean     | 0.0474       |\n",
            "| explained_variance | -1.5         |\n",
            "| fps                | 447          |\n",
            "| n_updates          | 15           |\n",
            "| policy_entropy     | 1.7752256    |\n",
            "| policy_loss        | -0.024444541 |\n",
            "| serial_timesteps   | 1920         |\n",
            "| time_elapsed       | 33.1         |\n",
            "| total_timesteps    | 15360        |\n",
            "| value_loss         | 0.0007586137 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010121565   |\n",
            "| clipfrac           | 0.1415039     |\n",
            "| ep_len_mean        | 313           |\n",
            "| ep_reward_mean     | 0.0435        |\n",
            "| explained_variance | 0.0024        |\n",
            "| fps                | 489           |\n",
            "| n_updates          | 16            |\n",
            "| policy_entropy     | 1.7341524     |\n",
            "| policy_loss        | -0.019346874  |\n",
            "| serial_timesteps   | 2048          |\n",
            "| time_elapsed       | 35.4          |\n",
            "| total_timesteps    | 16384         |\n",
            "| value_loss         | 0.00045811306 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0113283945 |\n",
            "| clipfrac           | 0.1774414    |\n",
            "| ep_len_mean        | 314          |\n",
            "| ep_reward_mean     | 0.0409       |\n",
            "| explained_variance | -0.729       |\n",
            "| fps                | 501          |\n",
            "| n_updates          | 17           |\n",
            "| policy_entropy     | 1.7710335    |\n",
            "| policy_loss        | -0.024987103 |\n",
            "| serial_timesteps   | 2176         |\n",
            "| time_elapsed       | 37.5         |\n",
            "| total_timesteps    | 17408        |\n",
            "| value_loss         | 0.0003913539 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009864201   |\n",
            "| clipfrac           | 0.15263672    |\n",
            "| ep_len_mean        | 314           |\n",
            "| ep_reward_mean     | 0.0373        |\n",
            "| explained_variance | -0.211        |\n",
            "| fps                | 492           |\n",
            "| n_updates          | 18            |\n",
            "| policy_entropy     | 1.7796484     |\n",
            "| policy_loss        | -0.020107377  |\n",
            "| serial_timesteps   | 2304          |\n",
            "| time_elapsed       | 39.5          |\n",
            "| total_timesteps    | 18432         |\n",
            "| value_loss         | 0.00026129087 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011167271  |\n",
            "| clipfrac           | 0.1453125    |\n",
            "| ep_len_mean        | 315          |\n",
            "| ep_reward_mean     | 0.0366       |\n",
            "| explained_variance | -2.64        |\n",
            "| fps                | 493          |\n",
            "| n_updates          | 19           |\n",
            "| policy_entropy     | 1.7535807    |\n",
            "| policy_loss        | -0.022755709 |\n",
            "| serial_timesteps   | 2432         |\n",
            "| time_elapsed       | 41.6         |\n",
            "| total_timesteps    | 19456        |\n",
            "| value_loss         | 6.308447e-05 |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008072674   |\n",
            "| clipfrac           | 0.10859375    |\n",
            "| ep_len_mean        | 315           |\n",
            "| ep_reward_mean     | 0.0348        |\n",
            "| explained_variance | -1.9          |\n",
            "| fps                | 184           |\n",
            "| n_updates          | 20            |\n",
            "| policy_entropy     | 1.7626013     |\n",
            "| policy_loss        | -0.01856153   |\n",
            "| serial_timesteps   | 2560          |\n",
            "| time_elapsed       | 43.6          |\n",
            "| total_timesteps    | 20480         |\n",
            "| value_loss         | 0.00019865995 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0102296695 |\n",
            "| clipfrac           | 0.15039062   |\n",
            "| ep_len_mean        | 316          |\n",
            "| ep_reward_mean     | 0.0326       |\n",
            "| explained_variance | -1.94        |\n",
            "| fps                | 508          |\n",
            "| n_updates          | 21           |\n",
            "| policy_entropy     | 1.7388674    |\n",
            "| policy_loss        | -0.024374684 |\n",
            "| serial_timesteps   | 2688         |\n",
            "| time_elapsed       | 49.2         |\n",
            "| total_timesteps    | 21504        |\n",
            "| value_loss         | 9.526286e-05 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009531324  |\n",
            "| clipfrac           | 0.15976563   |\n",
            "| ep_len_mean        | 315          |\n",
            "| ep_reward_mean     | 0.0364       |\n",
            "| explained_variance | -0.00193     |\n",
            "| fps                | 501          |\n",
            "| n_updates          | 22           |\n",
            "| policy_entropy     | 1.701868     |\n",
            "| policy_loss        | -0.022411251 |\n",
            "| serial_timesteps   | 2816         |\n",
            "| time_elapsed       | 51.2         |\n",
            "| total_timesteps    | 22528        |\n",
            "| value_loss         | 0.12909141   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009442471   |\n",
            "| clipfrac           | 0.12841797    |\n",
            "| ep_len_mean        | 315           |\n",
            "| ep_reward_mean     | 0.0339        |\n",
            "| explained_variance | -5.84         |\n",
            "| fps                | 454           |\n",
            "| n_updates          | 23            |\n",
            "| policy_entropy     | 1.6759589     |\n",
            "| policy_loss        | -0.014178643  |\n",
            "| serial_timesteps   | 2944          |\n",
            "| time_elapsed       | 53.2          |\n",
            "| total_timesteps    | 23552         |\n",
            "| value_loss         | 0.00036000492 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011143192   |\n",
            "| clipfrac           | 0.19746093    |\n",
            "| ep_len_mean        | 316           |\n",
            "| ep_reward_mean     | 0.033         |\n",
            "| explained_variance | -0.134        |\n",
            "| fps                | 453           |\n",
            "| n_updates          | 24            |\n",
            "| policy_entropy     | 1.6596664     |\n",
            "| policy_loss        | -0.024415057  |\n",
            "| serial_timesteps   | 3072          |\n",
            "| time_elapsed       | 55.5          |\n",
            "| total_timesteps    | 24576         |\n",
            "| value_loss         | 0.00022398429 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012823844  |\n",
            "| clipfrac           | 0.1751953    |\n",
            "| ep_len_mean        | 316          |\n",
            "| ep_reward_mean     | 0.0321       |\n",
            "| explained_variance | -1.33        |\n",
            "| fps                | 502          |\n",
            "| n_updates          | 25           |\n",
            "| policy_entropy     | 1.6514496    |\n",
            "| policy_loss        | -0.021471681 |\n",
            "| serial_timesteps   | 3200         |\n",
            "| time_elapsed       | 57.8         |\n",
            "| total_timesteps    | 25600        |\n",
            "| value_loss         | 0.0011578713 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008712512   |\n",
            "| clipfrac           | 0.12734374    |\n",
            "| ep_len_mean        | 316           |\n",
            "| ep_reward_mean     | 0.0305        |\n",
            "| explained_variance | -1.32         |\n",
            "| fps                | 504           |\n",
            "| n_updates          | 26            |\n",
            "| policy_entropy     | 1.66449       |\n",
            "| policy_loss        | -0.017710123  |\n",
            "| serial_timesteps   | 3328          |\n",
            "| time_elapsed       | 59.8          |\n",
            "| total_timesteps    | 26624         |\n",
            "| value_loss         | 0.00057227176 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0113226    |\n",
            "| clipfrac           | 0.15263672   |\n",
            "| ep_len_mean        | 316          |\n",
            "| ep_reward_mean     | 0.0294       |\n",
            "| explained_variance | -3.41        |\n",
            "| fps                | 466          |\n",
            "| n_updates          | 27           |\n",
            "| policy_entropy     | 1.6515726    |\n",
            "| policy_loss        | -0.025810316 |\n",
            "| serial_timesteps   | 3456         |\n",
            "| time_elapsed       | 61.8         |\n",
            "| total_timesteps    | 27648        |\n",
            "| value_loss         | 0.0002649696 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.013461709  |\n",
            "| clipfrac           | 0.21982422   |\n",
            "| ep_len_mean        | 317          |\n",
            "| ep_reward_mean     | 0.0277       |\n",
            "| explained_variance | -0.405       |\n",
            "| fps                | 460          |\n",
            "| n_updates          | 28           |\n",
            "| policy_entropy     | 1.6936575    |\n",
            "| policy_loss        | -0.029524544 |\n",
            "| serial_timesteps   | 3584         |\n",
            "| time_elapsed       | 64           |\n",
            "| total_timesteps    | 28672        |\n",
            "| value_loss         | 9.926156e-05 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010813621   |\n",
            "| clipfrac           | 0.15390626    |\n",
            "| ep_len_mean        | 317           |\n",
            "| ep_reward_mean     | 0.0274        |\n",
            "| explained_variance | -4.01         |\n",
            "| fps                | 485           |\n",
            "| n_updates          | 29            |\n",
            "| policy_entropy     | 1.6910149     |\n",
            "| policy_loss        | -0.02070963   |\n",
            "| serial_timesteps   | 3712          |\n",
            "| time_elapsed       | 66.2          |\n",
            "| total_timesteps    | 29696         |\n",
            "| value_loss         | 0.00028782972 |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 0.00960722   |\n",
            "| clipfrac           | 0.11738281   |\n",
            "| ep_len_mean        | 317          |\n",
            "| ep_reward_mean     | 0.0265       |\n",
            "| explained_variance | -2.03        |\n",
            "| fps                | 178          |\n",
            "| n_updates          | 30           |\n",
            "| policy_entropy     | 1.6840461    |\n",
            "| policy_loss        | -0.020018447 |\n",
            "| serial_timesteps   | 3840         |\n",
            "| time_elapsed       | 68.4         |\n",
            "| total_timesteps    | 30720        |\n",
            "| value_loss         | 0.000982736  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01219164    |\n",
            "| clipfrac           | 0.20009765    |\n",
            "| ep_len_mean        | 317           |\n",
            "| ep_reward_mean     | 0.0254        |\n",
            "| explained_variance | -0.365        |\n",
            "| fps                | 475           |\n",
            "| n_updates          | 31            |\n",
            "| policy_entropy     | 1.6694868     |\n",
            "| policy_loss        | -0.018571353  |\n",
            "| serial_timesteps   | 3968          |\n",
            "| time_elapsed       | 74.1          |\n",
            "| total_timesteps    | 31744         |\n",
            "| value_loss         | 0.00015101957 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009547096  |\n",
            "| clipfrac           | 0.12929687   |\n",
            "| ep_len_mean        | 318          |\n",
            "| ep_reward_mean     | 0.0246       |\n",
            "| explained_variance | 0.0699       |\n",
            "| fps                | 456          |\n",
            "| n_updates          | 32           |\n",
            "| policy_entropy     | 1.6324266    |\n",
            "| policy_loss        | -0.016450748 |\n",
            "| serial_timesteps   | 4096         |\n",
            "| time_elapsed       | 76.2         |\n",
            "| total_timesteps    | 32768        |\n",
            "| value_loss         | 4.325815e-05 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010728171   |\n",
            "| clipfrac           | 0.1663086     |\n",
            "| ep_len_mean        | 318           |\n",
            "| ep_reward_mean     | 0.0244        |\n",
            "| explained_variance | 0.000832      |\n",
            "| fps                | 518           |\n",
            "| n_updates          | 33            |\n",
            "| policy_entropy     | 1.6386974     |\n",
            "| policy_loss        | -0.018141875  |\n",
            "| serial_timesteps   | 4224          |\n",
            "| time_elapsed       | 78.5          |\n",
            "| total_timesteps    | 33792         |\n",
            "| value_loss         | 3.3963828e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0106568765  |\n",
            "| clipfrac           | 0.2140625     |\n",
            "| ep_len_mean        | 318           |\n",
            "| ep_reward_mean     | 0.0244        |\n",
            "| explained_variance | -0.185        |\n",
            "| fps                | 460           |\n",
            "| n_updates          | 34            |\n",
            "| policy_entropy     | 1.6371266     |\n",
            "| policy_loss        | -0.018475212  |\n",
            "| serial_timesteps   | 4352          |\n",
            "| time_elapsed       | 80.5          |\n",
            "| total_timesteps    | 34816         |\n",
            "| value_loss         | 3.7047685e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010319846  |\n",
            "| clipfrac           | 0.12177734   |\n",
            "| ep_len_mean        | 318          |\n",
            "| ep_reward_mean     | 0.0244       |\n",
            "| explained_variance | -14.5        |\n",
            "| fps                | 497          |\n",
            "| n_updates          | 35           |\n",
            "| policy_entropy     | 1.6287816    |\n",
            "| policy_loss        | -0.01634705  |\n",
            "| serial_timesteps   | 4480         |\n",
            "| time_elapsed       | 82.7         |\n",
            "| total_timesteps    | 35840        |\n",
            "| value_loss         | 0.0008951581 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013498897   |\n",
            "| clipfrac           | 0.21923828    |\n",
            "| ep_len_mean        | 321           |\n",
            "| ep_reward_mean     | 0.0125        |\n",
            "| explained_variance | -1.83         |\n",
            "| fps                | 500           |\n",
            "| n_updates          | 36            |\n",
            "| policy_entropy     | 1.5449169     |\n",
            "| policy_loss        | -0.021694366  |\n",
            "| serial_timesteps   | 4608          |\n",
            "| time_elapsed       | 84.7          |\n",
            "| total_timesteps    | 36864         |\n",
            "| value_loss         | 0.00026361537 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01052518    |\n",
            "| clipfrac           | 0.12607422    |\n",
            "| ep_len_mean        | 321           |\n",
            "| ep_reward_mean     | 0.0125        |\n",
            "| explained_variance | -0.414        |\n",
            "| fps                | 480           |\n",
            "| n_updates          | 37            |\n",
            "| policy_entropy     | 1.5970565     |\n",
            "| policy_loss        | -0.019749207  |\n",
            "| serial_timesteps   | 4736          |\n",
            "| time_elapsed       | 86.8          |\n",
            "| total_timesteps    | 37888         |\n",
            "| value_loss         | 0.00012142501 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008220344   |\n",
            "| clipfrac           | 0.11884765    |\n",
            "| ep_len_mean        | 321           |\n",
            "| ep_reward_mean     | 0.0111        |\n",
            "| explained_variance | -0.28         |\n",
            "| fps                | 498           |\n",
            "| n_updates          | 38            |\n",
            "| policy_entropy     | 1.5509437     |\n",
            "| policy_loss        | -0.021405695  |\n",
            "| serial_timesteps   | 4864          |\n",
            "| time_elapsed       | 88.9          |\n",
            "| total_timesteps    | 38912         |\n",
            "| value_loss         | 3.5630455e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008704805  |\n",
            "| clipfrac           | 0.14833984   |\n",
            "| ep_len_mean        | 321          |\n",
            "| ep_reward_mean     | 0.0111       |\n",
            "| explained_variance | -2.12        |\n",
            "| fps                | 502          |\n",
            "| n_updates          | 39           |\n",
            "| policy_entropy     | 1.5517483    |\n",
            "| policy_loss        | -0.014787959 |\n",
            "| serial_timesteps   | 4992         |\n",
            "| time_elapsed       | 91           |\n",
            "| total_timesteps    | 39936        |\n",
            "| value_loss         | 0.000630074  |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010854888  |\n",
            "| clipfrac           | 0.13173828   |\n",
            "| ep_len_mean        | 321          |\n",
            "| ep_reward_mean     | 0.0111       |\n",
            "| explained_variance | -2.49        |\n",
            "| fps                | 187          |\n",
            "| n_updates          | 40           |\n",
            "| policy_entropy     | 1.5258777    |\n",
            "| policy_loss        | -0.016923284 |\n",
            "| serial_timesteps   | 5120         |\n",
            "| time_elapsed       | 93           |\n",
            "| total_timesteps    | 40960        |\n",
            "| value_loss         | 7.113557e-05 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011737419  |\n",
            "| clipfrac           | 0.1383789    |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -0.244       |\n",
            "| fps                | 498          |\n",
            "| n_updates          | 41           |\n",
            "| policy_entropy     | 1.5401727    |\n",
            "| policy_loss        | -0.020048786 |\n",
            "| serial_timesteps   | 5248         |\n",
            "| time_elapsed       | 98.5         |\n",
            "| total_timesteps    | 41984        |\n",
            "| value_loss         | 6.382806e-06 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015483568  |\n",
            "| clipfrac           | 0.1977539    |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -0.169       |\n",
            "| fps                | 485          |\n",
            "| n_updates          | 42           |\n",
            "| policy_entropy     | 1.5353396    |\n",
            "| policy_loss        | -0.023532536 |\n",
            "| serial_timesteps   | 5376         |\n",
            "| time_elapsed       | 101          |\n",
            "| total_timesteps    | 43008        |\n",
            "| value_loss         | 9.320453e-06 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.007351498  |\n",
            "| clipfrac           | 0.108105466  |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -0.453       |\n",
            "| fps                | 481          |\n",
            "| n_updates          | 43           |\n",
            "| policy_entropy     | 1.5001534    |\n",
            "| policy_loss        | -0.014759366 |\n",
            "| serial_timesteps   | 5504         |\n",
            "| time_elapsed       | 103          |\n",
            "| total_timesteps    | 44032        |\n",
            "| value_loss         | 8.346102e-06 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.01454512   |\n",
            "| clipfrac           | 0.2142578    |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -1.93        |\n",
            "| fps                | 499          |\n",
            "| n_updates          | 44           |\n",
            "| policy_entropy     | 1.4662763    |\n",
            "| policy_loss        | -0.020077813 |\n",
            "| serial_timesteps   | 5632         |\n",
            "| time_elapsed       | 105          |\n",
            "| total_timesteps    | 45056        |\n",
            "| value_loss         | 9.176159e-06 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.020516923  |\n",
            "| clipfrac           | 0.2376953    |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -0.778       |\n",
            "| fps                | 495          |\n",
            "| n_updates          | 45           |\n",
            "| policy_entropy     | 1.4836173    |\n",
            "| policy_loss        | -0.024312072 |\n",
            "| serial_timesteps   | 5760         |\n",
            "| time_elapsed       | 107          |\n",
            "| total_timesteps    | 46080        |\n",
            "| value_loss         | 2.985854e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01851089    |\n",
            "| clipfrac           | 0.23720703    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -2.19         |\n",
            "| fps                | 492           |\n",
            "| n_updates          | 46            |\n",
            "| policy_entropy     | 1.5047033     |\n",
            "| policy_loss        | -0.029497927  |\n",
            "| serial_timesteps   | 5888          |\n",
            "| time_elapsed       | 109           |\n",
            "| total_timesteps    | 47104         |\n",
            "| value_loss         | 9.1544587e-07 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.017657008   |\n",
            "| clipfrac           | 0.20283203    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -1.91         |\n",
            "| fps                | 479           |\n",
            "| n_updates          | 47            |\n",
            "| policy_entropy     | 1.5486338     |\n",
            "| policy_loss        | -0.03165806   |\n",
            "| serial_timesteps   | 6016          |\n",
            "| time_elapsed       | 111           |\n",
            "| total_timesteps    | 48128         |\n",
            "| value_loss         | 1.2883542e-07 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011269009   |\n",
            "| clipfrac           | 0.19267578    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -0.675        |\n",
            "| fps                | 446           |\n",
            "| n_updates          | 48            |\n",
            "| policy_entropy     | 1.529835      |\n",
            "| policy_loss        | -0.013158937  |\n",
            "| serial_timesteps   | 6144          |\n",
            "| time_elapsed       | 113           |\n",
            "| total_timesteps    | 49152         |\n",
            "| value_loss         | 3.1608448e-05 |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009538472   |\n",
            "| clipfrac           | 0.13017578    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -3.54         |\n",
            "| fps                | 190           |\n",
            "| n_updates          | 49            |\n",
            "| policy_entropy     | 1.5158608     |\n",
            "| policy_loss        | -0.02094661   |\n",
            "| serial_timesteps   | 6272          |\n",
            "| time_elapsed       | 115           |\n",
            "| total_timesteps    | 50176         |\n",
            "| value_loss         | 5.5920293e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014287872  |\n",
            "| clipfrac           | 0.17783204   |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -2.55        |\n",
            "| fps                | 509          |\n",
            "| n_updates          | 50           |\n",
            "| policy_entropy     | 1.5255134    |\n",
            "| policy_loss        | -0.018723963 |\n",
            "| serial_timesteps   | 6400         |\n",
            "| time_elapsed       | 121          |\n",
            "| total_timesteps    | 51200        |\n",
            "| value_loss         | 3.47947e-05  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01033002    |\n",
            "| clipfrac           | 0.13642578    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -9.03         |\n",
            "| fps                | 483           |\n",
            "| n_updates          | 51            |\n",
            "| policy_entropy     | 1.4561201     |\n",
            "| policy_loss        | -0.022526408  |\n",
            "| serial_timesteps   | 6528          |\n",
            "| time_elapsed       | 123           |\n",
            "| total_timesteps    | 52224         |\n",
            "| value_loss         | 1.7416281e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.012747614   |\n",
            "| clipfrac           | 0.16933593    |\n",
            "| ep_len_mean        | 323           |\n",
            "| ep_reward_mean     | 0.00353       |\n",
            "| explained_variance | -1.49         |\n",
            "| fps                | 461           |\n",
            "| n_updates          | 52            |\n",
            "| policy_entropy     | 1.4093919     |\n",
            "| policy_loss        | -0.013619895  |\n",
            "| serial_timesteps   | 6656          |\n",
            "| time_elapsed       | 125           |\n",
            "| total_timesteps    | 53248         |\n",
            "| value_loss         | 4.6173705e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012274099  |\n",
            "| clipfrac           | 0.1663086    |\n",
            "| ep_len_mean        | 323          |\n",
            "| ep_reward_mean     | 0.00353      |\n",
            "| explained_variance | -42.1        |\n",
            "| fps                | 490          |\n",
            "| n_updates          | 53           |\n",
            "| policy_entropy     | 1.4996312    |\n",
            "| policy_loss        | -0.011613073 |\n",
            "| serial_timesteps   | 6784         |\n",
            "| time_elapsed       | 127          |\n",
            "| total_timesteps    | 54272        |\n",
            "| value_loss         | 0.0001424018 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.013788559  |\n",
            "| clipfrac           | 0.17197266   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.72        |\n",
            "| fps                | 458          |\n",
            "| n_updates          | 54           |\n",
            "| policy_entropy     | 1.4176306    |\n",
            "| policy_loss        | -0.025354277 |\n",
            "| serial_timesteps   | 6912         |\n",
            "| time_elapsed       | 129          |\n",
            "| total_timesteps    | 55296        |\n",
            "| value_loss         | 1.931565e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013090392   |\n",
            "| clipfrac           | 0.17773438    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.563        |\n",
            "| fps                | 476           |\n",
            "| n_updates          | 55            |\n",
            "| policy_entropy     | 1.3711451     |\n",
            "| policy_loss        | -0.020799998  |\n",
            "| serial_timesteps   | 7040          |\n",
            "| time_elapsed       | 131           |\n",
            "| total_timesteps    | 56320         |\n",
            "| value_loss         | 5.6110428e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008906854   |\n",
            "| clipfrac           | 0.120507814   |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.174        |\n",
            "| fps                | 477           |\n",
            "| n_updates          | 56            |\n",
            "| policy_entropy     | 1.3717233     |\n",
            "| policy_loss        | -0.0217982    |\n",
            "| serial_timesteps   | 7168          |\n",
            "| time_elapsed       | 134           |\n",
            "| total_timesteps    | 57344         |\n",
            "| value_loss         | 2.0618277e-06 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011017633   |\n",
            "| clipfrac           | 0.1546875     |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.961        |\n",
            "| fps                | 479           |\n",
            "| n_updates          | 57            |\n",
            "| policy_entropy     | 1.3919575     |\n",
            "| policy_loss        | -0.016803395  |\n",
            "| serial_timesteps   | 7296          |\n",
            "| time_elapsed       | 136           |\n",
            "| total_timesteps    | 58368         |\n",
            "| value_loss         | 3.0936147e-07 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012325108  |\n",
            "| clipfrac           | 0.13769531   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.54        |\n",
            "| fps                | 481          |\n",
            "| n_updates          | 58           |\n",
            "| policy_entropy     | 1.4004616    |\n",
            "| policy_loss        | -0.02016015  |\n",
            "| serial_timesteps   | 7424         |\n",
            "| time_elapsed       | 138          |\n",
            "| total_timesteps    | 59392        |\n",
            "| value_loss         | 3.722798e-07 |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012487581  |\n",
            "| clipfrac           | 0.19140625   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -12.6        |\n",
            "| fps                | 184          |\n",
            "| n_updates          | 59           |\n",
            "| policy_entropy     | 1.3907698    |\n",
            "| policy_loss        | -0.019364271 |\n",
            "| serial_timesteps   | 7552         |\n",
            "| time_elapsed       | 140          |\n",
            "| total_timesteps    | 60416        |\n",
            "| value_loss         | 1.591319e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009712612   |\n",
            "| clipfrac           | 0.14775391    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -4.55         |\n",
            "| fps                | 479           |\n",
            "| n_updates          | 60            |\n",
            "| policy_entropy     | 1.4241254     |\n",
            "| policy_loss        | -0.013593656  |\n",
            "| serial_timesteps   | 7680          |\n",
            "| time_elapsed       | 146           |\n",
            "| total_timesteps    | 61440         |\n",
            "| value_loss         | 0.00021158264 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.012627584   |\n",
            "| clipfrac           | 0.14833984    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -3.27         |\n",
            "| fps                | 483           |\n",
            "| n_updates          | 61            |\n",
            "| policy_entropy     | 1.4104238     |\n",
            "| policy_loss        | -0.021292005  |\n",
            "| serial_timesteps   | 7808          |\n",
            "| time_elapsed       | 148           |\n",
            "| total_timesteps    | 62464         |\n",
            "| value_loss         | 8.7820714e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.01739294   |\n",
            "| clipfrac           | 0.18925782   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.19        |\n",
            "| fps                | 490          |\n",
            "| n_updates          | 62           |\n",
            "| policy_entropy     | 1.3849658    |\n",
            "| policy_loss        | -0.019457119 |\n",
            "| serial_timesteps   | 7936         |\n",
            "| time_elapsed       | 150          |\n",
            "| total_timesteps    | 63488        |\n",
            "| value_loss         | 2.057767e-05 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012832008  |\n",
            "| clipfrac           | 0.17695312   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.27        |\n",
            "| fps                | 462          |\n",
            "| n_updates          | 63           |\n",
            "| policy_entropy     | 1.412531     |\n",
            "| policy_loss        | -0.024659386 |\n",
            "| serial_timesteps   | 8064         |\n",
            "| time_elapsed       | 152          |\n",
            "| total_timesteps    | 64512        |\n",
            "| value_loss         | 8.581845e-06 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011509202  |\n",
            "| clipfrac           | 0.16914062   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -5.65        |\n",
            "| fps                | 453          |\n",
            "| n_updates          | 64           |\n",
            "| policy_entropy     | 1.4256002    |\n",
            "| policy_loss        | -0.022298036 |\n",
            "| serial_timesteps   | 8192         |\n",
            "| time_elapsed       | 154          |\n",
            "| total_timesteps    | 65536        |\n",
            "| value_loss         | 7.478672e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011157875   |\n",
            "| clipfrac           | 0.13251953    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -1.14         |\n",
            "| fps                | 459           |\n",
            "| n_updates          | 65            |\n",
            "| policy_entropy     | 1.4483913     |\n",
            "| policy_loss        | -0.020321053  |\n",
            "| serial_timesteps   | 8320          |\n",
            "| time_elapsed       | 156           |\n",
            "| total_timesteps    | 66560         |\n",
            "| value_loss         | 1.7917682e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.019216297  |\n",
            "| clipfrac           | 0.22861329   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.76        |\n",
            "| fps                | 494          |\n",
            "| n_updates          | 66           |\n",
            "| policy_entropy     | 1.3957986    |\n",
            "| policy_loss        | -0.026138324 |\n",
            "| serial_timesteps   | 8448         |\n",
            "| time_elapsed       | 159          |\n",
            "| total_timesteps    | 67584        |\n",
            "| value_loss         | 0.002631635  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010939488  |\n",
            "| clipfrac           | 0.16464844   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.91        |\n",
            "| fps                | 492          |\n",
            "| n_updates          | 67           |\n",
            "| policy_entropy     | 1.4307972    |\n",
            "| policy_loss        | -0.019289942 |\n",
            "| serial_timesteps   | 8576         |\n",
            "| time_elapsed       | 161          |\n",
            "| total_timesteps    | 68608        |\n",
            "| value_loss         | 0.0013133034 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013407193   |\n",
            "| clipfrac           | 0.1866211     |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.595        |\n",
            "| fps                | 466           |\n",
            "| n_updates          | 68            |\n",
            "| policy_entropy     | 1.4222001     |\n",
            "| policy_loss        | -0.025936797  |\n",
            "| serial_timesteps   | 8704          |\n",
            "| time_elapsed       | 163           |\n",
            "| total_timesteps    | 69632         |\n",
            "| value_loss         | 0.00013498297 |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008005844  |\n",
            "| clipfrac           | 0.11240234   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -0.23        |\n",
            "| fps                | 184          |\n",
            "| n_updates          | 69           |\n",
            "| policy_entropy     | 1.4695437    |\n",
            "| policy_loss        | -0.013036169 |\n",
            "| serial_timesteps   | 8832         |\n",
            "| time_elapsed       | 165          |\n",
            "| total_timesteps    | 70656        |\n",
            "| value_loss         | 8.54769e-05  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013385341   |\n",
            "| clipfrac           | 0.20283203    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -1.56         |\n",
            "| fps                | 500           |\n",
            "| n_updates          | 70            |\n",
            "| policy_entropy     | 1.480562      |\n",
            "| policy_loss        | -0.018227624  |\n",
            "| serial_timesteps   | 8960          |\n",
            "| time_elapsed       | 171           |\n",
            "| total_timesteps    | 71680         |\n",
            "| value_loss         | 3.4439796e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.01708618   |\n",
            "| clipfrac           | 0.23623046   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -3.27        |\n",
            "| fps                | 512          |\n",
            "| n_updates          | 71           |\n",
            "| policy_entropy     | 1.4633695    |\n",
            "| policy_loss        | -0.020182034 |\n",
            "| serial_timesteps   | 9088         |\n",
            "| time_elapsed       | 173          |\n",
            "| total_timesteps    | 72704        |\n",
            "| value_loss         | 0.0018832864 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.020054981   |\n",
            "| clipfrac           | 0.28408203    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -6.02         |\n",
            "| fps                | 497           |\n",
            "| n_updates          | 72            |\n",
            "| policy_entropy     | 1.3353878     |\n",
            "| policy_loss        | -0.042536028  |\n",
            "| serial_timesteps   | 9216          |\n",
            "| time_elapsed       | 175           |\n",
            "| total_timesteps    | 73728         |\n",
            "| value_loss         | 0.00012416118 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010525991   |\n",
            "| clipfrac           | 0.16523437    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -2.81         |\n",
            "| fps                | 469           |\n",
            "| n_updates          | 73            |\n",
            "| policy_entropy     | 1.3421483     |\n",
            "| policy_loss        | -0.018549051  |\n",
            "| serial_timesteps   | 9344          |\n",
            "| time_elapsed       | 177           |\n",
            "| total_timesteps    | 74752         |\n",
            "| value_loss         | 6.2211984e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013336199   |\n",
            "| clipfrac           | 0.17021485    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -1.73         |\n",
            "| fps                | 483           |\n",
            "| n_updates          | 74            |\n",
            "| policy_entropy     | 1.3812383     |\n",
            "| policy_loss        | -0.01892348   |\n",
            "| serial_timesteps   | 9472          |\n",
            "| time_elapsed       | 179           |\n",
            "| total_timesteps    | 75776         |\n",
            "| value_loss         | 3.0365418e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.014593177   |\n",
            "| clipfrac           | 0.19677734    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.649        |\n",
            "| fps                | 480           |\n",
            "| n_updates          | 75            |\n",
            "| policy_entropy     | 1.4107864     |\n",
            "| policy_loss        | -0.020099388  |\n",
            "| serial_timesteps   | 9600          |\n",
            "| time_elapsed       | 181           |\n",
            "| total_timesteps    | 76800         |\n",
            "| value_loss         | 2.1985175e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.015271187   |\n",
            "| clipfrac           | 0.19267578    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.472        |\n",
            "| fps                | 467           |\n",
            "| n_updates          | 76            |\n",
            "| policy_entropy     | 1.4056629     |\n",
            "| policy_loss        | -0.025562054  |\n",
            "| serial_timesteps   | 9728          |\n",
            "| time_elapsed       | 183           |\n",
            "| total_timesteps    | 77824         |\n",
            "| value_loss         | 1.3805571e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.014337638   |\n",
            "| clipfrac           | 0.21259765    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -1.5          |\n",
            "| fps                | 490           |\n",
            "| n_updates          | 77            |\n",
            "| policy_entropy     | 1.4927205     |\n",
            "| policy_loss        | -0.023053816  |\n",
            "| serial_timesteps   | 9856          |\n",
            "| time_elapsed       | 185           |\n",
            "| total_timesteps    | 78848         |\n",
            "| value_loss         | 6.8273503e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014173955  |\n",
            "| clipfrac           | 0.19355468   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -3.45        |\n",
            "| fps                | 452          |\n",
            "| n_updates          | 78           |\n",
            "| policy_entropy     | 1.4873405    |\n",
            "| policy_loss        | -0.017815683 |\n",
            "| serial_timesteps   | 9984         |\n",
            "| time_elapsed       | 187          |\n",
            "| total_timesteps    | 79872        |\n",
            "| value_loss         | 0.0016953384 |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013129977   |\n",
            "| clipfrac           | 0.20380859    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -2.7          |\n",
            "| fps                | 190           |\n",
            "| n_updates          | 79            |\n",
            "| policy_entropy     | 1.446377      |\n",
            "| policy_loss        | -0.02631392   |\n",
            "| serial_timesteps   | 10112         |\n",
            "| time_elapsed       | 190           |\n",
            "| total_timesteps    | 80896         |\n",
            "| value_loss         | 0.00028825045 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011359007  |\n",
            "| clipfrac           | 0.17861328   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -3.69        |\n",
            "| fps                | 501          |\n",
            "| n_updates          | 80           |\n",
            "| policy_entropy     | 1.4694027    |\n",
            "| policy_loss        | -0.022951167 |\n",
            "| serial_timesteps   | 10240        |\n",
            "| time_elapsed       | 195          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.0002470726 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014956933  |\n",
            "| clipfrac           | 0.21494141   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -0.785       |\n",
            "| fps                | 483          |\n",
            "| n_updates          | 81           |\n",
            "| policy_entropy     | 1.469904     |\n",
            "| policy_loss        | -0.025368085 |\n",
            "| serial_timesteps   | 10368        |\n",
            "| time_elapsed       | 197          |\n",
            "| total_timesteps    | 82944        |\n",
            "| value_loss         | 9.820531e-05 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01202072    |\n",
            "| clipfrac           | 0.17802735    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -3.58         |\n",
            "| fps                | 501           |\n",
            "| n_updates          | 82            |\n",
            "| policy_entropy     | 1.5074655     |\n",
            "| policy_loss        | -0.023973253  |\n",
            "| serial_timesteps   | 10496         |\n",
            "| time_elapsed       | 199           |\n",
            "| total_timesteps    | 83968         |\n",
            "| value_loss         | 2.7989494e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.006910441   |\n",
            "| clipfrac           | 0.103320315   |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -1.43         |\n",
            "| fps                | 498           |\n",
            "| n_updates          | 83            |\n",
            "| policy_entropy     | 1.5055073     |\n",
            "| policy_loss        | -0.014395222  |\n",
            "| serial_timesteps   | 10624         |\n",
            "| time_elapsed       | 201           |\n",
            "| total_timesteps    | 84992         |\n",
            "| value_loss         | 4.6320867e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015664956  |\n",
            "| clipfrac           | 0.21289062   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -4.94        |\n",
            "| fps                | 497          |\n",
            "| n_updates          | 84           |\n",
            "| policy_entropy     | 1.5040313    |\n",
            "| policy_loss        | -0.026338454 |\n",
            "| serial_timesteps   | 10752        |\n",
            "| time_elapsed       | 203          |\n",
            "| total_timesteps    | 86016        |\n",
            "| value_loss         | 7.256797e-05 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011120513   |\n",
            "| clipfrac           | 0.14335938    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.419        |\n",
            "| fps                | 498           |\n",
            "| n_updates          | 85            |\n",
            "| policy_entropy     | 1.4880604     |\n",
            "| policy_loss        | -0.019432347  |\n",
            "| serial_timesteps   | 10880         |\n",
            "| time_elapsed       | 205           |\n",
            "| total_timesteps    | 87040         |\n",
            "| value_loss         | 2.2669712e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014929494  |\n",
            "| clipfrac           | 0.24560547   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -0.317       |\n",
            "| fps                | 482          |\n",
            "| n_updates          | 86           |\n",
            "| policy_entropy     | 1.4611413    |\n",
            "| policy_loss        | -0.028299779 |\n",
            "| serial_timesteps   | 11008        |\n",
            "| time_elapsed       | 207          |\n",
            "| total_timesteps    | 88064        |\n",
            "| value_loss         | 5.917447e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013602449   |\n",
            "| clipfrac           | 0.22539063    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.495        |\n",
            "| fps                | 507           |\n",
            "| n_updates          | 87            |\n",
            "| policy_entropy     | 1.48412       |\n",
            "| policy_loss        | -0.022891985  |\n",
            "| serial_timesteps   | 11136         |\n",
            "| time_elapsed       | 209           |\n",
            "| total_timesteps    | 89088         |\n",
            "| value_loss         | 1.2143375e-05 |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 324.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010476653  |\n",
            "| clipfrac           | 0.13671875   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.38        |\n",
            "| fps                | 184          |\n",
            "| n_updates          | 88           |\n",
            "| policy_entropy     | 1.4660828    |\n",
            "| policy_loss        | -0.02076993  |\n",
            "| serial_timesteps   | 11264        |\n",
            "| time_elapsed       | 211          |\n",
            "| total_timesteps    | 90112        |\n",
            "| value_loss         | 4.902357e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01196879    |\n",
            "| clipfrac           | 0.1694336     |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -7.81         |\n",
            "| fps                | 489           |\n",
            "| n_updates          | 89            |\n",
            "| policy_entropy     | 1.442122      |\n",
            "| policy_loss        | -0.01565265   |\n",
            "| serial_timesteps   | 11392         |\n",
            "| time_elapsed       | 217           |\n",
            "| total_timesteps    | 91136         |\n",
            "| value_loss         | 9.3797615e-05 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011477133   |\n",
            "| clipfrac           | 0.17226562    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -2.86         |\n",
            "| fps                | 503           |\n",
            "| n_updates          | 90            |\n",
            "| policy_entropy     | 1.440985      |\n",
            "| policy_loss        | -0.031041216  |\n",
            "| serial_timesteps   | 11520         |\n",
            "| time_elapsed       | 219           |\n",
            "| total_timesteps    | 92160         |\n",
            "| value_loss         | 1.5753161e-05 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009951112  |\n",
            "| clipfrac           | 0.1415039    |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -12.2        |\n",
            "| fps                | 492          |\n",
            "| n_updates          | 91           |\n",
            "| policy_entropy     | 1.488855     |\n",
            "| policy_loss        | -0.021001961 |\n",
            "| serial_timesteps   | 11648        |\n",
            "| time_elapsed       | 221          |\n",
            "| total_timesteps    | 93184        |\n",
            "| value_loss         | 7.900277e-05 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.012464717   |\n",
            "| clipfrac           | 0.19912109    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -5.06         |\n",
            "| fps                | 484           |\n",
            "| n_updates          | 92            |\n",
            "| policy_entropy     | 1.508347      |\n",
            "| policy_loss        | -0.025205618  |\n",
            "| serial_timesteps   | 11776         |\n",
            "| time_elapsed       | 223           |\n",
            "| total_timesteps    | 94208         |\n",
            "| value_loss         | 3.5362984e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011634284  |\n",
            "| clipfrac           | 0.15097657   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -2.44        |\n",
            "| fps                | 499          |\n",
            "| n_updates          | 93           |\n",
            "| policy_entropy     | 1.4916209    |\n",
            "| policy_loss        | -0.01329731  |\n",
            "| serial_timesteps   | 11904        |\n",
            "| time_elapsed       | 225          |\n",
            "| total_timesteps    | 95232        |\n",
            "| value_loss         | 3.138623e-06 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.01356099    |\n",
            "| clipfrac           | 0.20878907    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -2.81         |\n",
            "| fps                | 497           |\n",
            "| n_updates          | 94            |\n",
            "| policy_entropy     | 1.5105339     |\n",
            "| policy_loss        | -0.028824573  |\n",
            "| serial_timesteps   | 12032         |\n",
            "| time_elapsed       | 227           |\n",
            "| total_timesteps    | 96256         |\n",
            "| value_loss         | 1.3716916e-06 |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.016303219  |\n",
            "| clipfrac           | 0.26376954   |\n",
            "| ep_len_mean        | 324          |\n",
            "| ep_reward_mean     | 0            |\n",
            "| explained_variance | -1.87        |\n",
            "| fps                | 492          |\n",
            "| n_updates          | 95           |\n",
            "| policy_entropy     | 1.4644419    |\n",
            "| policy_loss        | -0.030245882 |\n",
            "| serial_timesteps   | 12160        |\n",
            "| time_elapsed       | 229          |\n",
            "| total_timesteps    | 97280        |\n",
            "| value_loss         | 6.645997e-07 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010628772   |\n",
            "| clipfrac           | 0.13662109    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -0.712        |\n",
            "| fps                | 503           |\n",
            "| n_updates          | 96            |\n",
            "| policy_entropy     | 1.482226      |\n",
            "| policy_loss        | -0.022555033  |\n",
            "| serial_timesteps   | 12288         |\n",
            "| time_elapsed       | 232           |\n",
            "| total_timesteps    | 98304         |\n",
            "| value_loss         | 1.9922383e-07 |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011312491   |\n",
            "| clipfrac           | 0.18095703    |\n",
            "| ep_len_mean        | 324           |\n",
            "| ep_reward_mean     | 0             |\n",
            "| explained_variance | -30.7         |\n",
            "| fps                | 474           |\n",
            "| n_updates          | 97            |\n",
            "| policy_entropy     | 1.452348      |\n",
            "| policy_loss        | -0.023254648  |\n",
            "| serial_timesteps   | 12416         |\n",
            "| time_elapsed       | 234           |\n",
            "| total_timesteps    | 99328         |\n",
            "| value_loss         | 2.6876316e-05 |\n",
            "--------------------------------------\n",
            "Saving to logs/ppo2/MiniGrid-SimpleCrossingEnvUmaze-v0_1\n",
            "\u001b[0m[c665ff97727f:01635] *** Process received signal ***\n",
            "[c665ff97727f:01635] Signal: Segmentation fault (11)\n",
            "[c665ff97727f:01635] Signal code: Address not mapped (1)\n",
            "[c665ff97727f:01635] Failing at address: 0x7fa908a0620d\n",
            "[c665ff97727f:01635] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x128a0)[0x7fa90bab58a0]\n",
            "[c665ff97727f:01635] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7fa90b6f4835]\n",
            "[c665ff97727f:01635] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7fa90bf5fe44]\n",
            "[c665ff97727f:01635] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7fa90b6f56c5]\n",
            "[c665ff97727f:01635] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7fa90bf5dcb3]\n",
            "[c665ff97727f:01635] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHBq73665yD"
      },
      "source": [
        "#### Evaluate trained agent\n",
        "\n",
        "\n",
        "You can remove the `--folder logs/` to evaluate pretrained agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw8YuEgU6bT3"
      },
      "source": [
        "!python enjoy.py --algo a2c --env CartPole-v1 --no-render --n-timesteps 5000 --folder logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Il2J0VHPLC"
      },
      "source": [
        "#### Tune Hyperparameters\n",
        "\n",
        "We use [Optuna](https://optuna.org/) for optimizing the hyperparameters.\n",
        "\n",
        "Tune the hyperparameters for PPO2, using a tpe sampler and median pruner, 2 parallels jobs,\n",
        "with a budget of 1000 trials and a maximum of 50000 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2sC22eGHTH-"
      },
      "source": [
        "!python -m train.py --algo ppo2 --env MountainCar-v0 -n 50000 -optimize --n-trials 1000 --n-jobs 2 --sampler tpe --pruner median"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Record  a Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS1VBBaQ_emT"
      },
      "source": [
        "!pip install pyglet==1.3.1  # pyglet v1.4.1 throws an error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip3AauLzwNGP"
      },
      "source": [
        "!python -m utils.record_video --algo a2c --env CartPole-v1 --exp-id 0 -f logs/ -n 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBuUfnzI8DN6"
      },
      "source": [
        "### Display the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC3OTfpf8CXu"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKOjFuwK9HI0"
      },
      "source": [
        "show_videos(prefix='a2c')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjdpP0HE8D2p"
      },
      "source": [
        "### Continue Training\n",
        "\n",
        "Here, we will continue training of the previous model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgMZQJJF6u1C"
      },
      "source": [
        "!python train.py --algo a2c --env CartPole-v1 --n-timesteps 50000 -i logs/a2c/CartPole-v1.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSaoyiAE8cVj"
      },
      "source": [
        "!python enjoy.py --algo a2c --env CartPole-v1 --no-render --n-timesteps 1000 --folder logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL9u4I1H-48O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}